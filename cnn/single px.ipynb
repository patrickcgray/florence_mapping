{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import pixel as pix\n",
    "import utilities as util\n",
    "import tile\n",
    "import importlib\n",
    "import resnet as rs\n",
    "import keras\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat, sentinel, dem, label = util.load_data()\n",
    "tile_size = 1\n",
    "num_classes = util.get_class_count()\n",
    "pixel_gen = pix.pixel_gen(landsat, sentinel, dem, label, tile_size, num_classes)\n",
    "tile_gen = tile.tile_gen(landsat, sentinel, dem, label, tile_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = util.read_txt([\"train_px.txt\", \"val_px.txt\", \"test_px.txt\"])\n",
    "train_px, val_px, test_px = (pixels[0], pixels[1], pixels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 25\n",
    "input_shape = tile_gen.get_tile_shape(reshape=False, flat=True)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = util.read_txt([\"train_px.txt\", \"val_px.txt\", \"test_px.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_px, val_px, test_px = (pixels[0], pixels[1], pixels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(in_shape, num_classes):\n",
    "    input_tensor = Input(shape = in_shape)\n",
    "    \n",
    "    dense_1 = Dense(128, activation='elu') (input_tensor)\n",
    "    dense_2 = Dense(128, activation='elu') (dense_1)\n",
    "    dense_3 = Dense(128, activation='elu') (dense_2)\n",
    "    dense_4 = Dense(128, activation='elu') (dense_3)\n",
    "    dense_5 = Dense(128, activation='elu') (dense_4)\n",
    "    dense_6 = Dense(128, activation='elu') (dense_5)\n",
    "\n",
    "\n",
    "    output = Dense(num_classes,activation='softmax') (dense_6)\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model((input_shape,), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "20791/20791 [==============================] - 2266s 109ms/step - loss: 1.3593 - acc: 0.5377 - val_loss: 1.3838 - val_acc: 0.5323\n",
      "Epoch 2/200\n",
      "20791/20791 [==============================] - 2259s 109ms/step - loss: 1.3573 - acc: 0.5383 - val_loss: 1.3830 - val_acc: 0.5331\n",
      "Epoch 3/200\n",
      "20791/20791 [==============================] - 2263s 109ms/step - loss: 1.3558 - acc: 0.5390 - val_loss: 1.3820 - val_acc: 0.5331\n",
      "Epoch 4/200\n",
      "20791/20791 [==============================] - 2263s 109ms/step - loss: 1.3543 - acc: 0.5393 - val_loss: 1.3807 - val_acc: 0.5335\n",
      "Epoch 5/200\n",
      "20791/20791 [==============================] - 2258s 109ms/step - loss: 1.3529 - acc: 0.5397 - val_loss: 1.3797 - val_acc: 0.5340\n",
      "Epoch 6/200\n",
      "20791/20791 [==============================] - 2260s 109ms/step - loss: 1.3515 - acc: 0.5401 - val_loss: 1.3793 - val_acc: 0.5342\n",
      "Epoch 7/200\n",
      "20791/20791 [==============================] - 2253s 108ms/step - loss: 1.3502 - acc: 0.5406 - val_loss: 1.3785 - val_acc: 0.5347\n",
      "Epoch 8/200\n",
      "20791/20791 [==============================] - 2243s 108ms/step - loss: 1.3492 - acc: 0.5410 - val_loss: 1.3773 - val_acc: 0.5350\n",
      "Epoch 9/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3480 - acc: 0.5414 - val_loss: 1.3769 - val_acc: 0.5350\n",
      "Epoch 10/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3470 - acc: 0.5415 - val_loss: 1.3764 - val_acc: 0.5354\n",
      "Epoch 11/200\n",
      "20791/20791 [==============================] - 2255s 108ms/step - loss: 1.3460 - acc: 0.5419 - val_loss: 1.3756 - val_acc: 0.5356\n",
      "Epoch 12/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3451 - acc: 0.5421 - val_loss: 1.3753 - val_acc: 0.5356\n",
      "Epoch 13/200\n",
      "20791/20791 [==============================] - 2248s 108ms/step - loss: 1.3441 - acc: 0.5424 - val_loss: 1.3741 - val_acc: 0.5362\n",
      "Epoch 14/200\n",
      "20791/20791 [==============================] - 2245s 108ms/step - loss: 1.3433 - acc: 0.5426 - val_loss: 1.3743 - val_acc: 0.5362\n",
      "Epoch 15/200\n",
      "20791/20791 [==============================] - 2261s 109ms/step - loss: 1.3426 - acc: 0.5429 - val_loss: 1.3736 - val_acc: 0.5364\n",
      "Epoch 16/200\n",
      "20791/20791 [==============================] - 2254s 108ms/step - loss: 1.3418 - acc: 0.5430 - val_loss: 1.3737 - val_acc: 0.5366\n",
      "Epoch 17/200\n",
      "20791/20791 [==============================] - 2259s 109ms/step - loss: 1.3411 - acc: 0.5434 - val_loss: 1.3724 - val_acc: 0.5369\n",
      "Epoch 18/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3403 - acc: 0.5436 - val_loss: 1.3720 - val_acc: 0.5370\n",
      "Epoch 19/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3396 - acc: 0.5438 - val_loss: 1.3721 - val_acc: 0.5371\n",
      "Epoch 20/200\n",
      "20791/20791 [==============================] - 2249s 108ms/step - loss: 1.3389 - acc: 0.5441 - val_loss: 1.3715 - val_acc: 0.5375\n",
      "Epoch 21/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3383 - acc: 0.5442 - val_loss: 1.3715 - val_acc: 0.5374\n",
      "Epoch 22/200\n",
      "20791/20791 [==============================] - 2253s 108ms/step - loss: 1.3377 - acc: 0.5443 - val_loss: 1.3709 - val_acc: 0.5375\n",
      "Epoch 23/200\n",
      "20791/20791 [==============================] - 2258s 109ms/step - loss: 1.3371 - acc: 0.5446 - val_loss: 1.3705 - val_acc: 0.5377\n",
      "Epoch 24/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3366 - acc: 0.5448 - val_loss: 1.3703 - val_acc: 0.5375\n",
      "Epoch 25/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3361 - acc: 0.5450 - val_loss: 1.3700 - val_acc: 0.5382\n",
      "Epoch 26/200\n",
      "20791/20791 [==============================] - 2249s 108ms/step - loss: 1.3356 - acc: 0.5450 - val_loss: 1.3698 - val_acc: 0.5380\n",
      "Epoch 27/200\n",
      "20791/20791 [==============================] - 2247s 108ms/step - loss: 1.3350 - acc: 0.5453 - val_loss: 1.3692 - val_acc: 0.5382\n",
      "Epoch 28/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3346 - acc: 0.5455 - val_loss: 1.3693 - val_acc: 0.5386\n",
      "Epoch 29/200\n",
      "20791/20791 [==============================] - 2248s 108ms/step - loss: 1.3341 - acc: 0.5455 - val_loss: 1.3692 - val_acc: 0.5383\n",
      "Epoch 30/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3336 - acc: 0.5458 - val_loss: 1.3687 - val_acc: 0.5388\n",
      "Epoch 31/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3330 - acc: 0.5458 - val_loss: 1.3691 - val_acc: 0.5384\n",
      "Epoch 32/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3326 - acc: 0.5460 - val_loss: 1.3685 - val_acc: 0.5387\n",
      "Epoch 33/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3322 - acc: 0.5462 - val_loss: 1.3686 - val_acc: 0.5387\n",
      "Epoch 34/200\n",
      "20791/20791 [==============================] - 2246s 108ms/step - loss: 1.3318 - acc: 0.5462 - val_loss: 1.3685 - val_acc: 0.5383\n",
      "Epoch 35/200\n",
      "20791/20791 [==============================] - 2249s 108ms/step - loss: 1.3314 - acc: 0.5465 - val_loss: 1.3676 - val_acc: 0.5389\n",
      "Epoch 36/200\n",
      "20791/20791 [==============================] - 2249s 108ms/step - loss: 1.3308 - acc: 0.5466 - val_loss: 1.3679 - val_acc: 0.5387\n",
      "Epoch 37/200\n",
      "20791/20791 [==============================] - 2253s 108ms/step - loss: 1.3305 - acc: 0.5467 - val_loss: 1.3675 - val_acc: 0.5389\n",
      "Epoch 38/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3302 - acc: 0.5470 - val_loss: 1.3674 - val_acc: 0.5392\n",
      "Epoch 39/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3298 - acc: 0.5470 - val_loss: 1.3668 - val_acc: 0.5393\n",
      "Epoch 40/200\n",
      "20791/20791 [==============================] - 2257s 109ms/step - loss: 1.3293 - acc: 0.5472 - val_loss: 1.3670 - val_acc: 0.5391\n",
      "Epoch 41/200\n",
      "20791/20791 [==============================] - 2248s 108ms/step - loss: 1.3289 - acc: 0.5472 - val_loss: 1.3672 - val_acc: 0.5391\n",
      "Epoch 42/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3286 - acc: 0.5474 - val_loss: 1.3666 - val_acc: 0.5391\n",
      "Epoch 43/200\n",
      "20791/20791 [==============================] - 2248s 108ms/step - loss: 1.3280 - acc: 0.5476 - val_loss: 1.3665 - val_acc: 0.5394\n",
      "Epoch 44/200\n",
      "20791/20791 [==============================] - 2253s 108ms/step - loss: 1.3277 - acc: 0.5478 - val_loss: 1.3664 - val_acc: 0.5396\n",
      "Epoch 45/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3273 - acc: 0.5480 - val_loss: 1.3661 - val_acc: 0.5395\n",
      "Epoch 46/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3271 - acc: 0.5480 - val_loss: 1.3658 - val_acc: 0.5399\n",
      "Epoch 47/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3266 - acc: 0.5481 - val_loss: 1.3663 - val_acc: 0.5398\n",
      "Epoch 48/200\n",
      "20791/20791 [==============================] - 2249s 108ms/step - loss: 1.3263 - acc: 0.5483 - val_loss: 1.3657 - val_acc: 0.5401\n",
      "Epoch 49/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3259 - acc: 0.5484 - val_loss: 1.3654 - val_acc: 0.5399\n",
      "Epoch 50/200\n",
      "20791/20791 [==============================] - 2246s 108ms/step - loss: 1.3254 - acc: 0.5486 - val_loss: 1.3656 - val_acc: 0.5399\n",
      "Epoch 51/200\n",
      "20791/20791 [==============================] - 2256s 109ms/step - loss: 1.3252 - acc: 0.5486 - val_loss: 1.3650 - val_acc: 0.5401\n",
      "Epoch 52/200\n",
      "20791/20791 [==============================] - 2256s 109ms/step - loss: 1.3248 - acc: 0.5487 - val_loss: 1.3653 - val_acc: 0.5403\n",
      "Epoch 53/200\n",
      "20791/20791 [==============================] - 2253s 108ms/step - loss: 1.3245 - acc: 0.5488 - val_loss: 1.3644 - val_acc: 0.5404\n",
      "Epoch 54/200\n",
      "20791/20791 [==============================] - 2246s 108ms/step - loss: 1.3241 - acc: 0.5489 - val_loss: 1.3647 - val_acc: 0.5402\n",
      "Epoch 55/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3236 - acc: 0.5490 - val_loss: 1.3644 - val_acc: 0.5403\n",
      "Epoch 56/200\n",
      "20791/20791 [==============================] - 2258s 109ms/step - loss: 1.3233 - acc: 0.5490 - val_loss: 1.3646 - val_acc: 0.5406\n",
      "Epoch 57/200\n",
      "20791/20791 [==============================] - 2248s 108ms/step - loss: 1.3231 - acc: 0.5493 - val_loss: 1.3643 - val_acc: 0.5407\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20791/20791 [==============================] - 2245s 108ms/step - loss: 1.3226 - acc: 0.5493 - val_loss: 1.3643 - val_acc: 0.5407\n",
      "Epoch 59/200\n",
      "20791/20791 [==============================] - 2254s 108ms/step - loss: 1.3223 - acc: 0.5494 - val_loss: 1.3642 - val_acc: 0.5406\n",
      "Epoch 60/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3221 - acc: 0.5495 - val_loss: 1.3638 - val_acc: 0.5411\n",
      "Epoch 61/200\n",
      "20791/20791 [==============================] - 2249s 108ms/step - loss: 1.3217 - acc: 0.5497 - val_loss: 1.3636 - val_acc: 0.5409\n",
      "Epoch 62/200\n",
      "20791/20791 [==============================] - 2257s 109ms/step - loss: 1.3213 - acc: 0.5498 - val_loss: 1.3636 - val_acc: 0.5409\n",
      "Epoch 63/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3211 - acc: 0.5499 - val_loss: 1.3630 - val_acc: 0.5413\n",
      "Epoch 64/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3208 - acc: 0.5499 - val_loss: 1.3633 - val_acc: 0.5411\n",
      "Epoch 65/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3203 - acc: 0.5502 - val_loss: 1.3633 - val_acc: 0.5409\n",
      "Epoch 66/200\n",
      "20791/20791 [==============================] - 2249s 108ms/step - loss: 1.3201 - acc: 0.5504 - val_loss: 1.3633 - val_acc: 0.5412\n",
      "Epoch 67/200\n",
      "20791/20791 [==============================] - 2253s 108ms/step - loss: 1.3198 - acc: 0.5504 - val_loss: 1.3626 - val_acc: 0.5414\n",
      "Epoch 68/200\n",
      "20791/20791 [==============================] - 2253s 108ms/step - loss: 1.3194 - acc: 0.5505 - val_loss: 1.3630 - val_acc: 0.5411\n",
      "Epoch 69/200\n",
      "20791/20791 [==============================] - 2255s 108ms/step - loss: 1.3193 - acc: 0.5507 - val_loss: 1.3624 - val_acc: 0.5415\n",
      "Epoch 70/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3189 - acc: 0.5509 - val_loss: 1.3627 - val_acc: 0.5412\n",
      "Epoch 71/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3186 - acc: 0.5509 - val_loss: 1.3625 - val_acc: 0.5414\n",
      "Epoch 72/200\n",
      "20791/20791 [==============================] - 2254s 108ms/step - loss: 1.3183 - acc: 0.5510 - val_loss: 1.3619 - val_acc: 0.5419\n",
      "Epoch 73/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3179 - acc: 0.5511 - val_loss: 1.3621 - val_acc: 0.5416\n",
      "Epoch 74/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3176 - acc: 0.5512 - val_loss: 1.3618 - val_acc: 0.5418\n",
      "Epoch 75/200\n",
      "20791/20791 [==============================] - 2247s 108ms/step - loss: 1.3173 - acc: 0.5514 - val_loss: 1.3616 - val_acc: 0.5419\n",
      "Epoch 76/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3171 - acc: 0.5514 - val_loss: 1.3619 - val_acc: 0.5418\n",
      "Epoch 77/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3167 - acc: 0.5516 - val_loss: 1.3619 - val_acc: 0.5417\n",
      "Epoch 78/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3165 - acc: 0.5517 - val_loss: 1.3617 - val_acc: 0.5418\n",
      "Epoch 79/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3163 - acc: 0.5518 - val_loss: 1.3611 - val_acc: 0.5418\n",
      "Epoch 80/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3160 - acc: 0.5519 - val_loss: 1.3610 - val_acc: 0.5420\n",
      "Epoch 81/200\n",
      "20791/20791 [==============================] - 2259s 109ms/step - loss: 1.3156 - acc: 0.5520 - val_loss: 1.3608 - val_acc: 0.5422\n",
      "Epoch 82/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3153 - acc: 0.5519 - val_loss: 1.3612 - val_acc: 0.5424\n",
      "Epoch 83/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3151 - acc: 0.5522 - val_loss: 1.3613 - val_acc: 0.5421\n",
      "Epoch 84/200\n",
      "20791/20791 [==============================] - 2254s 108ms/step - loss: 1.3148 - acc: 0.5522 - val_loss: 1.3611 - val_acc: 0.5424\n",
      "Epoch 85/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3145 - acc: 0.5522 - val_loss: 1.3606 - val_acc: 0.5426\n",
      "Epoch 86/200\n",
      "20791/20791 [==============================] - 2248s 108ms/step - loss: 1.3143 - acc: 0.5524 - val_loss: 1.3608 - val_acc: 0.5427\n",
      "Epoch 87/200\n",
      "20791/20791 [==============================] - 2255s 108ms/step - loss: 1.3142 - acc: 0.5525 - val_loss: 1.3606 - val_acc: 0.5426\n",
      "Epoch 88/200\n",
      "20791/20791 [==============================] - 2248s 108ms/step - loss: 1.3141 - acc: 0.5525 - val_loss: 1.3606 - val_acc: 0.5426\n",
      "Epoch 89/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3138 - acc: 0.5526 - val_loss: 1.3606 - val_acc: 0.5429\n",
      "Epoch 90/200\n",
      "20791/20791 [==============================] - 2255s 108ms/step - loss: 1.3132 - acc: 0.5527 - val_loss: 1.3604 - val_acc: 0.5424\n",
      "Epoch 91/200\n",
      "20791/20791 [==============================] - 2245s 108ms/step - loss: 1.3131 - acc: 0.5528 - val_loss: 1.3606 - val_acc: 0.5427\n",
      "Epoch 92/200\n",
      "20791/20791 [==============================] - 2258s 109ms/step - loss: 1.3130 - acc: 0.5528 - val_loss: 1.3598 - val_acc: 0.5431\n",
      "Epoch 93/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3125 - acc: 0.5530 - val_loss: 1.3598 - val_acc: 0.5431\n",
      "Epoch 94/200\n",
      "20791/20791 [==============================] - 2247s 108ms/step - loss: 1.3123 - acc: 0.5531 - val_loss: 1.3603 - val_acc: 0.5431\n",
      "Epoch 95/200\n",
      "20791/20791 [==============================] - 2257s 109ms/step - loss: 1.3123 - acc: 0.5532 - val_loss: 1.3599 - val_acc: 0.5431\n",
      "Epoch 96/200\n",
      "20791/20791 [==============================] - 2253s 108ms/step - loss: 1.3119 - acc: 0.5532 - val_loss: 1.3592 - val_acc: 0.5432\n",
      "Epoch 97/200\n",
      "20791/20791 [==============================] - 2252s 108ms/step - loss: 1.3116 - acc: 0.5533 - val_loss: 1.3596 - val_acc: 0.5430\n",
      "Epoch 98/200\n",
      "20791/20791 [==============================] - 2247s 108ms/step - loss: 1.3112 - acc: 0.5533 - val_loss: 1.3598 - val_acc: 0.5434\n",
      "Epoch 99/200\n",
      "20791/20791 [==============================] - 2246s 108ms/step - loss: 1.3112 - acc: 0.5533 - val_loss: 1.3599 - val_acc: 0.5433\n",
      "Epoch 100/200\n",
      "20791/20791 [==============================] - 2244s 108ms/step - loss: 1.3110 - acc: 0.5535 - val_loss: 1.3594 - val_acc: 0.5434\n",
      "Epoch 101/200\n",
      "20791/20791 [==============================] - 2257s 109ms/step - loss: 1.3108 - acc: 0.5535 - val_loss: 1.3603 - val_acc: 0.5435\n",
      "Epoch 102/200\n",
      "20791/20791 [==============================] - 2242s 108ms/step - loss: 1.3106 - acc: 0.5537 - val_loss: 1.3590 - val_acc: 0.5434\n",
      "Epoch 103/200\n",
      "20791/20791 [==============================] - 2243s 108ms/step - loss: 1.3102 - acc: 0.5538 - val_loss: 1.3597 - val_acc: 0.5433\n",
      "Epoch 104/200\n",
      "20791/20791 [==============================] - 2247s 108ms/step - loss: 1.3101 - acc: 0.5539 - val_loss: 1.3589 - val_acc: 0.5435\n",
      "Epoch 105/200\n",
      "20791/20791 [==============================] - 2246s 108ms/step - loss: 1.3097 - acc: 0.5538 - val_loss: 1.3590 - val_acc: 0.5436\n",
      "Epoch 106/200\n",
      "20791/20791 [==============================] - 2248s 108ms/step - loss: 1.3095 - acc: 0.5537 - val_loss: 1.3592 - val_acc: 0.5436\n",
      "Epoch 107/200\n",
      "20791/20791 [==============================] - 2249s 108ms/step - loss: 1.3093 - acc: 0.5541 - val_loss: 1.3598 - val_acc: 0.5432\n",
      "Epoch 108/200\n",
      "20791/20791 [==============================] - 2243s 108ms/step - loss: 1.3090 - acc: 0.5541 - val_loss: 1.3592 - val_acc: 0.5435\n",
      "Epoch 109/200\n",
      "20791/20791 [==============================] - 2246s 108ms/step - loss: 1.3089 - acc: 0.5541 - val_loss: 1.3592 - val_acc: 0.5432\n",
      "Epoch 110/200\n",
      "20791/20791 [==============================] - 2251s 108ms/step - loss: 1.3087 - acc: 0.5544 - val_loss: 1.3585 - val_acc: 0.5434\n",
      "Epoch 111/200\n",
      "20791/20791 [==============================] - 2250s 108ms/step - loss: 1.3085 - acc: 0.5544 - val_loss: 1.3587 - val_acc: 0.5437\n",
      "Epoch 112/200\n",
      "20791/20791 [==============================] - 2244s 108ms/step - loss: 1.3084 - acc: 0.5543 - val_loss: 1.3586 - val_acc: 0.5436\n",
      "Epoch 113/200\n",
      "20791/20791 [==============================] - 2246s 108ms/step - loss: 1.3081 - acc: 0.5545 - val_loss: 1.3587 - val_acc: 0.5438\n",
      "Epoch 114/200\n",
      "20791/20791 [==============================] - 2241s 108ms/step - loss: 1.3079 - acc: 0.5545 - val_loss: 1.3583 - val_acc: 0.5437\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20791/20791 [==============================] - 2238s 108ms/step - loss: 1.3077 - acc: 0.5545 - val_loss: 1.3593 - val_acc: 0.5432\n",
      "Epoch 116/200\n",
      "20791/20791 [==============================] - 2238s 108ms/step - loss: 1.3075 - acc: 0.5547 - val_loss: 1.3579 - val_acc: 0.5437\n",
      "Epoch 117/200\n",
      "20791/20791 [==============================] - 2244s 108ms/step - loss: 1.3071 - acc: 0.5548 - val_loss: 1.3590 - val_acc: 0.5436\n",
      "Epoch 118/200\n",
      "20791/20791 [==============================] - 2240s 108ms/step - loss: 1.3071 - acc: 0.5548 - val_loss: 1.3591 - val_acc: 0.5434\n",
      "Epoch 119/200\n",
      "20791/20791 [==============================] - 2244s 108ms/step - loss: 1.3069 - acc: 0.5548 - val_loss: 1.3583 - val_acc: 0.5437\n",
      "Epoch 120/200\n",
      "20791/20791 [==============================] - 2242s 108ms/step - loss: 1.3067 - acc: 0.5550 - val_loss: 1.3580 - val_acc: 0.5436\n",
      "Epoch 121/200\n",
      "20791/20791 [==============================] - 2240s 108ms/step - loss: 1.3066 - acc: 0.5550 - val_loss: 1.3582 - val_acc: 0.5436\n",
      "Epoch 122/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.3064 - acc: 0.5551 - val_loss: 1.3581 - val_acc: 0.5436\n",
      "Epoch 123/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.3061 - acc: 0.5552 - val_loss: 1.3581 - val_acc: 0.5435\n",
      "Epoch 124/200\n",
      "20791/20791 [==============================] - 2235s 107ms/step - loss: 1.3061 - acc: 0.5551 - val_loss: 1.3579 - val_acc: 0.5437\n",
      "Epoch 125/200\n",
      "20791/20791 [==============================] - 2234s 107ms/step - loss: 1.3058 - acc: 0.5552 - val_loss: 1.3571 - val_acc: 0.5435\n",
      "Epoch 126/200\n",
      "20791/20791 [==============================] - 2241s 108ms/step - loss: 1.3055 - acc: 0.5552 - val_loss: 1.3582 - val_acc: 0.5435\n",
      "Epoch 127/200\n",
      "20791/20791 [==============================] - 2238s 108ms/step - loss: 1.3055 - acc: 0.5554 - val_loss: 1.3589 - val_acc: 0.5432\n",
      "Epoch 128/200\n",
      "20791/20791 [==============================] - 2232s 107ms/step - loss: 1.3052 - acc: 0.5554 - val_loss: 1.3573 - val_acc: 0.5436\n",
      "Epoch 129/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.3048 - acc: 0.5555 - val_loss: 1.3574 - val_acc: 0.5435\n",
      "Epoch 130/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.3048 - acc: 0.5555 - val_loss: 1.3576 - val_acc: 0.5438\n",
      "Epoch 131/200\n",
      "20791/20791 [==============================] - 2242s 108ms/step - loss: 1.3046 - acc: 0.5556 - val_loss: 1.3579 - val_acc: 0.5439\n",
      "Epoch 132/200\n",
      "20791/20791 [==============================] - 2236s 108ms/step - loss: 1.3046 - acc: 0.5555 - val_loss: 1.3588 - val_acc: 0.5435\n",
      "Epoch 133/200\n",
      "20791/20791 [==============================] - 2236s 108ms/step - loss: 1.3043 - acc: 0.5556 - val_loss: 1.3576 - val_acc: 0.5435\n",
      "Epoch 134/200\n",
      "20791/20791 [==============================] - 2239s 108ms/step - loss: 1.3041 - acc: 0.5557 - val_loss: 1.3584 - val_acc: 0.5435\n",
      "Epoch 135/200\n",
      "20791/20791 [==============================] - 2240s 108ms/step - loss: 1.3038 - acc: 0.5557 - val_loss: 1.3581 - val_acc: 0.5435\n",
      "Epoch 136/200\n",
      "20791/20791 [==============================] - 2240s 108ms/step - loss: 1.3037 - acc: 0.5559 - val_loss: 1.3576 - val_acc: 0.5439\n",
      "Epoch 137/200\n",
      "20791/20791 [==============================] - 2239s 108ms/step - loss: 1.3037 - acc: 0.5559 - val_loss: 1.3579 - val_acc: 0.5439\n",
      "Epoch 138/200\n",
      "20791/20791 [==============================] - 2239s 108ms/step - loss: 1.3037 - acc: 0.5560 - val_loss: 1.3573 - val_acc: 0.5441\n",
      "Epoch 139/200\n",
      "20791/20791 [==============================] - 2234s 107ms/step - loss: 1.3033 - acc: 0.5559 - val_loss: 1.3590 - val_acc: 0.5434\n",
      "Epoch 140/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.3031 - acc: 0.5561 - val_loss: 1.3570 - val_acc: 0.5437\n",
      "Epoch 141/200\n",
      "20791/20791 [==============================] - 2241s 108ms/step - loss: 1.3029 - acc: 0.5562 - val_loss: 1.3580 - val_acc: 0.5439\n",
      "Epoch 142/200\n",
      "20791/20791 [==============================] - 2241s 108ms/step - loss: 1.3027 - acc: 0.5561 - val_loss: 1.3581 - val_acc: 0.5437\n",
      "Epoch 143/200\n",
      "20791/20791 [==============================] - 2240s 108ms/step - loss: 1.3026 - acc: 0.5562 - val_loss: 1.3575 - val_acc: 0.5439\n",
      "Epoch 144/200\n",
      "20791/20791 [==============================] - 2241s 108ms/step - loss: 1.3024 - acc: 0.5563 - val_loss: 1.3570 - val_acc: 0.5439\n",
      "Epoch 145/200\n",
      "20791/20791 [==============================] - 2242s 108ms/step - loss: 1.3020 - acc: 0.5563 - val_loss: 1.3570 - val_acc: 0.5437\n",
      "Epoch 146/200\n",
      "20791/20791 [==============================] - 2239s 108ms/step - loss: 1.3018 - acc: 0.5566 - val_loss: 1.3581 - val_acc: 0.5437\n",
      "Epoch 147/200\n",
      "20791/20791 [==============================] - 2241s 108ms/step - loss: 1.3017 - acc: 0.5564 - val_loss: 1.3580 - val_acc: 0.5439\n",
      "Epoch 148/200\n",
      "20791/20791 [==============================] - 2239s 108ms/step - loss: 1.3016 - acc: 0.5566 - val_loss: 1.3576 - val_acc: 0.5438\n",
      "Epoch 149/200\n",
      "20791/20791 [==============================] - 2239s 108ms/step - loss: 1.3015 - acc: 0.5567 - val_loss: 1.3582 - val_acc: 0.5437\n",
      "Epoch 150/200\n",
      "20791/20791 [==============================] - 2240s 108ms/step - loss: 1.3014 - acc: 0.5567 - val_loss: 1.3577 - val_acc: 0.5440\n",
      "Epoch 151/200\n",
      "20791/20791 [==============================] - 2238s 108ms/step - loss: 1.3012 - acc: 0.5568 - val_loss: 1.3571 - val_acc: 0.5440\n",
      "Epoch 152/200\n",
      "20791/20791 [==============================] - 2236s 108ms/step - loss: 1.3010 - acc: 0.5566 - val_loss: 1.3572 - val_acc: 0.5440\n",
      "Epoch 153/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.3007 - acc: 0.5567 - val_loss: 1.3572 - val_acc: 0.5438\n",
      "Epoch 154/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.3007 - acc: 0.5567 - val_loss: 1.3579 - val_acc: 0.5438\n",
      "Epoch 155/200\n",
      "20791/20791 [==============================] - 2236s 108ms/step - loss: 1.3004 - acc: 0.5568 - val_loss: 1.3569 - val_acc: 0.5442\n",
      "Epoch 156/200\n",
      "20791/20791 [==============================] - 2235s 107ms/step - loss: 1.3002 - acc: 0.5570 - val_loss: 1.3566 - val_acc: 0.5442\n",
      "Epoch 157/200\n",
      "20791/20791 [==============================] - 2235s 108ms/step - loss: 1.3002 - acc: 0.5572 - val_loss: 1.3562 - val_acc: 0.5441\n",
      "Epoch 158/200\n",
      "20791/20791 [==============================] - 2239s 108ms/step - loss: 1.3000 - acc: 0.5570 - val_loss: 1.3559 - val_acc: 0.5440\n",
      "Epoch 159/200\n",
      "20791/20791 [==============================] - 2234s 107ms/step - loss: 1.3000 - acc: 0.5571 - val_loss: 1.3571 - val_acc: 0.5440\n",
      "Epoch 160/200\n",
      "20791/20791 [==============================] - 2235s 108ms/step - loss: 1.2997 - acc: 0.5571 - val_loss: 1.3591 - val_acc: 0.5434\n",
      "Epoch 161/200\n",
      "20791/20791 [==============================] - 2239s 108ms/step - loss: 1.2996 - acc: 0.5572 - val_loss: 1.3570 - val_acc: 0.5443\n",
      "Epoch 162/200\n",
      "20791/20791 [==============================] - 2232s 107ms/step - loss: 1.2994 - acc: 0.5571 - val_loss: 1.3573 - val_acc: 0.5440\n",
      "Epoch 163/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.2992 - acc: 0.5574 - val_loss: 1.3560 - val_acc: 0.5444\n",
      "Epoch 164/200\n",
      "20791/20791 [==============================] - 2228s 107ms/step - loss: 1.2989 - acc: 0.5573 - val_loss: 1.3571 - val_acc: 0.5442\n",
      "Epoch 165/200\n",
      "20791/20791 [==============================] - 2233s 107ms/step - loss: 1.2989 - acc: 0.5574 - val_loss: 1.3587 - val_acc: 0.5435\n",
      "Epoch 166/200\n",
      "20791/20791 [==============================] - 2234s 107ms/step - loss: 1.2989 - acc: 0.5573 - val_loss: 1.3566 - val_acc: 0.5440\n",
      "Epoch 167/200\n",
      "20791/20791 [==============================] - 2240s 108ms/step - loss: 1.2988 - acc: 0.5574 - val_loss: 1.3573 - val_acc: 0.5440\n",
      "Epoch 168/200\n",
      "20791/20791 [==============================] - 2228s 107ms/step - loss: 1.2984 - acc: 0.5575 - val_loss: 1.3558 - val_acc: 0.5444\n",
      "Epoch 169/200\n",
      "20791/20791 [==============================] - 2238s 108ms/step - loss: 1.2983 - acc: 0.5576 - val_loss: 1.3575 - val_acc: 0.5444\n",
      "Epoch 170/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.2981 - acc: 0.5578 - val_loss: 1.3563 - val_acc: 0.5438\n",
      "Epoch 171/200\n",
      "20791/20791 [==============================] - 2236s 108ms/step - loss: 1.2981 - acc: 0.5577 - val_loss: 1.3575 - val_acc: 0.5442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.2980 - acc: 0.5577 - val_loss: 1.3568 - val_acc: 0.5442\n",
      "Epoch 173/200\n",
      "20791/20791 [==============================] - 2236s 108ms/step - loss: 1.2976 - acc: 0.5577 - val_loss: 1.3568 - val_acc: 0.5445\n",
      "Epoch 174/200\n",
      "20791/20791 [==============================] - 2233s 107ms/step - loss: 1.2975 - acc: 0.5579 - val_loss: 1.3584 - val_acc: 0.5438\n",
      "Epoch 175/200\n",
      "20791/20791 [==============================] - 2237s 108ms/step - loss: 1.2975 - acc: 0.5579 - val_loss: 1.3561 - val_acc: 0.5445\n",
      "Epoch 176/200\n",
      "20791/20791 [==============================] - 2234s 107ms/step - loss: 1.2974 - acc: 0.5580 - val_loss: 1.3567 - val_acc: 0.5443\n",
      "Epoch 177/200\n",
      "20791/20791 [==============================] - 2235s 108ms/step - loss: 1.2973 - acc: 0.5580 - val_loss: 1.3570 - val_acc: 0.5444\n",
      "Epoch 178/200\n",
      "20791/20791 [==============================] - 2243s 108ms/step - loss: 1.2970 - acc: 0.5581 - val_loss: 1.3561 - val_acc: 0.5446\n",
      "Epoch 179/200\n",
      "20791/20791 [==============================] - 2234s 107ms/step - loss: 1.2969 - acc: 0.5581 - val_loss: 1.3561 - val_acc: 0.5444\n",
      "Epoch 180/200\n",
      "20791/20791 [==============================] - 2242s 108ms/step - loss: 1.2967 - acc: 0.5583 - val_loss: 1.3571 - val_acc: 0.5444\n",
      "Epoch 181/200\n",
      "20791/20791 [==============================] - 2229s 107ms/step - loss: 1.2964 - acc: 0.5583 - val_loss: 1.3565 - val_acc: 0.5443\n",
      "Epoch 182/200\n",
      "20791/20791 [==============================] - 2230s 107ms/step - loss: 1.2965 - acc: 0.5583 - val_loss: 1.3570 - val_acc: 0.5444\n",
      "Epoch 183/200\n",
      "20791/20791 [==============================] - 2234s 107ms/step - loss: 1.2963 - acc: 0.5582 - val_loss: 1.3568 - val_acc: 0.5444\n",
      "Epoch 184/200\n",
      "20791/20791 [==============================] - 2241s 108ms/step - loss: 1.2961 - acc: 0.5584 - val_loss: 1.3562 - val_acc: 0.5442\n",
      "Epoch 185/200\n",
      "20791/20791 [==============================] - 2229s 107ms/step - loss: 1.2961 - acc: 0.5585 - val_loss: 1.3571 - val_acc: 0.5443\n",
      "Epoch 186/200\n",
      "20791/20791 [==============================] - 2231s 107ms/step - loss: 1.2959 - acc: 0.5585 - val_loss: 1.3558 - val_acc: 0.5447\n",
      "Epoch 187/200\n",
      "19989/20791 [===========================>..] - ETA: 1:06 - loss: 1.2962 - acc: 0.5583"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0a8631068001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_px\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtile_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_px\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     validation_steps=len(val_px) // batch_size)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=tile_gen.tile_generator(train_px, batch_size, flat=True), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=tile_gen.tile_generator(val_px, batch_size, flat=True),\n",
    "                    validation_steps=len(val_px) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nn_model_fixed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
