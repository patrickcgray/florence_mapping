{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import resnet as rs\n",
    "import importlib\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import classifier_utilities as cu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'classifier_utilities' from '/host/Desktop/cnn_dev/florence_mapping/classifier_utilities.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_datasets, sentinel_datasets, dem_datasets, label_dataset = cu.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "epochs = 200\n",
    "num_classes = len(cu.indexed_dictionary)\n",
    "\n",
    "# input image dimensions\n",
    "tile_side = 64\n",
    "img_rows, img_cols = tile_side, tile_side\n",
    "img_bands = landsat_datasets[0].count + sentinel_datasets[0].count + dem_datasets[0].count - 1\n",
    "\n",
    "input_shape = (img_bands, img_cols,img_rows)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:23<00:00, 143.25s/it]\n"
     ]
    }
   ],
   "source": [
    "pixels = cu.gen_balanced_pixel_locations(landsat_datasets[1:2], 80000, label_dataset=label_dataset, tile_size = tile_side,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54546\n"
     ]
    }
   ],
   "source": [
    "print(len(pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = cu.pixel_balance(pixels, landsat_datasets[1:2], label_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water:872.0\n",
      "Snow/Ice:0.0\n",
      "Open Space Developed:5000.0\n",
      "Low Intensity Developed:0.0\n",
      "Medium Intensity Developed:5000.0\n",
      "High Intensity Developed:0.0\n",
      "Barren Land:1579.0\n",
      "Deciduous Forest:5000.0\n",
      "Evergreen Forest:5000.0\n",
      "Mixed Forest:5000.0\n",
      "Scrub/Shrub:5000.0\n",
      "Grassland / Herbaceous:5000.0\n",
      "Pasture/Hay:5000.0\n",
      "Cultivated Land:5000.0\n",
      "Woody Wetland:5000.0\n",
      "Emergent Herbaceous Wetlands:2095.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cu.indexed_dictionary)):\n",
    "    print(\"{}:{}\".format(cu.indexed_dictionary[i], buckets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_px, val_px, test_px = cu.train_val_test_split(pixels, 0.7, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38182\n",
      "13091\n",
      "5892\n"
     ]
    }
   ],
   "source": [
    "print(len(train_px))\n",
    "print(len(val_px))\n",
    "print(len(test_px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, SeparableConv2D\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras import Input\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(in_shape):\n",
    "    input_tensor = Input(shape = in_shape)\n",
    "    conv_1 = SeparableConv2D(64, kernel_size=(2,2), activation='elu') (input_tensor)\n",
    "    norm_1 = BatchNormalization() (conv_1)\n",
    "    dropout_1 = Dropout(rate=0.5) (norm_1)\n",
    "    pool = MaxPooling2D() (dropout_1)\n",
    "    flatten = Flatten() (pool)\n",
    "    dense = Dense(128, activation='elu') (flatten)\n",
    "    output = Dense(num_classes,activation='softmax') (dense)\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rs.ResnetBuilder.build_resnet_34(input_shape,num_classes)\n",
    "#model = make_model(input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1527/1527 [==============================] - 394s 258ms/step - loss: 2.6886 - acc: 0.2536 - val_loss: 4.3674 - val_acc: 0.0929\n",
      "Epoch 2/200\n",
      " 370/1527 [======>.......................] - ETA: 4:23 - loss: 2.2661 - acc: 0.2837"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=cu.tile_generator(landsat_datasets[1:2], sentinel_datasets[1:2], dem_datasets[1:2], label_dataset, tile_side, tile_side, train_px, batch_size), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=cu.tile_generator(landsat_datasets[1:2], sentinel_datasets[1:2], dem_datasets[1:2], label_dataset, tile_side, tile_side, val_px, batch_size),\n",
    "                    validation_steps=len(val_px) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator=cu.tile_generator(landsat_datasets[1:2], sentinel_datasets[1:2], dem_datasets[2:3], \n",
    "        label_dataset, tile_side, tile_side, test_px, batch_size), \n",
    "                        steps=len(test_px) // batch_size,\n",
    "                         verbose=1)\n",
    "\n",
    "eval_generator = cu.tile_generator(landsat_datasets[1:2], sentinel_datasets[1:2], dem_datasets[1:2], \n",
    "                                label_dataset, tile_side, tile_side, test_px, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = cu.pixel_balance(test_px, landsat_datasets[1:2], label_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty(predictions.shape)\n",
    "count = 0\n",
    "while count < len(labels):\n",
    "    image_b, label_b = next(eval_generator)\n",
    "    labels[count] = label_b\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_index = np.argmax(labels, axis=1)     \n",
    "pred_index = np.argmax(predictions, axis=1)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "cu.plot_confusion_matrix(label_index, pred_index, classes=np.array(list(class_names)),\n",
    "                      class_dict=cu.indexed_dictionary)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "cu.plot_confusion_matrix(label_index, pred_index, classes=np.array(list(class_names)),\n",
    "                      class_dict=cu.indexed_dictionary,\n",
    "                      normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cnn(model, landsat_datasets, sentinel_datasets, dem_datasets, label_dataset, tile_side, test_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
