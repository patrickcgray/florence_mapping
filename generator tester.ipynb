{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dict((\n",
    "(11, \"Water\"),\n",
    "(12, \"Snow/Ice\"),\n",
    "(21, \"Open Space Developed\"),\n",
    "(22, \"Low Intensity Developed\"),\n",
    "(23, \"Medium Intensity Developed\"),\n",
    "(24, \"High Intensity Developed\"),\n",
    "(31, \"Barren Land\"),\n",
    "(41, \"Deciduous Forest\"),\n",
    "(42, \"Evergreen Forest\"),\n",
    "(43, \"Mixed Forest\"),\n",
    "#(51, \"Dwarf Scrub/Shrub - ALASKA\"),\n",
    "(52, \"Scrub/Shrub\"),\n",
    "(71, \"Grassland / Herbaceous\"),\n",
    "#(72, \"Sedge / Herbaceous - ALASKA\"),\n",
    "#(73, \"Lichen / Herbaceous - ALASKA\"),\n",
    "#(74, \"Moss - ALASKA\"),\n",
    "(81, \"Pasture/Hay\"),\n",
    "(82, \"Cultivated Land\"),\n",
    "(90, \"Woody Wetland\"),\n",
    "(95, \"Emergent Herbaceous Wetlands\"),\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import adjust_band\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Proj, transform\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import classifier_utilities as cu\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset = rasterio.open('/deep_data/NLCD/NLCD_2016_Land_Cover_L48_20190424.img')\n",
    "\n",
    "l8_image_paths = [\n",
    "    '/deep_data/processed_landsat/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined.tif',\n",
    "    '/deep_data/processed_landsat/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined.tif',  \n",
    "    '/deep_data/processed_landsat/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined.tif',\n",
    "    '/deep_data/processed_landsat/LC08_CU_028012_20171103_20190429_C01_V01_SR_combined.tif',\n",
    "    '/deep_data/processed_landsat/LC08_CU_029011_20171018_20190429_C01_V01_SR_combined.tif'\n",
    "]\n",
    "\n",
    "s1_image_paths = [\n",
    "    '/deep_data/sentinel_sar/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined/aligned-LC08_CU_027012_20170907_20181121_C01_V01_SR_combined_SAR.tif',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined/aligned-LC08_CU_028011_20170907_20181130_C01_V01_SR_combined_SAR.tif',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined/aligned-LC08_CU_028012_20171002_20171019_C01_V01_SR_combined_SAR.tif',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028012_20171103_20190429_C01_V01_SR_combined/aligned-LC08_CU_028012_20171103_20190429_C01_V01_SR_combined_SAR.tif',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_029011_20171018_20190429_C01_V01_SR_combined/aligned-LC08_CU_029011_20171018_20190429_C01_V01_SR_combined_SAR.tif',\n",
    "]\n",
    "\n",
    "dem_image_paths = [\n",
    "    '/deep_data/sentinel_sar/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-79.69001_33.95762_-77.7672_35.51886__4500X4631_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-77.7672_35.00779_-75.79042_36.58923__4500X4262_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-79.69001_33.95762_-77.7672_35.51886__4500X4631_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028012_20171103_20190429_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-78.07896_33.69485_-76.14021_35.27466__4500X4248_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_029011_20171018_20190429_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-76.14021_34.71847_-74.14865_36.318__4500X4408_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "]\n",
    "\n",
    "\n",
    "landsat_datasets = []\n",
    "for fp in l8_image_paths:\n",
    "    landsat_datasets.append(rasterio.open(fp))\n",
    "    \n",
    "sentinel_datasets = []\n",
    "for fp in s1_image_paths:\n",
    "    sentinel_datasets.append(rasterio.open(fp))\n",
    "    \n",
    "dem_datasets = []\n",
    "for fp in dem_image_paths:\n",
    "    dem_datasets.append(rasterio.open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_generator(l8_image_datasets, s1_image_datasets, dem_image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size, merge=False):\n",
    "    ### this is a keras compatible data generator which generates data and labels on the fly \n",
    "    ### from a set of pixel locations, a list of image datasets, and a label dataset\n",
    "\n",
    "    c = r = 0\n",
    "    i = 0\n",
    "    \n",
    "    label_proj = Proj(label_dataset.crs)\n",
    "    l8_proj = Proj(l8_image_datasets[0].crs)\n",
    "    s1_proj = Proj(s1_image_datasets[0].crs)\n",
    "\n",
    "    # assuming all images have the same num of bands\n",
    "    l8_band_count = l8_image_datasets[0].count  \n",
    "    s1_band_count = s1_image_datasets[0].count\n",
    "    dem_band_count = dem_image_datasets[0].count\n",
    "    band_count = l8_band_count + s1_band_count + dem_band_count\n",
    "    class_count = len(class_names)\n",
    "    buffer = math.ceil(tile_height / 2)\n",
    "  \n",
    "    while True:\n",
    "        image_batch = np.zeros((batch_size, tile_height, tile_width, band_count-1)) # take one off because we don't want the QA band\n",
    "        label_batch = np.zeros((batch_size,class_count))\n",
    "        b = 0\n",
    "        while b < batch_size:\n",
    "            # if we're at the end  of the data just restart\n",
    "            if i >= len(pixel_locations):\n",
    "                i=0\n",
    "            r, c = pixel_locations[i][0]\n",
    "            dataset_index = pixel_locations[i][1]\n",
    "            i += 1\n",
    "            tile = l8_image_datasets[dataset_index].read(list(np.arange(1, l8_band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "            if np.amax(tile) == 0: # don't include if it is part of the image with no pixels\n",
    "                pass\n",
    "            elif np.isnan(tile).any() == True or -9999 in tile: \n",
    "                # we don't want tiles containing nan or -999 this comes from edges\n",
    "                # this also takes a while and is inefficient\n",
    "                pass\n",
    "            elif tile.shape != (l8_band_count, tile_width, tile_height):\n",
    "                #print('wrong shape')\n",
    "                #print(tile.shape)\n",
    "                # somehow we're randomly getting tiles without the correct dimensions\n",
    "                pass\n",
    "            elif np.isin(tile[7,:,:], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
    "                # make sure pixel doesn't contain clouds\n",
    "                # this is probably pretty inefficient but only checking width x height for each tile\n",
    "                # read more here: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
    "                #print('Found some cloud.')\n",
    "                #print(tile[7,:,:])\n",
    "                pass\n",
    "            else:\n",
    "                # set medium developed to high dev\n",
    "                #tile[tile == 3] = 2\n",
    "                \n",
    "                # taking off the QA band\n",
    "                tile = tile[0:7]\n",
    "                # reshape from raster format to image format and standardize according to image wide stats\n",
    "                reshaped_tile = (reshape_as_image(tile)  - 982.5) / 1076.5\n",
    "                \n",
    "                # L8, S1, and DEM are all the same projection and area otherwise this wouldn't work\n",
    "                # read in the sentinel-1 data \n",
    "                s1_tile = s1_image_datasets[dataset_index].read(list(np.arange(1, s1_band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "               \n",
    "                # read in the DEM data \n",
    "                dem_tile = dem_image_datasets[dataset_index].read(list(np.arange(1, dem_band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "                \n",
    "                if np.isnan(s1_tile).any() == True:\n",
    "                    pass\n",
    "                elif np.isnan(dem_tile).any() == True:\n",
    "                    pass\n",
    "                else:\n",
    "                    # reshape from raster format to image format and standardize according to image wide stats\n",
    "                    reshaped_s1_tile = (reshape_as_image(s1_tile)  - 0.10) / 0.088\n",
    "                    # reshape from raster format to image format and standardize according to image wide stats\n",
    "                    reshaped_dem_tile = (reshape_as_image(dem_tile)  - 31) / 16.5\n",
    "                    \n",
    "                    ### get label data\n",
    "                    # find gps of that pixel within the image\n",
    "                    (x, y) = l8_image_datasets[dataset_index].xy(r, c)\n",
    "\n",
    "                    # convert the point we're sampling from to the same projection as the label dataset if necessary\n",
    "                    if l8_proj != label_proj:\n",
    "                        x,y = transform(l8_proj,label_proj,x,y)\n",
    "\n",
    "                    # reference gps in label_image\n",
    "                    row, col = label_dataset.index(x,y)\n",
    "\n",
    "                    # find label\n",
    "                    # image is huge so we need this to just get a single position\n",
    "                    window = ((row, row+1), (col, col+1))\n",
    "                    data = label_dataset.read(1, window=window, masked=False, boundless=True)\n",
    "                    label = data[0,0]\n",
    "                    # if this label is part of the unclassified area then ignore\n",
    "                    if label == 0 or np.isnan(label).any() == True:\n",
    "                        pass\n",
    "                    else:                   \n",
    "                        # add label to the batch in a one hot encoding style\n",
    "                        label_batch[b][label] = 1\n",
    "                        image_batch[b] = np.dstack( ( reshaped_tile, reshaped_s1_tile, reshaped_dem_tile ) )\n",
    "                        \n",
    "                        b += 1\n",
    "        yield (image_batch, label_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gen_balanced_pixel_locations(image_datasets, train_count, label_dataset, merge=False):\n",
    "    ### this function pulls out a train_count + val_count number of random pixels from a list of raster datasets\n",
    "    ### and returns a list of training pixel locations and image indices \n",
    "    ### and a list of validation pixel locations and indices\n",
    "    \n",
    "    label_proj = Proj(label_dataset.crs)\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    train_pixels = []\n",
    "    \n",
    "    train_count_per_dataset = math.ceil(train_count / len(image_datasets))\n",
    "    for index, image_dataset in enumerate(tqdm(image_datasets)):\n",
    "        # how many points from each class\n",
    "        points_per_class = train_count_per_dataset // num_classes\n",
    "        \n",
    "        # get landsat boundaries in this image\n",
    "        # create approx dataset mask in geographic coords\n",
    "        # this fcn maps pixel locations in (row, col) coordinates to (x, y) spatial positions\n",
    "        raster_points = image_dataset.transform * (0, 0), image_dataset.transform * (image_dataset.width, 0), image_dataset.transform * (image_dataset.width, image_dataset.height), image_dataset.transform * (0, image_dataset.height)\n",
    "        l8_proj = Proj(image_dataset.crs)\n",
    "        new_raster_points = []\n",
    "        # convert the raster bounds from landsat into label crs\n",
    "        for x,y in raster_points:\n",
    "            new_raster_points.append(transform(l8_proj,label_proj,x,y))\n",
    "            # convert from crs into row, col in label image coords\n",
    "            row, col = label_dataset.index(x, y)\n",
    "            # don't forget row, col is actually y, x so need to swap it when we append\n",
    "            new_raster_points.append((col, row))\n",
    "            \n",
    "        # turn this into a polygon\n",
    "        raster_poly = Polygon(new_raster_points)\n",
    "        # Window.from_slices((row_start, row_stop), (col_start, col_stop))\n",
    "        masked_label_image = label_dataset.read(window=Window.from_slices((int(raster_poly.bounds[1]), int(raster_poly.bounds[3])), (int(raster_poly.bounds[0]), int(raster_poly.bounds[2]))))\n",
    "        if merge:\n",
    "            masked_label_image = merge_classes(masked_label_image)\n",
    "        # loop for each class\n",
    "        all_points_per_image = []\n",
    "        for cls in class_names:\n",
    "            cls = int(cls)\n",
    "            # mask the label subset image to each class\n",
    "            # pull out the indicies where the mask is true\n",
    "            rows,cols = np.where(masked_label_image[0] == cls)\n",
    "            all_locations = list(zip(rows,cols))\n",
    "       \n",
    "            # shuffle all locations\n",
    "            random.shuffle(all_locations)\n",
    "            # now convert to landsat image crs\n",
    "            # TODO need to time this to see if it is slow, can probably optimize\n",
    "            l8_points = []\n",
    "            # TODO Will probably need to catch this for classes smaller than the ideal points per class\n",
    "            if len(all_locations)!=0:\n",
    "                for r,c in all_locations[:points_per_class]:\n",
    "                # convert label row and col into label geographic space\n",
    "                    x,y = label_dataset.xy(r,c)\n",
    "                # go from label projection into landsat projection\n",
    "                    x,y = transform(label_proj, l8_proj,x,y)\n",
    "                # convert from landsat geographic space into row col\n",
    "                    r,c = image_dataset.index(x,y)\n",
    "                    l8_points.append((r,c))\n",
    "                all_points_per_image += l8_points\n",
    "\n",
    "        dataset_index_list = [index] * len(all_points_per_image)\n",
    "\n",
    "        dataset_pixels = list(zip(all_points_per_image, dataset_index_list))\n",
    "        train_pixels += dataset_pixels\n",
    "    random.shuffle(train_pixels)\n",
    "    return (train_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 1/5 [03:48<15:13, 228.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 2/5 [06:02<10:00, 200.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 3/5 [09:52<06:58, 209.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 4/5 [11:06<02:48, 168.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 5/5 [12:03<00:00, 135.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91154\n"
     ]
    }
   ],
   "source": [
    "train_pixels = fast_gen_balanced_pixel_locations(landsat_datasets, 100000, label_dataset, merge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_px = train_pixels[int(len(train_pixels)*0.3):]\n",
    "val_px = train_pixels[:int(len(train_pixels)*0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56698216\n"
     ]
    }
   ],
   "source": [
    "print(len(train_pixels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "epochs = 200\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# input image dimensions\n",
    "tile_side = 64\n",
    "img_rows, img_cols = tile_side, tile_side\n",
    "img_bands = landsat_datasets[0].count + sentinel_datasets[0].count + dem_datasets[0].count - 1\n",
    "\n",
    "input_shape = (img_rows, img_cols, img_bands)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(tile_side, kernel_size=(3, 3), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=tile_generator(landsat_datasets, sentinel_datasets, dem_datasets, label_dataset, tile_side, tile_side, train_px, batch_size, merge=False), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=cu.tile_generator(landsat_datasets, sentinel_datasets, dem_datasets, label_dataset, tile_side, tile_side, val_px, batch_size, merge=False),\n",
    "                    validation_steps=len(val_px) // batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
