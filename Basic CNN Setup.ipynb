{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN Framework for Landsat Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import adjust_band\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Proj, transform\n",
    "import random\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset = rasterio.open('/deep_data/landcover_reproject.tif')\n",
    "label_image = label_dataset.read()\n",
    "\n",
    "landsat_dataset = rasterio.open('/deep_data/LC08_CU_028012_20140814_20171017_C01_V01_SR/combined.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image projection:\n",
      "PROJCS[\"Albers\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378140,298.2569999999957,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]\n",
      "Labels projection:\n",
      "EPSG:32618\n"
     ]
    }
   ],
   "source": [
    "# What is the raster's projection?\n",
    "image_proj = landsat_dataset.crs # 4326\n",
    "print('Image projection:')\n",
    "print(image_proj)\n",
    "\n",
    "# What is the raster's projection?\n",
    "label_proj = label_dataset.crs\n",
    "print('Labels projection:')\n",
    "print(label_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator and Prep Fcns\n",
    "\n",
    "This is a typical Keras generator that I've written to allow it to ingest a set of random pixel locations so we can randomly sample throughout the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_generator(image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size):\n",
    "    ### this is a keras compatible data generator which generates data and labels on the fly \n",
    "    ### from a set of pixel locations, a list of image datasets, and a label dataset\n",
    "    \n",
    "    # pixel locations looks like [r, c, dataset_index]\n",
    "    label_image = label_dataset.read()\n",
    "    label_image[label_image == 255] = 1\n",
    "\n",
    "    c = r = 0\n",
    "    i = 0\n",
    "    \n",
    "    outProj = Proj(label_dataset.crs)\n",
    "\n",
    "    # assuming all images have the same num of bands\n",
    "    band_count = image_datasets[0].count\n",
    "    class_count = len(np.unique(label_image))\n",
    "    buffer = math.ceil(tile_height / 2)\n",
    "  \n",
    "    while True:\n",
    "        image_batch = np.zeros((batch_size, tile_height, tile_width, band_count))\n",
    "        label_batch = np.zeros((batch_size,class_count))\n",
    "        b = 0\n",
    "        while b < batch_size:\n",
    "            # if we're at the end  of the data just restart\n",
    "            if i >= len(pixel_locations):\n",
    "                i=0\n",
    "            c, r = pixel_locations[i][0]\n",
    "            dataset_index = pixel_locations[i][1]\n",
    "            i += 1\n",
    "            tile = image_datasets[dataset_index].read(list(np.arange(1, band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "            if np.amax(tile) == 0: # don't include if it is part of the image with no pixels\n",
    "                pass\n",
    "            elif np.isnan(tile).any() == True or -9999 in tile: \n",
    "                # we don't want tiles containing nan or -999 this comes from edges\n",
    "                # this also takes a while and is inefficient\n",
    "                pass\n",
    "            else:\n",
    "                tile = adjust_band(tile)\n",
    "                # reshape from raster format to image format\n",
    "                reshaped_tile = reshape_as_image(tile)\n",
    "                middle_pixel_r = r + np.ceil(tile_width/2)\n",
    "                middle_pixel_c = c + np.ceil(tile_height/2)\n",
    "\n",
    "                # find gps of that pixel within the image\n",
    "                (x, y) = image_datasets[dataset_index].xy(middle_pixel_r, middle_pixel_c)\n",
    "\n",
    "                # convert the point we're sampling from to the same projection as the label dataset if necessary\n",
    "                inProj = Proj(image_datasets[dataset_index].crs)\n",
    "                if inProj != outProj:\n",
    "                    x,y = transform(inProj,outProj,x,y)\n",
    "\n",
    "                # reference gps in label_image\n",
    "                row, col = label_dataset.index(x,y)\n",
    "\n",
    "                # find label\n",
    "                label = label_image[:, row, col]\n",
    "                # if this label is part of the unclassified area then ignore\n",
    "                if label == 0 or np.isnan(label).any() == True:\n",
    "                    pass\n",
    "                else:\n",
    "                    # add label to the batch in a one hot encoding style\n",
    "                    label_batch[b][label] = 1\n",
    "                    image_batch[b] = reshaped_tile\n",
    "                    b += 1\n",
    "        yield (image_batch, label_batch)\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes in a list of raster datasets and randomly samples `train_count` and `val_count` random pixels from each dataset.\n",
    "\n",
    "It doesn't sample within tile_size / 2 of the edge in order to avoid missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pixel_locations(image_datasets, train_count, val_count, tile_size):\n",
    "    ### this function pulls out a randomly selected number of pixels from a list of raster datasets\n",
    "    ### and returns a list of training pixel locations and image indices \n",
    "    ### and a list of validation pixel locations and indices\n",
    "    \n",
    "    ## future improvements could make this select classes evenly\n",
    "    train_pixels = []\n",
    "    val_pixels = []\n",
    "    \n",
    "    buffer = math.ceil(tile_size/2)\n",
    "    \n",
    "    total_count = train_count + val_count\n",
    "    for index, image_dataset in enumerate(image_datasets):\n",
    "        #randomly pick `count` num of pixels from each dataset\n",
    "        img_height, img_width = image_dataset.shape\n",
    "        \n",
    "        rows = range(0+buffer, img_height-buffer)\n",
    "        columns = range(0+buffer, img_width-buffer)\n",
    "        #rows_sub, columns_sub = zip(*random.sample(list(zip(rows, columns)), total_count))\n",
    "        \n",
    "        points = random.sample(set(itertools.product(rows, columns)), total_count)\n",
    "        \n",
    "        dataset_index = [index] * total_count\n",
    "        \n",
    "        dataset_pixels = list(zip(points, dataset_index))\n",
    "        \n",
    "        train_pixels += dataset_pixels[:train_count]\n",
    "        val_pixels += dataset_pixels[train_count:]\n",
    "        \n",
    "        \n",
    "    return (train_pixels, val_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out the generator and data prep functions\n",
    "\n",
    "Let's make sure all this data prep actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the training and validation pixel locations\n",
    "train_px, val_px = gen_pixel_locations([landsat_dataset], 100, 20, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image\n",
      "(2, 11, 11, 7)\n",
      "Label\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(2, 23)\n",
      "----\n",
      "Image\n",
      "(2, 11, 11, 7)\n",
      "Label\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(2, 23)\n",
      "----\n",
      "Image\n",
      "(2, 11, 11, 7)\n",
      "Label\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(2, 23)\n",
      "----\n",
      "Image\n",
      "(2, 11, 11, 7)\n",
      "Label\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(2, 23)\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# print out some image and label batches and check out their shapes\n",
    "im_batch = None\n",
    "\n",
    "count = 0\n",
    "for (im, label) in tile_generator([landsat_dataset], label_dataset, 11, 11, train_px, 2):\n",
    "    if count > 3:\n",
    "        break\n",
    "    print('Image')\n",
    "    print(im.shape)\n",
    "    print('Label')\n",
    "    print(label)\n",
    "    print(label.shape)\n",
    "    print('----')\n",
    "    count += 1\n",
    "    im_batch = im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually inspect an image patch\n",
    "\n",
    "While it shouldn't necessarily be recognizable it should look like it has data in it and that it varies somewhat from pixel to pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9516b8b240>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(18, 5)) \n",
    "\n",
    "axs.imshow(im_batch[0,:,:,1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get to the CNN Development!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# The GPU id to use\n",
    "# Patrick \"0\"\n",
    "# Feroze  \"1\"\n",
    "# Yousuf  \"2\"\n",
    "# Diego   \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do other imports now...\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep some of the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 7)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "label_image[label_image == 255] = 1\n",
    "num_classes = len(np.unique(label_image))\n",
    "epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 11, 11\n",
    "img_bands = landsat_dataset.count\n",
    "\n",
    "input_shape = (img_rows, img_cols, img_bands)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the model\n",
    "\n",
    "This is just a simple CNN model but it should be able to perform well above random when predicting landcover types if everything is correct thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 11)          704       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 22)          2200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 22)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 22)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 198)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 44)                8756      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 23)                1035      \n",
      "=================================================================\n",
      "Total params: 12,695\n",
      "Trainable params: 12,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(11, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(22, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(44, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the train/validation pixel locations to train with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_px, val_px = gen_pixel_locations(image_datasets=[landsat_dataset], \n",
    "                                       train_count=10000, val_count=50, tile_size=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up the remaining model hyperparameters and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "metrics=['accuracy']\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN THE MODEL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 19s 49ms/step - loss: 2.1090 - acc: 0.3197 - val_loss: 2.0758 - val_acc: 0.3200\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.9466 - acc: 0.3505 - val_loss: 1.9430 - val_acc: 0.3000\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.9167 - acc: 0.3611 - val_loss: 1.9167 - val_acc: 0.2200\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.8955 - acc: 0.3688 - val_loss: 1.9340 - val_acc: 0.3000\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.8713 - acc: 0.3730 - val_loss: 1.8560 - val_acc: 0.3800\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.8680 - acc: 0.3743 - val_loss: 1.8410 - val_acc: 0.3400\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.8622 - acc: 0.3745 - val_loss: 1.8593 - val_acc: 0.3000\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.8439 - acc: 0.3820 - val_loss: 1.8682 - val_acc: 0.3400\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.8404 - acc: 0.3821 - val_loss: 1.7670 - val_acc: 0.4200\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.8336 - acc: 0.3808 - val_loss: 1.8143 - val_acc: 0.3800\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.8270 - acc: 0.3847 - val_loss: 1.7985 - val_acc: 0.3600\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.8136 - acc: 0.3858 - val_loss: 1.7686 - val_acc: 0.3800\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.8113 - acc: 0.3846 - val_loss: 1.7919 - val_acc: 0.4000\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.8122 - acc: 0.3874 - val_loss: 1.7673 - val_acc: 0.3000\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7961 - acc: 0.3931 - val_loss: 1.7358 - val_acc: 0.4200\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7997 - acc: 0.3886 - val_loss: 1.7587 - val_acc: 0.4200\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7937 - acc: 0.3925 - val_loss: 1.7687 - val_acc: 0.3000\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7894 - acc: 0.3943 - val_loss: 1.7102 - val_acc: 0.4800\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7822 - acc: 0.3986 - val_loss: 1.6564 - val_acc: 0.4400\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7810 - acc: 0.3960 - val_loss: 1.7079 - val_acc: 0.4800\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7743 - acc: 0.3979 - val_loss: 1.7468 - val_acc: 0.3800\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7703 - acc: 0.4015 - val_loss: 1.7146 - val_acc: 0.4200\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7577 - acc: 0.4049 - val_loss: 1.7638 - val_acc: 0.4400\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7647 - acc: 0.4031 - val_loss: 1.7907 - val_acc: 0.3800\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7501 - acc: 0.4053 - val_loss: 1.7810 - val_acc: 0.3600\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7410 - acc: 0.4084 - val_loss: 1.8256 - val_acc: 0.4400\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7450 - acc: 0.4108 - val_loss: 1.9138 - val_acc: 0.2000\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 1.7387 - acc: 0.4087 - val_loss: 1.9119 - val_acc: 0.3000\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7296 - acc: 0.4128 - val_loss: 1.9000 - val_acc: 0.4000\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7233 - acc: 0.4137 - val_loss: 1.9159 - val_acc: 0.2800\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7238 - acc: 0.4120 - val_loss: 1.8179 - val_acc: 0.2200\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7146 - acc: 0.4158 - val_loss: 1.9068 - val_acc: 0.2200\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7086 - acc: 0.4174 - val_loss: 1.9404 - val_acc: 0.2800\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6998 - acc: 0.4224 - val_loss: 1.8661 - val_acc: 0.2200\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.7058 - acc: 0.4179 - val_loss: 2.0812 - val_acc: 0.2200\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6919 - acc: 0.4212 - val_loss: 2.0277 - val_acc: 0.4200\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6801 - acc: 0.4234 - val_loss: 1.9844 - val_acc: 0.3000\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6945 - acc: 0.4140 - val_loss: 1.9541 - val_acc: 0.4200\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6822 - acc: 0.4268 - val_loss: 2.0073 - val_acc: 0.1600\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6699 - acc: 0.4275 - val_loss: 2.0379 - val_acc: 0.2200\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6673 - acc: 0.4251 - val_loss: 1.9089 - val_acc: 0.3600\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6641 - acc: 0.4263 - val_loss: 2.3046 - val_acc: 0.2200\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6524 - acc: 0.4290 - val_loss: 2.0077 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6558 - acc: 0.4272 - val_loss: 1.8961 - val_acc: 0.3600\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6582 - acc: 0.4244 - val_loss: 2.0811 - val_acc: 0.3400\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6684 - acc: 0.4269 - val_loss: 2.1040 - val_acc: 0.2200\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6375 - acc: 0.4321 - val_loss: 2.1965 - val_acc: 0.2200\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6453 - acc: 0.4301 - val_loss: 2.1345 - val_acc: 0.3600\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6404 - acc: 0.4358 - val_loss: 2.3739 - val_acc: 0.2200\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 11s 28ms/step - loss: 1.6302 - acc: 0.4334 - val_loss: 2.2294 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94f925fe80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=tile_generator([landsat_dataset], label_dataset, 11, 11, train_px, batch_size), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=tile_generator([landsat_dataset], label_dataset, 11, 11, val_px, batch_size),\n",
    "                    validation_steps=len(val_px) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's evaluate the Model\n",
    "\n",
    "We'll just generate 500 test pixels to evaluate it on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_px, val_px = gen_pixel_locations([landsat_dataset], train_count=500, val_count=0, tile_size=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has a built in evaluate_generator function and because we told it above to use accuracy as a metric this function automatically outputs categorical accuracy which is what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 7s 372ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8179943680763244, 0.446000000834465]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator=tile_generator([landsat_dataset], label_dataset, 11, 11, test_px, batch_size), \n",
    "                        steps=len(test_px) // batch_size,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this simple model we're getting 37% accuracy across 23 classes which is well above the random accuracy which would be around 4% (aka 1/23). That means we're in business!\n",
    "\n",
    "### Evaluating the model ourselves\n",
    "\n",
    "If we wanted to run this evaluation and take a look at specific predictions and labels we can do that below (albeit more inefficiently) just to get an intuitive understanding of what is going wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 7s 374ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(generator=tile_generator([landsat_dataset], label_dataset, 11, 11, test_px, batch_size), \n",
    "                        steps=len(test_px) // batch_size,\n",
    "                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator = tile_generator([landsat_dataset], label_dataset, 11, 11, test_px, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty(predictions.shape)\n",
    "count = 0\n",
    "while count < len(test_px):\n",
    "    image_b, label_b = next(eval_generator)\n",
    "    labels[count] = label_b\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 23)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = np.argmax(labels, axis=1)     \n",
    "pred_index = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  6, 13, 13, 21, 10, 21, 13, 13, 10])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  6, 13, 13, 21,  6, 21,  4, 13, 13])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = np.zeros(pred_index.shape)\n",
    "correct_predictions[label_index == pred_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.446"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(correct_predictions) / len(test_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.08640160e-04, 4.84855846e-04, 1.17506471e-03, 4.00249753e-03,\n",
       "        1.74783133e-02, 1.57069713e-02, 5.41413985e-02, 4.38049552e-04,\n",
       "        6.92349672e-02, 8.39073583e-03, 2.51662791e-01, 2.36524008e-02,\n",
       "        1.62879273e-01, 2.23872915e-01, 1.16974287e-01, 3.02073397e-02,\n",
       "        2.93572055e-04, 6.55897369e-04, 3.75441625e-03, 4.95439512e-04,\n",
       "        5.92936715e-03, 7.78747909e-03, 3.73290706e-04],\n",
       "       [1.08968852e-04, 1.17197240e-04, 2.54674139e-03, 1.33019453e-02,\n",
       "        1.31508231e-01, 1.38075918e-01, 3.48803282e-01, 2.23744311e-04,\n",
       "        5.90150021e-02, 1.78924971e-03, 1.03307426e-01, 1.88870449e-02,\n",
       "        8.92392397e-02, 6.43814206e-02, 9.69998632e-03, 9.55410209e-03,\n",
       "        9.23416810e-05, 9.80259210e-05, 1.69915496e-03, 2.79611704e-04,\n",
       "        5.52317873e-03, 1.59120408e-03, 1.56987735e-04],\n",
       "       [1.03179598e-04, 8.97636637e-05, 1.08738088e-04, 9.06293455e-04,\n",
       "        1.90031494e-03, 1.43826776e-03, 6.46321522e-03, 5.25143041e-05,\n",
       "        2.95673925e-02, 6.44137105e-03, 2.42942497e-01, 1.04512842e-02,\n",
       "        1.43044546e-01, 3.93453568e-01, 1.24987110e-01, 2.92619299e-02,\n",
       "        7.12684705e-05, 2.15041437e-04, 1.84851664e-03, 1.34285219e-04,\n",
       "        2.31708167e-03, 4.12165932e-03, 8.01886126e-05]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  6, 13, 13, 21,  6, 21,  4, 13, 13, 13,  4, 21, 21, 21, 13, 10,\n",
       "        6, 13,  6])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions, axis=1)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now maybe more informatively let's build a confusion matrix using the scikit-learn function.\n",
    "\n",
    "Read the docs here and make this more informative by following some of their examples: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(label_index, pred_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  2,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  2],\n",
       "       [ 0,  0,  6,  0,  9,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  3],\n",
       "       [ 0,  0,  3,  3,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  3,  0, 32,  0,  0,  0,  8,  0,  0, 11,  0,  0,  0,  0,\n",
       "         0,  6],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  6,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  7,  0, 13,  0,  0,  0, 14,  0,  0, 29,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  6,  0,  0,  0,  0,  0,  0, 12,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  5,  0, 13,  0,  0,  0,  2,  0,  0, 26,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  3,  0, 15,  0,  0,  0,  6,  0,  3, 84,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  6,  0,  0,  0,  5,  0,  0, 11,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  8,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0, 11],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  3],\n",
       "       [ 0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  3],\n",
       "       [ 0,  0,  0,  0,  3,  0,  0,  0,  3,  0,  0,  3,  0,  0,  0,  0,\n",
       "         0, 84]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd64a01ca20>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_matrix, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd5e8e6aeb8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "norm_conf_matrix = conf_matrix / row_sums\n",
    "plt.matshow(norm_conf_matrix, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd64a04c7b8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.fill_diagonal(norm_conf_matrix, 0)\n",
    "plt.matshow(norm_conf_matrix, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
