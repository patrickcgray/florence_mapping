{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDE_DEVICE_ORDER\"] = \"PCI_B_US_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"3\"\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import adjust_band\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "from itertools import product\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Proj, transform\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "import datagenerator as dg\n",
    "from unet_model import unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset = rasterio.open('/deep_data/landcover_reproject.tif')\n",
    "label_image = label_dataset.read()\n",
    "\n",
    "image_paths = ['/deep_data/processed_landsat/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined.tif',\n",
    "               '/deep_data/processed_landsat/LC08_CU_028012_20140814_20171017_C01_V01_SR_combined.tif',\n",
    "               '/deep_data/processed_landsat/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined.tif',  \n",
    "               '/deep_data/processed_landsat/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined.tif']\n",
    "\n",
    "landsat_datasets = []\n",
    "for fp in image_paths:\n",
    "    landsat_datasets.append(rasterio.open(fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_tile_generator(image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size):\n",
    "    ### this is a keras compatible data generator which generates data and labels on the fly \n",
    "    ### from a set of pixel locations, a list of image datasets, and a label dataset\n",
    "    # pixel locations looks like [r, c, dataset_index]\n",
    "    label_image = label_dataset.read()\n",
    "    label_image[label_image == 255] = 1\n",
    "    c = r = 0\n",
    "    i = 0\n",
    "    outProj = Proj(label_dataset.crs)\n",
    "    # assuming all images have the same num of bands\n",
    "    band_count = image_datasets[0].count\n",
    "    class_count = len(np.unique(label_image))\n",
    "    buffer = math.ceil(tile_height / 2)\n",
    "  \n",
    "    while True:\n",
    "        image_batch = np.zeros((batch_size, tile_height, tile_width, band_count-1)) # take one off because we don't want the QA band\n",
    "        label_batch = np.zeros((batch_size, tile_height, tile_width, class_count))\n",
    "        b = 0\n",
    "        while b < batch_size:\n",
    "            # if we're at the end  of the data just restart\n",
    "            if i >= len(pixel_locations):\n",
    "                i=0\n",
    "            #GET PIXELS\n",
    "            c, r = pixel_locations[i][0]\n",
    "            dataset_index = pixel_locations[i][1]\n",
    "            i += 1\n",
    "            #TILE PROCESSING\n",
    "            tile = image_datasets[dataset_index].read(list(np.arange(1, band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "            if np.amax(tile) == 0: # don't include if it is part of the image with no pixels\n",
    "                pass\n",
    "            elif np.isnan(tile).any() == True or -9999 in tile: \n",
    "                # we don't want tiles containing nan or -999 this comes from edges\n",
    "                # this also takes a while and is inefficient\n",
    "                pass\n",
    "            elif tile.shape != (band_count, tile_width, tile_height):\n",
    "                print('wrong shape')\n",
    "                print(tile.shape)\n",
    "                # somehow we're randomly getting tiles without the correct dimensions\n",
    "                pass\n",
    "            elif np.isin(tile[7,:,:], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
    "                # make sure pixel doesn't contain clouds\n",
    "                # this is probably pretty inefficient but only checking width x height for each tile\n",
    "                # read more here: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
    "                #print('Found some cloud.')\n",
    "                #print(tile[7,:,:])\n",
    "                pass\n",
    "            else:\n",
    "                tile = adjust_band(tile[0:7])\n",
    "                # reshape from raster format to image format\n",
    "                train_tile = reshape_as_image(tile)\n",
    "                # LABEL TILE PROCESSING\n",
    "                #Transforms train pixel location to equivalent label pixel location\n",
    "                outProj = Proj(label_dataset.crs)\n",
    "                inProj = Proj(image_datasets[dataset_index].crs)\n",
    "                (x, y) = image_datasets[dataset_index].xy(r, c)\n",
    "                if inProj != outProj:\n",
    "                    x,y = transform(inProj,outProj,x,y) \n",
    "                #use pixel to create tile\n",
    "                row, col = label_dataset.index(x, y)\n",
    "                label_tile = label_dataset.read(1, window=Window(row-buffer, col-buffer, tile_width, tile_height))\n",
    "                label_masks = np.zeros((tile_height, tile_width, class_count))\n",
    "                #use tile to make the masks\n",
    "                for h in range(tile_height):\n",
    "                    tileRow = row-buffer+h\n",
    "                    for w in range(tile_width):\n",
    "                        tileCol = col-buffer+w\n",
    "                        for i in range(class_count):\n",
    "                            if(label_image[0, tileRow, tileCol] == i):\n",
    "                                label_masks[h][w][i] = 1\n",
    "                            else:\n",
    "                                label_masks[h][w][i] = 0               \n",
    "                label_batch[b] = label_masks;\n",
    "                image_batch[b] = train_tile\n",
    "                b += 1\n",
    "                yield (image_batch, label_batch)\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 7)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "label_image[label_image == 255] = 1\n",
    "num_classes = len(np.unique(label_image))\n",
    "epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "tile_side = 64\n",
    "img_rows, img_cols = tile_side, tile_side\n",
    "img_bands = landsat_datasets[0].count - 1\n",
    "\n",
    "input_shape = (img_rows, img_cols, img_bands)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_px, val_px = dg.gen_pixel_locations(landsat_datasets, 100, 50, tile_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 1/23\n",
    "weight_list = []\n",
    "for i in range(num_classes):\n",
    "    weight_list.append(weight)\n",
    "    \n",
    "model = unet_model(n_classes=num_classes, im_sz=tile_side, n_channels=7, n_filters_start=32, growth_factor=2, upconv=True, class_weights=weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.6569\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5054\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.3484\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.2151\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.1435\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.1266\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.0859\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.0761\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.0983\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.1181\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.1252\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.1037\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.0861\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0659\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.0749\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.0795\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.1005\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.0908\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0819\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0601\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0674\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0746\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0885\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0787\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.0763\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0752\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.0603\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.0716\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.0945\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0825\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0840\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.0874\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0583\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0662\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0802\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.0787\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.0760\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.0839\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0528\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.0556\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0690\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0741\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.0675\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.0652\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.0466\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.0512\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0564\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0657\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.0613\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0de8a8db00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=fcn_tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, train_px, batch_size), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1)\n",
    "\n",
    "                    \n",
    "#validation_data=fcn_tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, val_px, batch_size),\n",
    "#validation_steps=len(val_px) // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
