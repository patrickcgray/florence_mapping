{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDE_DEVICE_ORDER\"] = \"PCI_B_US_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"3\"\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import adjust_band\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "from itertools import product\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Proj, transform\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "import datagenerator as dg\n",
    "import kerasd-\n",
    "from unet_model import unet_model\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset = rasterio.open('/deep_data/landcover_reproject.tif')\n",
    "label_image = label_dataset.read()\n",
    "\n",
    "image_paths = ['/deep_data/processed_landsat/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined.tif',\n",
    "               '/deep_data/processed_landsat/LC08_CU_028012_20140814_20171017_C01_V01_SR_combined.tif',\n",
    "               '/deep_data/processed_landsat/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined.tif',  \n",
    "               '/deep_data/processed_landsat/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined.tif']\n",
    "\n",
    "landsat_datasets = []\n",
    "for fp in image_paths:\n",
    "    landsat_datasets.append(rasterio.open(fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_tile_generator(image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size):\n",
    "    ### this is a keras compatible data generator which generates data and labels on the fly \n",
    "    ### from a set of pixel locations, a list of image datasets, and a label dataset\n",
    "    # pixel locations looks like [r, c, dataset_index]\n",
    "    label_image = label_dataset.read()\n",
    "    label_image[label_image == 255] = 1\n",
    "    c = r = 0\n",
    "    i = 0\n",
    "    outProj = Proj(label_dataset.crs)\n",
    "    # assuming all images have the same num of bands\n",
    "    band_count = image_datasets[0].count\n",
    "    class_count = len(np.unique(label_image))\n",
    "    buffer = math.ceil(tile_height / 2)\n",
    "  \n",
    "    while True:\n",
    "        image_batch = np.zeros((batch_size, tile_height, tile_width, band_count-1)) # take one off because we don't want the QA band\n",
    "        label_batch = np.zeros((batch_size, tile_height, tile_width, class_count))\n",
    "        b = 0\n",
    "        while b < batch_size:\n",
    "            # if we're at the end  of the data just restart\n",
    "            if i >= len(pixel_locations):\n",
    "                i=0\n",
    "            #GET PIXELS\n",
    "            c, r = pixel_locations[i][0]\n",
    "            dataset_index = pixel_locations[i][1]\n",
    "            i += 1\n",
    "            #TILE PROCESSING\n",
    "            tile = image_datasets[dataset_index].read(list(np.arange(1, band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "            if np.amax(tile) == 0: # don't include if it is part of the image with no pixels\n",
    "                pass\n",
    "            elif np.isnan(tile).any() == True or -9999 in tile: \n",
    "                # we don't want tiles containing nan or -999 this comes from edges\n",
    "                # this also takes a while and is inefficient\n",
    "                pass\n",
    "            elif tile.shape != (band_count, tile_width, tile_height):\n",
    "                print('wrong shape')\n",
    "                print(tile.shape)\n",
    "                # somehow we're randomly getting tiles without the correct dimensions\n",
    "                pass\n",
    "            elif np.isin(tile[7,:,:], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
    "                # make sure pixel doesn't contain clouds\n",
    "                # this is probably pretty inefficient but only checking width x height for each tile\n",
    "                # read more here: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
    "                #print('Found some cloud.')\n",
    "                #print(tile[7,:,:])\n",
    "                pass\n",
    "            else:\n",
    "                tile = adjust_band(tile[0:7])\n",
    "                # reshape from raster format to image format\n",
    "                train_tile = reshape_as_image(tile)\n",
    "                # LABEL TILE PROCESSING\n",
    "                #Transforms train pixel location to equivalent label pixel location\n",
    "                outProj = Proj(label_dataset.crs)\n",
    "                inProj = Proj(image_datasets[dataset_index].crs)\n",
    "                (x, y) = image_datasets[dataset_index].xy(r, c)\n",
    "                if inProj != outProj:\n",
    "                    x,y = transform(inProj,outProj,x,y) \n",
    "                #use pixel to create tile\n",
    "                row, col = label_dataset.index(x, y)\n",
    "                label_tile = label_dataset.read(1, window=Window(row-buffer, col-buffer, tile_width, tile_height))\n",
    "                label_masks = np.zeros((tile_height, tile_width, class_count))\n",
    "                #use tile to make the masks\n",
    "                for h in range(tile_height):\n",
    "                    tileRow = row-buffer+h\n",
    "                    for w in range(tile_width):\n",
    "                        tileCol = col-buffer+w\n",
    "                        for i in range(class_count):\n",
    "                            if(label_image[0, tileRow, tileCol] == i):\n",
    "                                label_masks[h][w][i] = 1\n",
    "                            else:\n",
    "                                label_masks[h][w][i] = 0               \n",
    "                label_batch[b] = label_masks;\n",
    "                image_batch[b] = train_tile\n",
    "                b += 1\n",
    "                yield (image_batch, label_batch)\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 7)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "label_image[label_image == 255] = 1\n",
    "num_classes = len(np.unique(label_image))\n",
    "epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "tile_side = 64\n",
    "img_rows, img_cols = tile_side, tile_side\n",
    "img_bands = landsat_datasets[0].count - 1\n",
    "\n",
    "input_shape = (img_rows, img_cols, img_bands)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_px, val_px = dg.gen_pixel_locations(landsat_datasets, 1000, 500, tile_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 1/23\n",
    "weight_list = []\n",
    "for i in range(num_classes):\n",
    "    weight_list.append(weight)\n",
    "    \n",
    "model = unet_model(n_classes=num_classes, im_sz=tile_side, n_channels=7, n_filters_start=32, growth_factor=2, upconv=True, class_weights=weight_list)\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "metrics=['accuracy']\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 24s 591ms/step - loss: 0.8039 - acc: 0.0777 - val_loss: 1.3179 - val_acc: 0.0840\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 1.0916 - acc: 0.1104 - val_loss: 1.2498 - val_acc: 0.0838\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 14s 358ms/step - loss: 1.0850 - acc: 0.1147 - val_loss: 1.6050 - val_acc: 0.1086\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 15s 370ms/step - loss: 0.9785 - acc: 0.1193 - val_loss: 1.8757 - val_acc: 0.1107\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 15s 369ms/step - loss: 1.1279 - acc: 0.1443 - val_loss: 2.2908 - val_acc: 0.1234\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 14s 362ms/step - loss: 0.8563 - acc: 0.1121 - val_loss: 1.5896 - val_acc: 0.0906\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 15s 374ms/step - loss: 0.9043 - acc: 0.1228 - val_loss: 1.4344 - val_acc: 0.0899\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 14s 361ms/step - loss: 0.9513 - acc: 0.1369 - val_loss: 1.7152 - val_acc: 0.1009\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 14s 356ms/step - loss: 0.8947 - acc: 0.1374 - val_loss: 1.9544 - val_acc: 0.1206\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 14s 353ms/step - loss: 1.0269 - acc: 0.1635 - val_loss: 2.1134 - val_acc: 0.1265\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 14s 359ms/step - loss: 0.8149 - acc: 0.1362 - val_loss: 1.7085 - val_acc: 0.0947\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 15s 363ms/step - loss: 0.9083 - acc: 0.1584 - val_loss: 1.6025 - val_acc: 0.0914\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 14s 354ms/step - loss: 0.9054 - acc: 0.1614 - val_loss: 1.9358 - val_acc: 0.1040\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 14s 355ms/step - loss: 0.8147 - acc: 0.1496 - val_loss: 2.1524 - val_acc: 0.1218\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 14s 359ms/step - loss: 0.9843 - acc: 0.1854 - val_loss: 2.4807 - val_acc: 0.1313\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.7860 - acc: 0.1482 - val_loss: 1.7467 - val_acc: 0.0964\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 14s 352ms/step - loss: 0.8650 - acc: 0.1711 - val_loss: 2.0881 - val_acc: 0.0913\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 14s 360ms/step - loss: 0.8919 - acc: 0.1793 - val_loss: 2.2944 - val_acc: 0.1122\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 14s 354ms/step - loss: 0.8232 - acc: 0.1673 - val_loss: 2.6111 - val_acc: 0.1237\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 14s 352ms/step - loss: 0.9514 - acc: 0.1929 - val_loss: 2.8555 - val_acc: 0.1289\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 14s 355ms/step - loss: 0.8749 - acc: 0.1725 - val_loss: 3.3397 - val_acc: 0.0843\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 14s 356ms/step - loss: 0.8786 - acc: 0.1695 - val_loss: 2.4422 - val_acc: 0.0881\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 14s 355ms/step - loss: 0.7855 - acc: 0.1643 - val_loss: 2.2018 - val_acc: 0.1165\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.7008 - acc: 0.1513 - val_loss: 2.4385 - val_acc: 0.1275\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 14s 358ms/step - loss: 0.8973 - acc: 0.1965 - val_loss: 2.9735 - val_acc: 0.1330\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 14s 354ms/step - loss: 0.7029 - acc: 0.1604 - val_loss: 2.2449 - val_acc: 0.0928\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 0.7531 - acc: 0.1746 - val_loss: 2.1896 - val_acc: 0.0914\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 14s 357ms/step - loss: 0.7683 - acc: 0.1869 - val_loss: 3.0991 - val_acc: 0.0995\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 14s 357ms/step - loss: 0.6853 - acc: 0.1753 - val_loss: 3.2856 - val_acc: 0.1144\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 14s 361ms/step - loss: 0.8019 - acc: 0.2084 - val_loss: 3.5759 - val_acc: 0.1166\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 14s 353ms/step - loss: 0.6828 - acc: 0.1854 - val_loss: 2.7494 - val_acc: 0.0850\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 14s 358ms/step - loss: 0.7306 - acc: 0.1981 - val_loss: 2.4618 - val_acc: 0.0851\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.6930 - acc: 0.1938 - val_loss: 3.1070 - val_acc: 0.0979\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 14s 350ms/step - loss: 0.6599 - acc: 0.1873 - val_loss: 3.4741 - val_acc: 0.1098\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 14s 358ms/step - loss: 0.7563 - acc: 0.1941 - val_loss: 4.9507 - val_acc: 0.1142\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 14s 357ms/step - loss: 0.5749 - acc: 0.1335 - val_loss: 3.8096 - val_acc: 0.0848\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 14s 353ms/step - loss: 0.6305 - acc: 0.1509 - val_loss: 2.5037 - val_acc: 0.0931\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 14s 356ms/step - loss: 0.6010 - acc: 0.1474 - val_loss: 3.6176 - val_acc: 0.0967\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 14s 359ms/step - loss: 0.5017 - acc: 0.1294 - val_loss: 3.5985 - val_acc: 0.1108\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 14s 355ms/step - loss: 0.6090 - acc: 0.1536 - val_loss: 4.2567 - val_acc: 0.1166\n",
      "Epoch 41/50\n",
      " 9/40 [=====>........................] - ETA: 8s - loss: 0.4326 - acc: 0.1252"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=fcn_tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, train_px, batch_size), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=fcn_tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, val_px, batch_size),\n",
    "                    validation_steps=len(val_px) // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011048634769394994"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator=fcn_tile_generator(landsat_datasets, label_dataset,tile_side , tile_side, val_px, batch_size), \n",
    "                        steps=len(val_px) // batch_size,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
