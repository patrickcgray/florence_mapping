{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Viz Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import adjust_band\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Proj, transform\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('rcnn/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import utilities as util\n",
    "import importlib\n",
    "import rnn_tiles\n",
    "import rnn_pixels\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression,Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/host/Code/florence_mapping/utilities.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rnn_pixels)\n",
    "importlib.reload(rnn_tiles)\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/landcover/NLCD_2011_Land_Cover_L48_20190424.img')\n",
    "canopy_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/canopy/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img')\n",
    "\n",
    "class_dict = util.indexed_dictionary\n",
    "\n",
    "tiles = {}\n",
    "landsat_datasets = {}\n",
    "tiles['028012'] = ['20110324', '20110612', '20110831', '20111103']\n",
    "tiles['029011'] = ['20110308', '20110425', '20110831', '20111103']\n",
    "tiles['028011'] = ['20110308', '20110628', '20110831', '20111103']\n",
    "#tiles['028012'] = ['20110831']\n",
    "#tiles['029011'] = ['20110831']\n",
    "#tiles['028011'] = ['20110831']\n",
    "for tile_number, dates in tiles.items():\n",
    "    tile_datasets = []\n",
    "    l8_image_paths = []\n",
    "    for date in dates:\n",
    "        l8_image_paths.append('/deep_data/recurrent_data/tile{}/combined/combined{}.tif'.format(tile_number, date))\n",
    "    for fp in l8_image_paths:\n",
    "        tile_datasets.append(rasterio.open(fp))\n",
    "    landsat_datasets[tile_number] = tile_datasets\n",
    "    \n",
    "tile_size = 5\n",
    "tile_list = ['028012', '029011', '028011']\n",
    "class_count = len(class_dict)\n",
    "clean_pixels_count = 3000000\n",
    "max_count_per_class = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning balanced data creation.\n"
     ]
    }
   ],
   "source": [
    "sk_data, sk_labels, class_count_dict = rnn_pixels.balanced_pix_data(landsat_datasets, lc_labels, canopy_labels, tile_size, tile_list, \n",
    "                           clean_pixels_count, class_count, max_count_per_class, class_dict, buffer_pix=1)\n",
    "\n",
    "sk_data.shape, sk_labels.shape, class_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_train_test_split(max_per_test_class, max_per_train_class, sk_data, sk_labels):\n",
    "\n",
    "    # Create Test and Train Count Dictionary\n",
    "    test_class_count_dict = {}\n",
    "    train_class_count_dict = {}\n",
    "    for key in class_dict:\n",
    "        test_class_count_dict[key] = 0 \n",
    "        train_class_count_dict[key] = 0\n",
    "\n",
    "    # Training \n",
    "    sk_data_test = []\n",
    "    sk_labels_test = []\n",
    "\n",
    "    #Testing\n",
    "    sk_data_train = []\n",
    "    sk_labels_train = []\n",
    "\n",
    "    for x in range(len(sk_data)):\n",
    "        pop_data = sk_data[x]\n",
    "        pop_label = sk_labels[x]\n",
    "        pop_class = pop_label[0]\n",
    "        if test_class_count_dict[pop_class] < max_per_test_class:\n",
    "            sk_data_test.append(pop_data)\n",
    "            sk_labels_test.append(pop_label)\n",
    "            test_class_count_dict[pop_class] += 1\n",
    "        elif train_class_count_dict[pop_class] < max_per_train_class:\n",
    "            sk_data_train.append(pop_data)\n",
    "            sk_labels_train.append(pop_label)\n",
    "            train_class_count_dict[pop_class] += 1\n",
    "\n",
    "    return(np.array(sk_data_train),np.array(sk_labels_train), np.array(sk_data_test), np.array(sk_labels_test),train_class_count_dict,test_class_count_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_per_test_class = 100\n",
    "max_per_train_class = 300\n",
    "\n",
    "sk_data_train, sk_labels_train, sk_data_test, sk_labels_test, train_class_count_dict,test_class_count_dict = sk_train_test_split(max_per_test_class, max_per_train_class, sk_data, sk_labels)\n",
    "\n",
    "\n",
    "print(test_class_count_dict)\n",
    "print(train_class_count_dict)\n",
    "print(sk_data_train.shape)\n",
    "print(sk_data_test.shape)\n",
    "print(sk_labels_train.shape)\n",
    "print(sk_labels_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Input Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_pixels_count_train = 2000000\n",
    "\n",
    "max_count_per = []\n",
    "scores = []\n",
    "for x in range(10,900,10):\n",
    "    max_count_per.append(x)\n",
    "    \n",
    "    # Split\n",
    "    max_per_test_class = 100\n",
    "    max_per_train_class = x\n",
    "\n",
    "    sk_data_train, sk_labels_train, sk_data_test, sk_labels_test, train_class_count_dict,test_class_count_dict = sk_train_test_split(max_per_test_class, max_per_train_class, sk_data, sk_labels)\n",
    "\n",
    "    \n",
    "    # Data\n",
    "    landcover_train = sk_labels_train[:,0]\n",
    "    canopy_train = sk_labels_train[:,1]\n",
    "    tiles_train = sk_data_train\n",
    "    tiles_test = sk_data_test\n",
    "    landcover_test = sk_labels_test[:,0]\n",
    "    canopy_test = sk_labels_test[:,1]\n",
    "    \n",
    "    # Model\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(tiles_train,landcover_train.astype('int'))\n",
    "    pred_clf = clf.predict(tiles_test)\n",
    "    scores.append(accuracy_score(landcover_test.astype('int'),pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.figure(1);\n",
    "plt.plot(max_count_per,scores)\n",
    "plt.xlabel('Size of Test Data')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('0 to 1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep\n",
    "landcover_train = sk_labels_train[:,0]\n",
    "canopy_train = sk_labels_train[:,1]\n",
    "tiles_train = sk_data_train\n",
    "\n",
    "landcover_test = sk_labels_test[:,0]\n",
    "canopy_test = sk_labels_test[:,1]\n",
    "tiles_test = sk_data_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Landcover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "clf = svm.SVC()\n",
    "clf.fit(tiles_train,landcover_train.astype('int'))\n",
    "pred_clf = clf.predict(tiles_test)\n",
    "print('Classification Report')\n",
    "print(classification_report(landcover_test.astype('int'), pred_clf))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(landcover_test.astype('int'), pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC (Landcover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC\n",
    "rfc = RandomForestClassifier(n_estimators = 350)\n",
    "rfc.fit(tiles_train,landcover_train.astype('int'))\n",
    "pred_rfc = rfc.predict(tiles_test)\n",
    "print('Classification Report')\n",
    "print(classification_report(landcover_test.astype('int'), pred_rfc))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(landcover_test.astype('int'), pred_rfc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (Landcover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 23)\n",
    "knn.fit(tiles_train,landcover_train.astype('int'))\n",
    "pred_knn = knn.predict(tiles_test)\n",
    "print('Classification Report')\n",
    "print(classification_report(landcover_test.astype('int'), pred_knn))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(landcover_test.astype('int'), pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (Canopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(tiles_train,canopy_train)\n",
    "predLR = LR.predict(tiles_test)\n",
    "\n",
    "print('Mean Absolute Error:',metrics.mean_absolute_error(canopy_test, predLR))\n",
    "print('Mean Squared Error:',metrics.mean_squared_error(canopy_test, predLR))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(canopy_test,predLR)))\n",
    "\n",
    "%matplotlib inline \n",
    "plt.figure(1);\n",
    "plt.scatter(canopy_test, predLR, alpha = .1)\n",
    "plt.plot(canopy_test, canopy_test,color = 'r')\n",
    "plt.xlabel('Canopy Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Linear Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso (Canopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las= Lasso(alpha = 0.05)\n",
    "las.fit(tiles_train,canopy_train)\n",
    "predLas = las.predict(tiles_test)\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:',metrics.mean_absolute_error(canopy_test, predLas))\n",
    "print('Mean Squared Error:',metrics.mean_squared_error(canopy_test, predLas))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(canopy_test, predLas)))\n",
    "\n",
    "%matplotlib inline \n",
    "plt.figure(1);\n",
    "plt.scatter(canopy_test, predLas)\n",
    "plt.plot(canopy_test, canopy_test,color = 'r')\n",
    "plt.xlabel('Canopy Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(tiles_train,canopy_train)\n",
    "pred_rfr = rfr.predict(tiles_test)\n",
    "\n",
    "print('Mean Absolute Error:',metrics.mean_absolute_error(canopy_test, pred_rfr))\n",
    "print('Mean Squared Error:',metrics.mean_squared_error(canopy_test, pred_rfr))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(canopy_test,pred_rfr)))\n",
    "\n",
    "%matplotlib inline \n",
    "plt.figure(1);\n",
    "plt.scatter(canopy_test, pred_rfr, alpha = .1)\n",
    "plt.plot(canopy_test, canopy_test,color = 'r')\n",
    "plt.xlabel('Canopy Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Random Forest Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Signatures\n",
    "\n",
    "Landsat 5 specs from USGS https://www.usgs.gov/land-resources/nli/landsat/landsat-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=[8,8])\n",
    "\n",
    "# numbers 1-8\n",
    "band_count = np.arange(1,29)\n",
    "\n",
    "for class_index in class_dict:\n",
    "    band_intensity = np.mean(sk_data[sk_labels==class_index, :], axis=0)\n",
    "    ax.plot(band_count, band_intensity, label=class_dict[class_index])\n",
    "# plot them as lines\n",
    "\n",
    "# Add some axis labels\n",
    "ax.set_xlabel('Band #')\n",
    "ax.set_ylabel('Reflectance Value')\n",
    "# Add a title\n",
    "ax.set_title('Band Intensities Full Overview')\n",
    "ax.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_data.reshape(-1,4,7).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=[8,8])\n",
    "\n",
    "# numbers 1-8\n",
    "band_count = np.arange(1,8)\n",
    "\n",
    "for class_index in class_dict:\n",
    "    # reshape into 4 time steps of \n",
    "    time_steps = len(tiles['028012'])\n",
    "    band_intensity = np.mean(sk_data[sk_labels==class_index, :].reshape(-1,time_steps,7), axis=(0,1))\n",
    "    ax.plot(band_count, band_intensity, label=class_dict[class_index])\n",
    "# plot them as lines\n",
    "\n",
    "# Add some axis labels\n",
    "ax.set_xlabel('Band #')\n",
    "ax.set_ylabel('Reflectance Value')\n",
    "# Add a title\n",
    "ax.set_title('Band Intensities Full Overview')\n",
    "ax.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "\n",
    "image_avgs = []    \n",
    "for class_index in class_dict:\n",
    "    image_avgs.append(np.mean(sk_data[sk_labels==class_index, :], axis=0))\n",
    "\n",
    "ytdist = np.array(image_avgs)\n",
    "\n",
    "Z = hierarchy.linkage(ytdist, 'single')\n",
    "plt.figure(figsize=(10,10))\n",
    "dn = hierarchy.dendrogram(Z, labels=list(class_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(sk_data)\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "df = pd.DataFrame({'pca-one':pca_result[:,0],'pca-two':pca_result[:,1],'pca-three':pca_result[:,2], 'y' : sk_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", len(np.unique(sk_labels))),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=df[\"pca-one\"], \n",
    "    ys=df[\"pca-two\"], \n",
    "    zs=df[\"pca-three\"], \n",
    "    c=df[\"y\"], \n",
    "    cmap='tab10'\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "N = 10000\n",
    "data_subset = sk_data[:N, :]\n",
    "\n",
    "time_start = time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(data_subset)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df.loc[:N-1,:].copy()\n",
    "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "df_subset['tsne-2d-two'] = tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", len(np.unique(sk_labels))),\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
