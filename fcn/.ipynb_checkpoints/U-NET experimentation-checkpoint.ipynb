{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dict((\n",
    "(0,  'Background'),\n",
    "(1, 'Unclassified'),\n",
    "(2, 'High Intensity Developed'),\n",
    "(3, 'Medium Intensity Developed'),\n",
    "(4, 'Low Intensity Developed'),\n",
    "(5, 'Open Space Developed'),\n",
    "(6, 'Cultivated Land'),\n",
    "(7, 'Pasture/Hay'),\n",
    "(8, 'Grassland'),\n",
    "(9, 'Deciduous Forest'),\n",
    "(10, 'Evergreen Forest'),\n",
    "(11, 'Mixed Forest'),\n",
    "(12, 'Scrub/Shrub'),\n",
    "(13, 'Palustrine Forested Wetland'),\n",
    "(14, 'Palustrine Scrub/Shrub Wetland'),\n",
    "(15, 'Palustrine Emergent Wetland'),\n",
    "(16, 'Estuarine Forested Wetland'),\n",
    "(17, 'Estuarine Scrub/Shrub Wetland'),\n",
    "(18, 'Estuarine Emergent Wetland'),\n",
    "(19, 'Unconsolidated Shore'),\n",
    "(20, 'Bare Land'),\n",
    "(21, 'Water'),\n",
    "(22, 'Palustrine Aquatic Bed'),\n",
    "(23, 'Estuarine Aquatic Bed'),\n",
    "(24, 'Tundra'),\n",
    "(25, 'Snow/Ice')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import adjust_band\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Proj, transform\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import classifier_utilities as cu\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset = rasterio.open('/deep_data/landcover_reproject.tif')\n",
    "label_image = label_dataset.read()\n",
    "\n",
    "l8_image_paths = [\n",
    "    '/deep_data/processed_landsat/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined.tif',\n",
    "    '/deep_data/processed_landsat/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined.tif',  \n",
    "    '/deep_data/processed_landsat/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined.tif',\n",
    "    '/deep_data/processed_landsat/LC08_CU_028012_20171103_20190429_C01_V01_SR_combined.tif',\n",
    "    '/deep_data/processed_landsat/LC08_CU_029011_20171018_20190429_C01_V01_SR_combined.tif'\n",
    "]\n",
    "\n",
    "s1_image_paths = [\n",
    "    '/deep_data/sentinel_sar/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined/aligned-LC08_CU_027012_20170907_20181121_C01_V01_SR_combined_SAR.tif',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined/aligned-LC08_CU_028011_20170907_20181130_C01_V01_SR_combined_SAR.tif',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined/aligned-LC08_CU_028012_20171002_20171019_C01_V01_SR_combined_SAR.tif',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028012_20171103_20190429_C01_V01_SR_combined/aligned-LC08_CU_028012_20171103_20190429_C01_V01_SR_combined_SAR.tif',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_029011_20171018_20190429_C01_V01_SR_combined/aligned-LC08_CU_029011_20171018_20190429_C01_V01_SR_combined_SAR.tif',\n",
    "]\n",
    "\n",
    "dem_image_paths = [\n",
    "    '/deep_data/sentinel_sar/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-79.69001_33.95762_-77.7672_35.51886__4500X4631_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-77.7672_35.00779_-75.79042_36.58923__4500X4262_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-79.69001_33.95762_-77.7672_35.51886__4500X4631_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_028012_20171103_20190429_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-78.07896_33.69485_-76.14021_35.27466__4500X4248_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "    '/deep_data/sentinel_sar/LC08_CU_029011_20171018_20190429_C01_V01_SR_combined_dem/aligned-wms_DEM_EPSG4326_-76.14021_34.71847_-74.14865_36.318__4500X4408_ShowLogo_False_tiff_depth=32f.tiff',\n",
    "]\n",
    "\n",
    "\n",
    "landsat_datasets = []\n",
    "for fp in l8_image_paths:\n",
    "    landsat_datasets.append(rasterio.open(fp))\n",
    "    \n",
    "sentinel_datasets = []\n",
    "for fp in s1_image_paths:\n",
    "    sentinel_datasets.append(rasterio.open(fp))\n",
    "    \n",
    "dem_datasets = []\n",
    "for fp in dem_image_paths:\n",
    "    dem_datasets.append(rasterio.open(fp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def unet_model(n_classes=5, im_sz=160, n_channels=8, n_filters_start=32, growth_factor=2, upconv=True,\n",
    "               metrics=['accuracy']):\n",
    "    droprate=0.25\n",
    "    n_filters = n_filters_start\n",
    "    inputs = Input((im_sz, im_sz, n_channels))\n",
    "    #inputs = BatchNormalization()(inputs)\n",
    "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #pool1 = Dropout(droprate)(pool1)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(droprate)(pool2)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(droprate)(pool3)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool3 = BatchNormalization()(pool3)\n",
    "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)\n",
    "    pool4_1 = Dropout(droprate)(pool4_1)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool4_1 = BatchNormalization()(pool4_1)\n",
    "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)\n",
    "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n",
    "    pool4_2 = Dropout(droprate)(pool4_2)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)\n",
    "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])\n",
    "    else:\n",
    "        up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])\n",
    "    up6_1 = BatchNormalization()(up6_1)\n",
    "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)\n",
    "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)\n",
    "    conv6_1 = Dropout(droprate)(conv6_1)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])\n",
    "    else:\n",
    "        up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])\n",
    "    up6_2 = BatchNormalization()(up6_2)\n",
    "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)\n",
    "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)\n",
    "    conv6_2 = Dropout(droprate)(conv6_2)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])\n",
    "    else:\n",
    "        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = Dropout(droprate)(conv7)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
    "    else:\n",
    "        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = Dropout(droprate)(conv8)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
    "    else:\n",
    "        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
    "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    \n",
    "    sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_tile_generator(l8_image_datasets, s1_image_datasets, dem_image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size, merge=True):\n",
    "    ### this is a keras compatible data generator which generates data and labels on the fly \n",
    "    ### from a set of pixel locations, a list of image datasets, and a label dataset\n",
    "    \n",
    "    # pixel locations looks like [r, c, dataset_index]\n",
    "    label_image = label_dataset.read()\n",
    "    # merge some of the labels\n",
    "    if merge:\n",
    "        label_image = merge_classes(label_image)\n",
    "\n",
    "    c = r = 0\n",
    "    i = 0\n",
    "    \n",
    "    label_proj = Proj(label_dataset.crs)\n",
    "    l8_proj = Proj(l8_image_datasets[0].crs)\n",
    "    s1_proj = Proj(s1_image_datasets[0].crs)\n",
    "\n",
    "    # assuming all images have the same num of bands\n",
    "    l8_band_count = l8_image_datasets[0].count  \n",
    "    s1_band_count = s1_image_datasets[0].count\n",
    "    dem_band_count = dem_image_datasets[0].count\n",
    "    band_count = l8_band_count + s1_band_count + dem_band_count\n",
    "    class_count = len(class_names)\n",
    "    buffer = math.ceil(tile_height / 2)\n",
    "  \n",
    "    while True:\n",
    "        image_batch = np.zeros((batch_size, tile_height, tile_width, band_count-1)) # take one off because we don't want the QA band\n",
    "        label_batch = np.zeros((batch_size,tile_height,tile_width,class_count))\n",
    "        b = 0\n",
    "        while b < batch_size:\n",
    "            # if we're at the end  of the data just restart\n",
    "            if i >= len(pixel_locations):\n",
    "                i=0\n",
    "            r, c = pixel_locations[i][0]\n",
    "            dataset_index = pixel_locations[i][1]\n",
    "            i += 1\n",
    "            tile = l8_image_datasets[dataset_index].read(list(np.arange(1, l8_band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "            if np.amax(tile) == 0: # don't include if it is part of the image with no pixels\n",
    "                pass\n",
    "            elif np.isnan(tile).any() == True or -9999 in tile: \n",
    "                # we don't want tiles containing nan or -999 this comes from edges\n",
    "                # this also takes a while and is inefficient\n",
    "                pass\n",
    "            elif tile.shape != (l8_band_count, tile_width, tile_height):\n",
    "                #print('wrong shape')\n",
    "                #print(tile.shape)\n",
    "                # somehow we're randomly getting tiles without the correct dimensions\n",
    "                pass\n",
    "            elif np.isin(tile[7,:,:], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
    "                # make sure pixel doesn't contain clouds\n",
    "                # this is probably pretty inefficient but only checking width x height for each tile\n",
    "                # read more here: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
    "                #print('Found some cloud.')\n",
    "                #print(tile[7,:,:])\n",
    "                pass\n",
    "            else:\n",
    "                # set medium developed to high dev\n",
    "                #tile[tile == 3] = 2\n",
    "                \n",
    "                # taking off the QA band\n",
    "                tile = tile[0:7]\n",
    "                # reshape from raster format to image format and standardize according to image wide stats\n",
    "                reshaped_tile = (reshape_as_image(tile)  - 982.5) / 1076.5\n",
    "                \n",
    "                # L8, S1, and DEM are all the same projection and area otherwise this wouldn't work\n",
    "                # read in the sentinel-1 data \n",
    "                s1_tile = s1_image_datasets[dataset_index].read(list(np.arange(1, s1_band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "               \n",
    "                # read in the DEM data \n",
    "                dem_tile = dem_image_datasets[dataset_index].read(list(np.arange(1, dem_band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "                \n",
    "                if np.isnan(s1_tile).any() == True:\n",
    "                    pass\n",
    "                elif np.isnan(dem_tile).any() == True:\n",
    "                    pass\n",
    "                else:\n",
    "                    # reshape from raster format to image format and standardize according to image wide stats\n",
    "                    reshaped_s1_tile = (reshape_as_image(s1_tile)  - 0.10) / 0.088\n",
    "                    # reshape from raster format to image format and standardize according to image wide stats\n",
    "                    reshaped_dem_tile = (reshape_as_image(dem_tile)  - 31) / 16.5\n",
    "                    \n",
    "                    ### get label data\n",
    "                    # find gps of that pixel within the image\n",
    "                    (x, y) = l8_image_datasets[dataset_index].xy(r, c)\n",
    "\n",
    "                    # convert the point we're sampling from to the same projection as the label dataset if necessary\n",
    "                    if l8_proj != label_proj:\n",
    "                        x,y = transform(l8_proj,label_proj,x,y)\n",
    "\n",
    "                    # reference gps in label_image\n",
    "                    \n",
    "                    row, col = label_dataset.index(x,y)\n",
    "                    label_masks = np.zeros((tile_height, tile_width, class_count))\n",
    "                    flag = False\n",
    "                    #use tile to make the masks\n",
    "                    for h in range(tile_height):\n",
    "                        if flag:\n",
    "                            break\n",
    "                        tileRow = row-buffer+h\n",
    "                        for w in range(tile_width):\n",
    "                            tileCol = col-buffer+w\n",
    "                            if(label_image[0, tileRow, tileCol] == 0):\n",
    "                                flag = True\n",
    "                            else:\n",
    "                                label_masks[h][w][label_image[0, tileRow, tileCol]-1] = 1\n",
    "                    if flag:\n",
    "                        pass\n",
    "                    else:\n",
    "                        label_batch[b] = label_masks\n",
    "                        image_batch[b] = np.dstack( ( reshaped_tile, reshaped_s1_tile, reshaped_dem_tile ) )\n",
    "                        b += 1\n",
    "        yield (image_batch, label_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "epochs = 200\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# input image dimensions\n",
    "tile_side = 64\n",
    "img_rows, img_cols = tile_side, tile_side\n",
    "img_bands = landsat_datasets[0].count + sentinel_datasets[0].count + dem_datasets[0].count - 1\n",
    "\n",
    "input_shape = (img_rows, img_cols, img_bands)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_px, val_px = cu.gen_pixel_locations(landsat_datasets, 100000, 30000, tile_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(n_classes=len(class_names), im_sz=tile_side, n_channels=img_bands, n_filters_start=64, growth_factor=2, upconv=True,\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4000/4000 [==============================] - 3391s 848ms/step - loss: 2.0528 - acc: 0.2345 - val_loss: 1.9094 - val_acc: 0.4147\n",
      "Epoch 2/200\n",
      "4000/4000 [==============================] - 3340s 835ms/step - loss: 1.6895 - acc: 0.4616 - val_loss: 1.7090 - val_acc: 0.4685\n",
      "Epoch 3/200\n",
      "4000/4000 [==============================] - 3379s 845ms/step - loss: 1.5335 - acc: 0.5123 - val_loss: 1.5708 - val_acc: 0.5077\n",
      "Epoch 4/200\n",
      "4000/4000 [==============================] - 3346s 837ms/step - loss: 1.5913 - acc: 0.4929 - val_loss: 1.6635 - val_acc: 0.4889\n",
      "Epoch 5/200\n",
      "4000/4000 [==============================] - 3348s 837ms/step - loss: 1.5508 - acc: 0.5030 - val_loss: 1.6183 - val_acc: 0.4887\n",
      "Epoch 6/200\n",
      "4000/4000 [==============================] - 3344s 836ms/step - loss: 1.4710 - acc: 0.5277 - val_loss: 1.5418 - val_acc: 0.5094\n",
      "Epoch 7/200\n",
      "4000/4000 [==============================] - 3328s 832ms/step - loss: 1.5252 - acc: 0.5089 - val_loss: 1.5730 - val_acc: 0.5019\n",
      "Epoch 8/200\n",
      "4000/4000 [==============================] - 3345s 836ms/step - loss: 1.4721 - acc: 0.5222 - val_loss: 1.7371 - val_acc: 0.4870\n",
      "Epoch 9/200\n",
      "4000/4000 [==============================] - 3319s 830ms/step - loss: 1.4489 - acc: 0.5295 - val_loss: 1.5841 - val_acc: 0.4920\n",
      "Epoch 10/200\n",
      "4000/4000 [==============================] - 3322s 831ms/step - loss: 1.4831 - acc: 0.5181 - val_loss: 1.5640 - val_acc: 0.5030\n",
      "Epoch 11/200\n",
      "4000/4000 [==============================] - 3370s 842ms/step - loss: 1.3859 - acc: 0.5475 - val_loss: 1.9599 - val_acc: 0.4851\n",
      "Epoch 12/200\n",
      "4000/4000 [==============================] - 3330s 833ms/step - loss: 1.4677 - acc: 0.5209 - val_loss: 1.5397 - val_acc: 0.5113\n",
      "Epoch 13/200\n",
      "4000/4000 [==============================] - 3316s 829ms/step - loss: 1.4559 - acc: 0.5241 - val_loss: 1.5141 - val_acc: 0.5172\n",
      "Epoch 14/200\n",
      "4000/4000 [==============================] - 3366s 841ms/step - loss: 1.3583 - acc: 0.5548 - val_loss: 1.4702 - val_acc: 0.5264\n",
      "Epoch 15/200\n",
      "4000/4000 [==============================] - 3323s 831ms/step - loss: 1.4384 - acc: 0.5295 - val_loss: 1.5395 - val_acc: 0.5152\n",
      "Epoch 16/200\n",
      "4000/4000 [==============================] - 3341s 835ms/step - loss: 1.4136 - acc: 0.5357 - val_loss: 1.4546 - val_acc: 0.5338\n",
      "Epoch 17/200\n",
      "4000/4000 [==============================] - 3332s 833ms/step - loss: 1.3456 - acc: 0.5579 - val_loss: 1.4823 - val_acc: 0.5238\n",
      "Epoch 18/200\n",
      "4000/4000 [==============================] - 3334s 834ms/step - loss: 1.4066 - acc: 0.5387 - val_loss: 1.4853 - val_acc: 0.5263\n",
      "Epoch 19/200\n",
      "4000/4000 [==============================] - 3351s 838ms/step - loss: 1.3660 - acc: 0.5493 - val_loss: 1.7243 - val_acc: 0.4909\n",
      "Epoch 20/200\n",
      "4000/4000 [==============================] - 3328s 832ms/step - loss: 1.3452 - acc: 0.5570 - val_loss: 1.4864 - val_acc: 0.5190\n",
      "Epoch 21/200\n",
      "4000/4000 [==============================] - 3342s 835ms/step - loss: 1.3851 - acc: 0.5445 - val_loss: 1.5010 - val_acc: 0.5236\n",
      "Epoch 22/200\n",
      "4000/4000 [==============================] - 3361s 840ms/step - loss: 1.2991 - acc: 0.5706 - val_loss: 2.0750 - val_acc: 0.4219\n",
      "Epoch 23/200\n",
      "4000/4000 [==============================] - 3352s 838ms/step - loss: 1.3766 - acc: 0.5460 - val_loss: 1.4885 - val_acc: 0.5300\n",
      "Epoch 24/200\n",
      "4000/4000 [==============================] - 3316s 829ms/step - loss: 1.3711 - acc: 0.5475 - val_loss: 1.4476 - val_acc: 0.5410\n",
      "Epoch 25/200\n",
      "4000/4000 [==============================] - 3373s 843ms/step - loss: 1.2817 - acc: 0.5756 - val_loss: 1.4712 - val_acc: 0.5316\n",
      "Epoch 26/200\n",
      "3999/4000 [============================>.] - ETA: 0s - loss: 1.3646 - acc: 0.5497"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-844ca76824a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_px\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcn_tile_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandsat_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdem_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_side\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_side\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_px\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     validation_steps=len(val_px) // batch_size)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=fcn_tile_generator(landsat_datasets, sentinel_datasets, dem_datasets, label_dataset, tile_side, tile_side, train_px, batch_size, merge=False), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=fcn_tile_generator(landsat_datasets, sentinel_datasets, dem_datasets, label_dataset, tile_side, tile_side, val_px, batch_size, merge=False),\n",
    "                    validation_steps=len(val_px) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 190s 158ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(generator=cu.tile_generator(landsat_datasets, sentinel_datasets, dem_datasets, \n",
    "        label_dataset, tile_side, tile_side, val_px, batch_size, merge=False), \n",
    "                        steps=len(val_px) // batch_size,\n",
    "                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator = fcn_tile_generator(landsat_datasets, sentinel_datasets, dem_datasets, \n",
    "                                label_dataset, tile_side, tile_side, val_px, batch_size=1, merge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pred = np.argmax(predictions, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatpred = actual_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122880000,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatpred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatpred[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ddf36a3fbe2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimage_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-226b181ebb49>\u001b[0m in \u001b[0;36mfcn_tile_generator\u001b[0;34m(l8_image_datasets, s1_image_datasets, dem_image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size, merge)\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                             \u001b[0mtileCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtileRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtileCol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                                 \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels = np.empty(flatpred.shape)\n",
    "count = 0\n",
    "while count < len(labels):\n",
    "    image_b, label_b = next(eval_generator)\n",
    "    labels[count] = label_b\n",
    "    count += 1\n",
    "    \n",
    "label_index = np.argmax(labels, axis=1)     \n",
    "pred_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "cu.plot_confusion_matrix(label_index, pred_index, classes=np.array(list(class_names)),\n",
    "                      class_dict=class_names)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "cu.plot_confusion_matrix(label_index, pred_index, classes=np.array(list(class_names)),\n",
    "                      class_dict=class_names,\n",
    "                      normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
