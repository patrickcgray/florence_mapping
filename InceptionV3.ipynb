{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import adjust_band\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Proj, transform\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_generator(image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size):\n",
    "    ### this is a keras compatible data generator which generates data and labels on the fly \n",
    "    ### from a set of pixel locations, a list of image datasets, and a label dataset\n",
    "    \n",
    "    # pixel locations looks like [r, c, dataset_index]\n",
    "    label_image = label_dataset.read()\n",
    "    label_image[label_image == 255] = 1\n",
    "\n",
    "    c = r = 0\n",
    "    i = 0\n",
    "    \n",
    "    outProj = Proj(label_dataset.crs)\n",
    "\n",
    "    # assuming all images have the same num of bands\n",
    "    band_count = image_datasets[0].count\n",
    "    class_count = len(np.unique(label_image))\n",
    "    buffer = math.ceil(tile_height / 2)\n",
    "  \n",
    "    while True:\n",
    "        image_batch = np.zeros((batch_size, tile_height, tile_width, 3)) # take one off because we don't want the QA band\n",
    "        label_batch = np.zeros((batch_size,class_count))\n",
    "        b = 0\n",
    "        while b < batch_size:\n",
    "            # if we're at the end  of the data just restart\n",
    "            if i >= len(pixel_locations):\n",
    "                i=0\n",
    "            c, r = pixel_locations[i][0]\n",
    "            dataset_index = pixel_locations[i][1]\n",
    "            i += 1\n",
    "            tile = image_datasets[dataset_index].read(list(np.arange(1, band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "            if np.amax(tile) == 0: # don't include if it is part of the image with no pixels\n",
    "                pass\n",
    "            elif np.isnan(tile).any() == True or -9999 in tile: \n",
    "                # we don't want tiles containing nan or -999 this comes from edges\n",
    "                # this also takes a while and is inefficient\n",
    "                pass\n",
    "            elif tile.shape != (band_count, tile_width, tile_height):\n",
    "                print('wrong shape')\n",
    "                print(tile.shape)\n",
    "                # somehow we're randomly getting tiles without the correct dimensions\n",
    "                pass\n",
    "            elif np.isin(tile[7,:,:], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
    "                # make sure pixel doesn't contain clouds\n",
    "                # this is probably pretty inefficient but only checking width x height for each tile\n",
    "                # read more here: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
    "                #print('Found some cloud.')\n",
    "                #print(tile[7,:,:])\n",
    "                pass\n",
    "            else:\n",
    "                tile = adjust_band(tile[0:7])\n",
    "                # reshape from raster format to image format\n",
    "                reshaped_tile = reshape_as_image(tile)\n",
    "                #print(reshaped_tile.shape)\n",
    "\n",
    "                # find gps of that pixel within the image\n",
    "                (x, y) = image_datasets[dataset_index].xy(r, c)\n",
    "\n",
    "                # convert the point we're sampling from to the same projection as the label dataset if necessary\n",
    "                inProj = Proj(image_datasets[dataset_index].crs)\n",
    "                if inProj != outProj:\n",
    "                    x,y = transform(inProj,outProj,x,y)\n",
    "\n",
    "                # reference gps in label_image\n",
    "                row, col = label_dataset.index(x,y)\n",
    "\n",
    "                # find label\n",
    "                label = label_image[:, row, col]\n",
    "                # if this label is part of the unclassified area then ignore\n",
    "                if label == 0 or np.isnan(label).any() == True:\n",
    "                    pass\n",
    "                else:\n",
    "                    # add label to the batch in a one hot encoding style\n",
    "                    label_batch[b][label] = 1\n",
    "                    image_batch[b] = reshaped_tile[:,:,4:1:-1]\n",
    "                    b += 1\n",
    "        yield (image_batch, label_batch)\n",
    "        \n",
    "def gen_pixel_locations(image_datasets, train_count, val_count, tile_size):\n",
    "    ### this function pulls out a train_count + val_count number of random pixels from a list of raster datasets\n",
    "    ### and returns a list of training pixel locations and image indices \n",
    "    ### and a list of validation pixel locations and indices\n",
    "    \n",
    "    ## future improvements could make this select classes evenly\n",
    "    train_pixels = []\n",
    "    val_pixels = []\n",
    "    \n",
    "    buffer = math.ceil(tile_size/2)\n",
    "    \n",
    "    train_count_per_dataset = math.ceil(train_count / len(image_datasets))\n",
    "    val_count_per_dataset = math.ceil(val_count / len(image_datasets))\n",
    "   \n",
    "    total_count_per_dataset = train_count_per_dataset + val_count_per_dataset\n",
    "    for index, image_dataset in enumerate(tqdm(image_datasets)):\n",
    "        #randomly pick `count` num of pixels from each dataset\n",
    "        img_height, img_width = image_dataset.shape\n",
    "        \n",
    "        rows = range(0+buffer, img_height-buffer)\n",
    "        columns = range(0+buffer, img_width-buffer)\n",
    "        #rows_sub, columns_sub = zip(*random.sample(list(zip(rows, columns)), total_count))\n",
    "        \n",
    "        points = random.sample(set(itertools.product(rows, columns)), total_count_per_dataset)\n",
    "        \n",
    "        dataset_index_list = [index] * total_count_per_dataset\n",
    "        \n",
    "        dataset_pixels = list(zip(points, dataset_index_list))\n",
    "        \n",
    "        train_pixels += dataset_pixels[:train_count_per_dataset]\n",
    "        val_pixels += dataset_pixels[train_count_per_dataset:]\n",
    "        \n",
    "        \n",
    "    return (train_pixels, val_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# The GPU id to use\n",
    "# Patrick \"0\"\n",
    "# Feroze  \"1\"\n",
    "# Yousuf  \"2\"\n",
    "# Diego   \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do other imports now...\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (75,75,3)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(23, activation='softmax')(x)\n",
    "inception_model = keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "metrics=['accuracy']\n",
    "inception_model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset = rasterio.open('/deep_data/landcover_reproject.tif')\n",
    "label_image = label_dataset.read()\n",
    "\n",
    "image_paths = ['/deep_data/processed_landsat/LC08_CU_027012_20170907_20181121_C01_V01_SR_combined.tif',\n",
    "               '/deep_data/processed_landsat/LC08_CU_028012_20140814_20171017_C01_V01_SR_combined.tif',\n",
    "               '/deep_data/processed_landsat/LC08_CU_028011_20170907_20181130_C01_V01_SR_combined.tif',  \n",
    "               '/deep_data/processed_landsat/LC08_CU_028012_20171002_20171019_C01_V01_SR_combined.tif']\n",
    "\n",
    "landsat_datasets = []\n",
    "for fp in image_paths:\n",
    "    landsat_datasets.append(rasterio.open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "label_image[label_image == 255] = 1\n",
    "num_classes = len(np.unique(label_image))\n",
    "epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "tile_side = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 37, 37, 32)   864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 37, 37, 32)   96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 37, 37, 32)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 35, 35, 32)   9216        activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 35, 35, 32)   96          conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 35, 35, 32)   0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 35, 35, 64)   18432       activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 35, 35, 64)   192         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 35, 35, 64)   0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 17, 17, 64)   0           activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 17, 17, 80)   5120        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 17, 17, 80)   240         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 17, 17, 80)   0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 15, 15, 192)  138240      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 15, 15, 192)  576         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 15, 15, 192)  0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 7, 7, 192)    0           activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 7, 7, 64)     12288       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 7, 7, 64)     192         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 64)     0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 7, 7, 48)     9216        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 7, 7, 96)     55296       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 7, 7, 48)     144         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 7, 7, 96)     288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 48)     0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 96)     0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 7, 7, 192)    0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 7, 7, 64)     12288       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 7, 7, 64)     76800       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 7, 7, 96)     82944       activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 7, 7, 32)     6144        average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 7, 7, 64)     192         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 7, 7, 64)     192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 7, 7, 96)     288         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 7, 7, 32)     96          conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 64)     0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 64)     0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 96)     0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 32)     0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_288[0][0]             \n",
      "                                                                 activation_290[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "                                                                 activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 7, 7, 64)     192         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 7, 7, 64)     0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 7, 7, 96)     55296       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 7, 7, 48)     144         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 7, 7, 96)     288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 7, 7, 48)     0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 7, 7, 96)     0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 7, 7, 64)     76800       activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 7, 7, 96)     82944       activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 7, 7, 64)     16384       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 7, 7, 64)     192         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 7, 7, 64)     192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 7, 7, 96)     288         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 7, 7, 64)     192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 7, 7, 64)     0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 7, 7, 64)     0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 7, 7, 96)     0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 7, 7, 64)     0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_295[0][0]             \n",
      "                                                                 activation_297[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "                                                                 activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 7, 7, 64)     192         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 7, 7, 64)     0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 7, 7, 96)     55296       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 7, 7, 48)     144         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 7, 7, 96)     288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 7, 7, 48)     0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 7, 7, 96)     0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 7, 7, 64)     76800       activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 7, 7, 96)     82944       activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 7, 7, 64)     18432       average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 7, 7, 64)     192         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 7, 7, 64)     192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 7, 7, 96)     288         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 7, 7, 64)     192         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 7, 7, 64)     0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 7, 7, 64)     0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 7, 7, 96)     0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 7, 7, 64)     0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_302[0][0]             \n",
      "                                                                 activation_304[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "                                                                 activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 7, 7, 64)     192         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 7, 7, 64)     0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 7, 7, 96)     55296       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 7, 7, 96)     288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 7, 7, 96)     0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 3, 3, 96)     82944       activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 3, 3, 384)    1152        conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 3, 3, 96)     288         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 3, 3, 384)    0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 3, 3, 96)     0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_309[0][0]             \n",
      "                                                                 activation_312[0][0]             \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 3, 3, 128)    384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 3, 3, 128)    0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 3, 3, 128)    114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 3, 3, 128)    384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 3, 3, 128)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 3, 3, 128)    114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 3, 3, 128)    384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 3, 3, 128)    384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 3, 3, 128)    0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 3, 3, 128)    0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 3, 3, 128)    114688      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 3, 3, 128)    114688      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 3, 3, 128)    384         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 3, 3, 128)    384         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 3, 3, 128)    0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 3, 3, 128)    0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 3, 3, 192)    172032      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 3, 3, 192)    172032      activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 3, 3, 192)    576         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 3, 3, 192)    576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 3, 3, 192)    576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 3, 3, 192)    576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 3, 3, 192)    0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 3, 3, 192)    0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 3, 3, 192)    0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 3, 3, 192)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_313[0][0]             \n",
      "                                                                 activation_316[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 3, 3, 160)    480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 3, 3, 160)    0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 3, 3, 160)    179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 3, 3, 160)    480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 3, 3, 160)    0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 3, 3, 160)    179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 3, 3, 160)    480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 3, 3, 160)    480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 3, 3, 160)    0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 3, 3, 160)    0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 3, 3, 160)    179200      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 3, 3, 160)    179200      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 3, 3, 160)    480         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 3, 3, 160)    480         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 3, 3, 160)    0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 3, 3, 160)    0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 3, 3, 192)    215040      activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 3, 3, 192)    215040      activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 3, 3, 192)    576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 3, 3, 192)    576         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 3, 3, 192)    576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 3, 3, 192)    576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 3, 3, 192)    0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 3, 3, 192)    0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 3, 3, 192)    0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 3, 3, 192)    0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_323[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "                                                                 activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 3, 3, 160)    480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 3, 3, 160)    0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 3, 3, 160)    179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 3, 3, 160)    480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 3, 3, 160)    0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 3, 3, 160)    179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 3, 3, 160)    480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 3, 3, 160)    480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 3, 3, 160)    0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 3, 3, 160)    0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 3, 3, 160)    179200      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 3, 3, 160)    179200      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 3, 3, 160)    480         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 3, 3, 160)    480         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 3, 3, 160)    0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 3, 3, 160)    0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 3, 3, 192)    215040      activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 3, 3, 192)    215040      activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 3, 3, 192)    576         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 3, 3, 192)    576         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 3, 3, 192)    576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 3, 3, 192)    576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 3, 3, 192)    0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 3, 3, 192)    0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 3, 3, 192)    0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 3, 3, 192)    0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_333[0][0]             \n",
      "                                                                 activation_336[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "                                                                 activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 3, 3, 192)    576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 3, 3, 192)    0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 3, 3, 192)    258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 3, 3, 192)    576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 3, 3, 192)    0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 3, 3, 192)    258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 3, 3, 192)    576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 3, 3, 192)    576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 3, 3, 192)    0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 3, 3, 192)    0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 3, 3, 192)    258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 3, 3, 192)    258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 3, 3, 192)    576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 3, 3, 192)    576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 3, 3, 192)    0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 3, 3, 192)    0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 3, 3, 192)    258048      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 3, 3, 192)    258048      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 3, 3, 192)    576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 3, 3, 192)    576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 3, 3, 192)    576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 3, 3, 192)    576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 3, 3, 192)    0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 3, 3, 192)    0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 3, 3, 192)    0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 3, 3, 192)    0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_343[0][0]             \n",
      "                                                                 activation_346[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "                                                                 activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 3, 3, 192)    576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 3, 3, 192)    0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 3, 3, 192)    258048      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 3, 3, 192)    576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 3, 3, 192)    0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 3, 3, 192)    258048      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 3, 3, 192)    576         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 3, 3, 192)    576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 3, 3, 192)    0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 3, 3, 192)    0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 1, 1, 320)    552960      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 1, 1, 192)    331776      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 1, 1, 320)    960         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 1, 1, 192)    576         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 1, 1, 320)    0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 1, 1, 192)    0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_354[0][0]             \n",
      "                                                                 activation_358[0][0]             \n",
      "                                                                 max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 1, 1, 448)    1344        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 1, 1, 448)    0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 1, 1, 384)    1548288     activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 1, 1, 384)    1152        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 1, 1, 384)    1152        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 1, 1, 384)    0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 1, 1, 384)    0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 1, 1, 384)    442368      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 1, 1, 384)    442368      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 1, 1, 384)    442368      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 1, 1, 384)    442368      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 1, 1, 384)    1152        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 1, 1, 384)    1152        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 1, 1, 384)    1152        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 1, 1, 384)    1152        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 1, 1, 192)    245760      average_pooling2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 1, 1, 320)    960         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 1, 1, 384)    0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 1, 1, 384)    0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 1, 1, 384)    0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 1, 1, 384)    0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 1, 1, 192)    576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 1, 1, 320)    0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_361[0][0]             \n",
      "                                                                 activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 1, 768)    0           activation_365[0][0]             \n",
      "                                                                 activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 1, 1, 192)    0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_359[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 1, 1, 448)    1344        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 1, 1, 448)    0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 1, 1, 384)    1548288     activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 1, 1, 384)    1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 1, 1, 384)    1152        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 1, 1, 384)    0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 1, 1, 384)    0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 1, 1, 384)    442368      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 1, 1, 384)    442368      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 1, 1, 384)    442368      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 1, 1, 384)    442368      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 1, 1, 384)    1152        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 1, 1, 384)    1152        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 1, 1, 384)    1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 1, 1, 384)    1152        conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 1, 1, 192)    393216      average_pooling2d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 1, 1, 320)    960         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 1, 1, 384)    0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 1, 1, 384)    0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 1, 1, 384)    0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 1, 1, 384)    0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 1, 1, 192)    576         conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 1, 1, 320)    0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_370[0][0]             \n",
      "                                                                 activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1, 1, 768)    0           activation_374[0][0]             \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 1, 1, 192)    0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_368[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 23)           23575       dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,924,535\n",
      "Trainable params: 2,121,751\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:45<00:00, 11.26s/it]\n"
     ]
    }
   ],
   "source": [
    "train_px, val_px = gen_pixel_locations(image_datasets=landsat_datasets, \n",
    "                                       train_count=50000, val_count=5000, tile_size=tile_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 113s 2s/step - loss: 2.3597 - acc: 0.2825 - val_loss: 3.3709 - val_acc: 0.2414\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 93s 2s/step - loss: 2.1278 - acc: 0.3104 - val_loss: 3.0275 - val_acc: 0.2284\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 98s 2s/step - loss: 2.0410 - acc: 0.3279 - val_loss: 3.1056 - val_acc: 0.1894\n",
      "Epoch 4/50\n",
      " 8/50 [===>..........................] - ETA: 1:35 - loss: 2.0322 - acc: 0.3386"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f5c79273060f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtile_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandsat_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_side\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_side\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_px\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_px\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     class_weight=class_weights)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inception_model.fit_generator(generator=tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, train_px, batch_size), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=50, verbose=1,\n",
    "                    validation_data=tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, val_px, batch_size),\n",
    "                    validation_steps=len(val_px) // batch_size,\n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 conv2d_95\n",
      "2 batch_normalization_95\n",
      "3 activation_95\n",
      "4 conv2d_96\n",
      "5 batch_normalization_96\n",
      "6 activation_96\n",
      "7 conv2d_97\n",
      "8 batch_normalization_97\n",
      "9 activation_97\n",
      "10 max_pooling2d_5\n",
      "11 conv2d_98\n",
      "12 batch_normalization_98\n",
      "13 activation_98\n",
      "14 conv2d_99\n",
      "15 batch_normalization_99\n",
      "16 activation_99\n",
      "17 max_pooling2d_6\n",
      "18 conv2d_103\n",
      "19 batch_normalization_103\n",
      "20 activation_103\n",
      "21 conv2d_101\n",
      "22 conv2d_104\n",
      "23 batch_normalization_101\n",
      "24 batch_normalization_104\n",
      "25 activation_101\n",
      "26 activation_104\n",
      "27 average_pooling2d_10\n",
      "28 conv2d_100\n",
      "29 conv2d_102\n",
      "30 conv2d_105\n",
      "31 conv2d_106\n",
      "32 batch_normalization_100\n",
      "33 batch_normalization_102\n",
      "34 batch_normalization_105\n",
      "35 batch_normalization_106\n",
      "36 activation_100\n",
      "37 activation_102\n",
      "38 activation_105\n",
      "39 activation_106\n",
      "40 mixed0\n",
      "41 conv2d_110\n",
      "42 batch_normalization_110\n",
      "43 activation_110\n",
      "44 conv2d_108\n",
      "45 conv2d_111\n",
      "46 batch_normalization_108\n",
      "47 batch_normalization_111\n",
      "48 activation_108\n",
      "49 activation_111\n",
      "50 average_pooling2d_11\n",
      "51 conv2d_107\n",
      "52 conv2d_109\n",
      "53 conv2d_112\n",
      "54 conv2d_113\n",
      "55 batch_normalization_107\n",
      "56 batch_normalization_109\n",
      "57 batch_normalization_112\n",
      "58 batch_normalization_113\n",
      "59 activation_107\n",
      "60 activation_109\n",
      "61 activation_112\n",
      "62 activation_113\n",
      "63 mixed1\n",
      "64 conv2d_117\n",
      "65 batch_normalization_117\n",
      "66 activation_117\n",
      "67 conv2d_115\n",
      "68 conv2d_118\n",
      "69 batch_normalization_115\n",
      "70 batch_normalization_118\n",
      "71 activation_115\n",
      "72 activation_118\n",
      "73 average_pooling2d_12\n",
      "74 conv2d_114\n",
      "75 conv2d_116\n",
      "76 conv2d_119\n",
      "77 conv2d_120\n",
      "78 batch_normalization_114\n",
      "79 batch_normalization_116\n",
      "80 batch_normalization_119\n",
      "81 batch_normalization_120\n",
      "82 activation_114\n",
      "83 activation_116\n",
      "84 activation_119\n",
      "85 activation_120\n",
      "86 mixed2\n",
      "87 conv2d_122\n",
      "88 batch_normalization_122\n",
      "89 activation_122\n",
      "90 conv2d_123\n",
      "91 batch_normalization_123\n",
      "92 activation_123\n",
      "93 conv2d_121\n",
      "94 conv2d_124\n",
      "95 batch_normalization_121\n",
      "96 batch_normalization_124\n",
      "97 activation_121\n",
      "98 activation_124\n",
      "99 max_pooling2d_7\n",
      "100 mixed3\n",
      "101 conv2d_129\n",
      "102 batch_normalization_129\n",
      "103 activation_129\n",
      "104 conv2d_130\n",
      "105 batch_normalization_130\n",
      "106 activation_130\n",
      "107 conv2d_126\n",
      "108 conv2d_131\n",
      "109 batch_normalization_126\n",
      "110 batch_normalization_131\n",
      "111 activation_126\n",
      "112 activation_131\n",
      "113 conv2d_127\n",
      "114 conv2d_132\n",
      "115 batch_normalization_127\n",
      "116 batch_normalization_132\n",
      "117 activation_127\n",
      "118 activation_132\n",
      "119 average_pooling2d_13\n",
      "120 conv2d_125\n",
      "121 conv2d_128\n",
      "122 conv2d_133\n",
      "123 conv2d_134\n",
      "124 batch_normalization_125\n",
      "125 batch_normalization_128\n",
      "126 batch_normalization_133\n",
      "127 batch_normalization_134\n",
      "128 activation_125\n",
      "129 activation_128\n",
      "130 activation_133\n",
      "131 activation_134\n",
      "132 mixed4\n",
      "133 conv2d_139\n",
      "134 batch_normalization_139\n",
      "135 activation_139\n",
      "136 conv2d_140\n",
      "137 batch_normalization_140\n",
      "138 activation_140\n",
      "139 conv2d_136\n",
      "140 conv2d_141\n",
      "141 batch_normalization_136\n",
      "142 batch_normalization_141\n",
      "143 activation_136\n",
      "144 activation_141\n",
      "145 conv2d_137\n",
      "146 conv2d_142\n",
      "147 batch_normalization_137\n",
      "148 batch_normalization_142\n",
      "149 activation_137\n",
      "150 activation_142\n",
      "151 average_pooling2d_14\n",
      "152 conv2d_135\n",
      "153 conv2d_138\n",
      "154 conv2d_143\n",
      "155 conv2d_144\n",
      "156 batch_normalization_135\n",
      "157 batch_normalization_138\n",
      "158 batch_normalization_143\n",
      "159 batch_normalization_144\n",
      "160 activation_135\n",
      "161 activation_138\n",
      "162 activation_143\n",
      "163 activation_144\n",
      "164 mixed5\n",
      "165 conv2d_149\n",
      "166 batch_normalization_149\n",
      "167 activation_149\n",
      "168 conv2d_150\n",
      "169 batch_normalization_150\n",
      "170 activation_150\n",
      "171 conv2d_146\n",
      "172 conv2d_151\n",
      "173 batch_normalization_146\n",
      "174 batch_normalization_151\n",
      "175 activation_146\n",
      "176 activation_151\n",
      "177 conv2d_147\n",
      "178 conv2d_152\n",
      "179 batch_normalization_147\n",
      "180 batch_normalization_152\n",
      "181 activation_147\n",
      "182 activation_152\n",
      "183 average_pooling2d_15\n",
      "184 conv2d_145\n",
      "185 conv2d_148\n",
      "186 conv2d_153\n",
      "187 conv2d_154\n",
      "188 batch_normalization_145\n",
      "189 batch_normalization_148\n",
      "190 batch_normalization_153\n",
      "191 batch_normalization_154\n",
      "192 activation_145\n",
      "193 activation_148\n",
      "194 activation_153\n",
      "195 activation_154\n",
      "196 mixed6\n",
      "197 conv2d_159\n",
      "198 batch_normalization_159\n",
      "199 activation_159\n",
      "200 conv2d_160\n",
      "201 batch_normalization_160\n",
      "202 activation_160\n",
      "203 conv2d_156\n",
      "204 conv2d_161\n",
      "205 batch_normalization_156\n",
      "206 batch_normalization_161\n",
      "207 activation_156\n",
      "208 activation_161\n",
      "209 conv2d_157\n",
      "210 conv2d_162\n",
      "211 batch_normalization_157\n",
      "212 batch_normalization_162\n",
      "213 activation_157\n",
      "214 activation_162\n",
      "215 average_pooling2d_16\n",
      "216 conv2d_155\n",
      "217 conv2d_158\n",
      "218 conv2d_163\n",
      "219 conv2d_164\n",
      "220 batch_normalization_155\n",
      "221 batch_normalization_158\n",
      "222 batch_normalization_163\n",
      "223 batch_normalization_164\n",
      "224 activation_155\n",
      "225 activation_158\n",
      "226 activation_163\n",
      "227 activation_164\n",
      "228 mixed7\n",
      "229 conv2d_167\n",
      "230 batch_normalization_167\n",
      "231 activation_167\n",
      "232 conv2d_168\n",
      "233 batch_normalization_168\n",
      "234 activation_168\n",
      "235 conv2d_165\n",
      "236 conv2d_169\n",
      "237 batch_normalization_165\n",
      "238 batch_normalization_169\n",
      "239 activation_165\n",
      "240 activation_169\n",
      "241 conv2d_166\n",
      "242 conv2d_170\n",
      "243 batch_normalization_166\n",
      "244 batch_normalization_170\n",
      "245 activation_166\n",
      "246 activation_170\n",
      "247 max_pooling2d_8\n",
      "248 mixed8\n",
      "249 conv2d_175\n",
      "250 batch_normalization_175\n",
      "251 activation_175\n",
      "252 conv2d_172\n",
      "253 conv2d_176\n",
      "254 batch_normalization_172\n",
      "255 batch_normalization_176\n",
      "256 activation_172\n",
      "257 activation_176\n",
      "258 conv2d_173\n",
      "259 conv2d_174\n",
      "260 conv2d_177\n",
      "261 conv2d_178\n",
      "262 average_pooling2d_17\n",
      "263 conv2d_171\n",
      "264 batch_normalization_173\n",
      "265 batch_normalization_174\n",
      "266 batch_normalization_177\n",
      "267 batch_normalization_178\n",
      "268 conv2d_179\n",
      "269 batch_normalization_171\n",
      "270 activation_173\n",
      "271 activation_174\n",
      "272 activation_177\n",
      "273 activation_178\n",
      "274 batch_normalization_179\n",
      "275 activation_171\n",
      "276 mixed9_0\n",
      "277 concatenate_3\n",
      "278 activation_179\n",
      "279 mixed9\n",
      "280 conv2d_184\n",
      "281 batch_normalization_184\n",
      "282 activation_184\n",
      "283 conv2d_181\n",
      "284 conv2d_185\n",
      "285 batch_normalization_181\n",
      "286 batch_normalization_185\n",
      "287 activation_181\n",
      "288 activation_185\n",
      "289 conv2d_182\n",
      "290 conv2d_183\n",
      "291 conv2d_186\n",
      "292 conv2d_187\n",
      "293 average_pooling2d_18\n",
      "294 conv2d_180\n",
      "295 batch_normalization_182\n",
      "296 batch_normalization_183\n",
      "297 batch_normalization_186\n",
      "298 batch_normalization_187\n",
      "299 conv2d_188\n",
      "300 batch_normalization_180\n",
      "301 activation_182\n",
      "302 activation_183\n",
      "303 activation_186\n",
      "304 activation_187\n",
      "305 batch_normalization_188\n",
      "306 activation_180\n",
      "307 mixed9_1\n",
      "308 concatenate_4\n",
      "309 activation_188\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in inception_model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in inception_model.layers[249:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.compile(optimizer=keras.optimizers.SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 0.0925 - val_loss: 11.8802\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.1194 - val_loss: 11.7619\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.0566 - val_loss: 11.3576\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0910 - val_loss: 11.2776\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0755 - val_loss: 12.0530\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0792 - val_loss: 11.4591\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0752 - val_loss: 11.0519\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0657 - val_loss: 11.7521\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0577 - val_loss: 11.8887\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0568 - val_loss: 11.4094\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0563 - val_loss: 10.0140\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0366 - val_loss: 9.8194\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0185 - val_loss: 11.3285\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0143 - val_loss: 11.1971\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0127 - val_loss: 11.0858\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0186 - val_loss: 10.0845\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0157 - val_loss: 10.2168\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0108 - val_loss: 11.2089\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0110 - val_loss: 10.8866\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0089 - val_loss: 10.0951\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0097 - val_loss: 11.0259\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0079 - val_loss: 10.7239\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0065 - val_loss: 11.2423\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0043 - val_loss: 11.4072\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0030 - val_loss: 11.2903\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0031 - val_loss: 11.3514\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0038 - val_loss: 11.0444\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0031 - val_loss: 11.0130\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0030 - val_loss: 11.0296\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0028 - val_loss: 11.2268\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0027 - val_loss: 10.9205\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0024 - val_loss: 10.8382\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0025 - val_loss: 10.9200\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0026 - val_loss: 10.9444\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0019 - val_loss: 10.9916\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0015 - val_loss: 11.0071\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0014 - val_loss: 11.1114\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0015 - val_loss: 10.8677\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0015 - val_loss: 11.0047\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0016 - val_loss: 11.0554\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0016 - val_loss: 10.9746\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0016 - val_loss: 11.1506\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0015 - val_loss: 11.0470\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0015 - val_loss: 10.7553\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0017 - val_loss: 10.9920\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0015 - val_loss: 11.0345\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0012 - val_loss: 10.9567\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0011 - val_loss: 11.0168\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0011 - val_loss: 11.0714\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0011 - val_loss: 10.8279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c80358fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_model.fit_generator(generator=tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, train_px, batch_size), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=50, verbose=1,\n",
    "                    validation_data=tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, val_px, batch_size),\n",
    "                    validation_steps=len(val_px) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:59<00:00, 14.89s/it]\n"
     ]
    }
   ],
   "source": [
    "test_px, val_px = gen_pixel_locations(image_datasets=landsat_datasets, \n",
    "                                       train_count=5000, val_count=0, tile_size=tile_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 21s 103ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.25083693742752, 0.17279999811202287]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_model.evaluate_generator(generator=tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, test_px, batch_size), \n",
    "                        steps=len(test_px) // batch_size,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 23 artists>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 0\n",
    "classes = np.zeros(23)\n",
    "for x in tile_generator(landsat_datasets, label_dataset, tile_side, tile_side, test_px, 1):\n",
    "    if count > 100:\n",
    "        break\n",
    "    classes[np.where(x[1]>0)[1]] += 1\n",
    "    count+=1\n",
    "plt.bar(np.arange(23),classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 23 artists>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_counts = np.zeros(23)\n",
    "for i in range(2,23):\n",
    "    total_counts[i] = len(np.where(label_image == i)[0])\n",
    "plt.bar(np.arange(23),total_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(label_image), np.ravel(label_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.45440165e-02, 1.40289867e-01, 1.02229135e+02, 4.01745361e+01,\n",
       "       8.49967596e+00, 1.13010189e+01, 9.15229899e-01, 1.08806948e+01,\n",
       "       5.85763056e+00, 1.06874402e+01, 1.62748582e+00, 9.99339328e+00,\n",
       "       1.93763546e+00, 1.17595169e+00, 3.47239908e+00, 9.79855601e+00,\n",
       "       1.92086811e+04, 3.00164033e+02, 1.48855750e+01, 5.90825058e+01,\n",
       "       3.66828751e+01, 9.80978671e-01, 3.01642027e+04])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1, ...,  1,  1,  1],\n",
       "       [ 1,  1,  1, ...,  1,  1,  1],\n",
       "       [ 1,  1,  1, ...,  1,  1,  1],\n",
       "       ...,\n",
       "       [ 1,  1,  1, ...,  6,  6, 13],\n",
       "       [ 1,  1,  1, ...,  6,  6, 12],\n",
       "       [ 1,  1,  1, ...,  6,  6,  6]], dtype=uint8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_image[0, :10000, :10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
