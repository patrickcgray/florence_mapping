{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rnn_tiles' from '/host/Desktop/cnn_dev/florence_mapping/rcnn/rnn_tiles.py'>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rasterio\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Bidirectional\n",
    "from keras.layers import Conv2D, MaxPooling2D, ConvLSTM2D, TimeDistributed, UpSampling2D, Concatenate\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import utilities as util\n",
    "import importlib\n",
    "import rnn_tiles\n",
    "import rnn_pixels\n",
    "import numpy as np\n",
    "importlib.reload(rnn_pixels)\n",
    "importlib.reload(rnn_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11: 0,\n",
       " 21: 3,\n",
       " 22: 1,\n",
       " 23: 1,\n",
       " 24: 1,\n",
       " 31: 4,\n",
       " 41: 2,\n",
       " 42: 2,\n",
       " 43: 2,\n",
       " 52: 2,\n",
       " 71: 3,\n",
       " 81: 3,\n",
       " 82: 3,\n",
       " 90: 2,\n",
       " 95: 5}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangeBlock(input_block, nb_layers, filters):\n",
    "    x_list = [input_block]\n",
    "    c_temp = input_block\n",
    "    for i in range(nb_layers):\n",
    "        c_l = ConvLSTM2D(filters=filters,kernel_size=(3,3), activation='elu', padding = 'same', return_sequences=True) (c_temp)\n",
    "        x_list.append(c_l)\n",
    "        merge = Concatenate()(x_list)\n",
    "        c_temp = merge\n",
    "    return c_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network_v2(input_shape, class_count):\n",
    "    input_img = Input(input_shape)\n",
    "    strange_block_1 = strangeBlock(input_img, 4, 20)\n",
    "    pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (strange_block_1)\n",
    "    strange_block_2 = strangeBlock(pool_1, 4, 20)\n",
    "    upsample_1 = TimeDistributed(UpSampling2D((3,3))) (strange_block_2)\n",
    "    conv_1 = TimeDistributed(Conv2D(32, (3,3)))(upsample_1)\n",
    "    conv_lc = ConvLSTM2D(filters=class_count,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False, name='landcover') (conv_1)\n",
    "    reshaping = Reshape((64*64,class_count)) (conv_lc)\n",
    "    #conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), padding = 'same', return_sequences=False, name='canopy')(conv_1)\n",
    "    model = Model(inputs=input_img, outputs=reshaping)  # conv_out_cc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network_v3(input_shape, class_count):\n",
    "    input_img = Input(input_shape)\n",
    "    strange_block_1 = strangeBlock(input_img, 4, 20)\n",
    "    #pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (strange_block_1)\n",
    "    strange_block_2 = strangeBlock(strange_block_1, 4, 20)\n",
    "    conv_lc = ConvLSTM2D(filters=class_count,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False, name='landcover') (strange_block_2)\n",
    "    reshaping = Reshape((64*64,class_count)) (conv_lc)\n",
    "    #conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), padding = 'same', return_sequences=False, name='canopy')(conv_1)\n",
    "    model = Model(inputs=input_img, outputs=reshaping)  # conv_out_cc])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network_v4(input_shape, class_count):\n",
    "    input_img = Input(input_shape)\n",
    "    strange_block_1 = strangeBlock(input_img, 4, 20)\n",
    "    #pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (strange_block_1)\n",
    "    strange_block_2 = strangeBlock(strange_block_1, 4, 20)\n",
    "    strange_block_3 = strangeBlock(strange_block_2, 4, 20)\n",
    "    conv_lc = ConvLSTM2D(filters=class_count,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False, name='landcover') (strange_block_3)\n",
    "    conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), activation='sigmoid', padding = 'same', return_sequences=False, name='canopy')(strange_block_3)\n",
    "    model = Model(inputs=input_img, outputs=[conv_lc, conv_out_cc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/landcover/NLCD_2011_Land_Cover_L48_20190424.img')\n",
    "canopy_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/canopy/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = {}\n",
    "landsat_datasets = {}\n",
    "tiles['028012'] = ['20110324', '20110612', '20110831', '20111103']\n",
    "tiles['029011'] = ['20110308', '20110425', '20110831', '20111103']\n",
    "tiles['028011'] = ['20110308', '20110628', '20110831', '20111103']\n",
    "for tile_number, dates in tiles.items():\n",
    "    tile_datasets = []\n",
    "    l8_image_paths = []\n",
    "    for date in dates:\n",
    "        l8_image_paths.append('/deep_data/recurrent_data/tile{}/combined/combined{}.tif'.format(tile_number, date))\n",
    "    for fp in l8_image_paths:\n",
    "        tile_datasets.append(rasterio.open(fp))\n",
    "    landsat_datasets[tile_number] = tile_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 64\n",
    "tile_list = ['028012', '029011', '028011']\n",
    "class_count = 6\n",
    "epochs = 200\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px = rnn_pixels.make_pixels(tile_size, tile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixels = rnn_pixels.delete_bad_tiles(landsat_datasets,lc_labels, canopy_labels, px, tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2481"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:1736 val:521 test:381\n"
     ]
    }
   ],
   "source": [
    "train_px, val_px, test_px = rnn_pixels.train_val_test_split(pixels, 0.7, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = strange_network_v4((4, 64, 64, 7), class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 4, 64, 64, 7) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_25 (ConvLSTM2D)    (None, 4, 64, 64, 20 19520       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 4, 64, 64, 27 0           input_4[0][0]                    \n",
      "                                                                 conv_lst_m2d_25[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_26 (ConvLSTM2D)    (None, 4, 64, 64, 20 33920       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 4, 64, 64, 47 0           input_4[0][0]                    \n",
      "                                                                 conv_lst_m2d_25[0][0]            \n",
      "                                                                 conv_lst_m2d_26[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_27 (ConvLSTM2D)    (None, 4, 64, 64, 20 48320       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 4, 64, 64, 67 0           input_4[0][0]                    \n",
      "                                                                 conv_lst_m2d_25[0][0]            \n",
      "                                                                 conv_lst_m2d_26[0][0]            \n",
      "                                                                 conv_lst_m2d_27[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_28 (ConvLSTM2D)    (None, 4, 64, 64, 20 62720       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 4, 64, 64, 87 0           input_4[0][0]                    \n",
      "                                                                 conv_lst_m2d_25[0][0]            \n",
      "                                                                 conv_lst_m2d_26[0][0]            \n",
      "                                                                 conv_lst_m2d_27[0][0]            \n",
      "                                                                 conv_lst_m2d_28[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_29 (ConvLSTM2D)    (None, 4, 64, 64, 20 77120       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 4, 64, 64, 10 0           concatenate_28[0][0]             \n",
      "                                                                 conv_lst_m2d_29[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_30 (ConvLSTM2D)    (None, 4, 64, 64, 20 91520       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 4, 64, 64, 12 0           concatenate_28[0][0]             \n",
      "                                                                 conv_lst_m2d_29[0][0]            \n",
      "                                                                 conv_lst_m2d_30[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_31 (ConvLSTM2D)    (None, 4, 64, 64, 20 105920      concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 4, 64, 64, 14 0           concatenate_28[0][0]             \n",
      "                                                                 conv_lst_m2d_29[0][0]            \n",
      "                                                                 conv_lst_m2d_30[0][0]            \n",
      "                                                                 conv_lst_m2d_31[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_32 (ConvLSTM2D)    (None, 4, 64, 64, 20 120320      concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 4, 64, 64, 16 0           concatenate_28[0][0]             \n",
      "                                                                 conv_lst_m2d_29[0][0]            \n",
      "                                                                 conv_lst_m2d_30[0][0]            \n",
      "                                                                 conv_lst_m2d_31[0][0]            \n",
      "                                                                 conv_lst_m2d_32[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_33 (ConvLSTM2D)    (None, 4, 64, 64, 20 134720      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 4, 64, 64, 18 0           concatenate_32[0][0]             \n",
      "                                                                 conv_lst_m2d_33[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_34 (ConvLSTM2D)    (None, 4, 64, 64, 20 149120      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 4, 64, 64, 20 0           concatenate_32[0][0]             \n",
      "                                                                 conv_lst_m2d_33[0][0]            \n",
      "                                                                 conv_lst_m2d_34[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_35 (ConvLSTM2D)    (None, 4, 64, 64, 20 163520      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 4, 64, 64, 22 0           concatenate_32[0][0]             \n",
      "                                                                 conv_lst_m2d_33[0][0]            \n",
      "                                                                 conv_lst_m2d_34[0][0]            \n",
      "                                                                 conv_lst_m2d_35[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_36 (ConvLSTM2D)    (None, 4, 64, 64, 20 177920      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 64, 64, 24 0           concatenate_32[0][0]             \n",
      "                                                                 conv_lst_m2d_33[0][0]            \n",
      "                                                                 conv_lst_m2d_34[0][0]            \n",
      "                                                                 conv_lst_m2d_35[0][0]            \n",
      "                                                                 conv_lst_m2d_36[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "landcover (ConvLSTM2D)          (None, 64, 64, 6)    6096        concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "canopy (ConvLSTM2D)             (None, 64, 64, 1)    996         concatenate_36[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,191,732\n",
      "Trainable params: 1,191,732\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.utils.multi_gpu_model(model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath ='strange_v4_merged.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    \"\"\"Jaccard distance for semantic segmentation.\n",
    "    Also known as the intersection-over-union loss.\n",
    "    This loss is useful when you have unbalanced numbers of pixels within an image\n",
    "    because it gives all classes equal weight. However, it is not the defacto\n",
    "    standard for image segmentation.\n",
    "    For example, assume you are trying to predict if\n",
    "    each pixel is cat, dog, or background.\n",
    "    You have 80% background pixels, 10% dog, and 10% cat.\n",
    "    If the model predicts 100% background\n",
    "    should it be be 80% right (as with categorical cross entropy)\n",
    "    or 30% (with this loss)?\n",
    "    The loss has been modified to have a smooth gradient as it converges on zero.\n",
    "    This has been shifted so it converges on 0 and is smoothed to avoid exploding\n",
    "    or disappearing gradient.\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    # Arguments\n",
    "        y_true: The ground truth tensor.\n",
    "        y_pred: The predicted tensor\n",
    "        smooth: Smoothing factor. Default is 100.\n",
    "    # Returns\n",
    "        The Jaccard distance between the two tensors.\n",
    "    # References\n",
    "        - [What is a good evaluation measure for semantic segmentation?](\n",
    "           http://www.bmva.org/bmvc/2013/Papers/paper0032/paper0032.pdf)\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss={'landcover':jaccard_distance, 'canopy':'mse'}, metrics={'landcover':['accuracy'], 'canopy':['mae']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "69/69 [==============================] - 111s 2s/step - loss: 1.3038 - landcover_loss: 0.8613 - canopy_loss: 0.4425 - landcover_acc: 0.6769 - canopy_mean_absolute_error: 0.5065 - val_loss: 1.2803 - val_landcover_loss: 0.8367 - val_canopy_loss: 0.4436 - val_landcover_acc: 0.5890 - val_canopy_mean_absolute_error: 0.5069\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2643 - landcover_loss: 0.8219 - canopy_loss: 0.4425 - landcover_acc: 0.6231 - canopy_mean_absolute_error: 0.5064 - val_loss: 1.2769 - val_landcover_loss: 0.8332 - val_canopy_loss: 0.4438 - val_landcover_acc: 0.5966 - val_canopy_mean_absolute_error: 0.5069\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2644 - landcover_loss: 0.8209 - canopy_loss: 0.4435 - landcover_acc: 0.6230 - canopy_mean_absolute_error: 0.5077 - val_loss: 1.2726 - val_landcover_loss: 0.8290 - val_canopy_loss: 0.4435 - val_landcover_acc: 0.6158 - val_canopy_mean_absolute_error: 0.5068\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2625 - landcover_loss: 0.8188 - canopy_loss: 0.4437 - landcover_acc: 0.6280 - canopy_mean_absolute_error: 0.5078 - val_loss: 1.2722 - val_landcover_loss: 0.8265 - val_canopy_loss: 0.4457 - val_landcover_acc: 0.6151 - val_canopy_mean_absolute_error: 0.5090\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2585 - landcover_loss: 0.8161 - canopy_loss: 0.4424 - landcover_acc: 0.6313 - canopy_mean_absolute_error: 0.5063 - val_loss: 1.2721 - val_landcover_loss: 0.8272 - val_canopy_loss: 0.4449 - val_landcover_acc: 0.6034 - val_canopy_mean_absolute_error: 0.5079\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2589 - landcover_loss: 0.8161 - canopy_loss: 0.4428 - landcover_acc: 0.6324 - canopy_mean_absolute_error: 0.5069 - val_loss: 1.2685 - val_landcover_loss: 0.8284 - val_canopy_loss: 0.4401 - val_landcover_acc: 0.6086 - val_canopy_mean_absolute_error: 0.5030\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2573 - landcover_loss: 0.8151 - canopy_loss: 0.4422 - landcover_acc: 0.6323 - canopy_mean_absolute_error: 0.5061 - val_loss: 1.2714 - val_landcover_loss: 0.8261 - val_canopy_loss: 0.4453 - val_landcover_acc: 0.6146 - val_canopy_mean_absolute_error: 0.5084\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2572 - landcover_loss: 0.8147 - canopy_loss: 0.4424 - landcover_acc: 0.6319 - canopy_mean_absolute_error: 0.5064 - val_loss: 1.2688 - val_landcover_loss: 0.8273 - val_canopy_loss: 0.4415 - val_landcover_acc: 0.6214 - val_canopy_mean_absolute_error: 0.5044\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2578 - landcover_loss: 0.8152 - canopy_loss: 0.4426 - landcover_acc: 0.6318 - canopy_mean_absolute_error: 0.5065 - val_loss: 1.2688 - val_landcover_loss: 0.8263 - val_canopy_loss: 0.4424 - val_landcover_acc: 0.6029 - val_canopy_mean_absolute_error: 0.5051\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2597 - landcover_loss: 0.8163 - canopy_loss: 0.4434 - landcover_acc: 0.6310 - canopy_mean_absolute_error: 0.5074 - val_loss: 1.2681 - val_landcover_loss: 0.8249 - val_canopy_loss: 0.4432 - val_landcover_acc: 0.6193 - val_canopy_mean_absolute_error: 0.5061\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2589 - landcover_loss: 0.8159 - canopy_loss: 0.4430 - landcover_acc: 0.6315 - canopy_mean_absolute_error: 0.5071 - val_loss: 1.2639 - val_landcover_loss: 0.8248 - val_canopy_loss: 0.4391 - val_landcover_acc: 0.6066 - val_canopy_mean_absolute_error: 0.5017\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.2633 - landcover_loss: 0.8211 - canopy_loss: 0.4423 - landcover_acc: 0.6323 - canopy_mean_absolute_error: 0.5063 - val_loss: 1.2745 - val_landcover_loss: 0.8310 - val_canopy_loss: 0.4435 - val_landcover_acc: 0.5753 - val_canopy_mean_absolute_error: 0.5063\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.0254 - landcover_loss: 0.8255 - canopy_loss: 0.1999 - landcover_acc: 0.6175 - canopy_mean_absolute_error: 0.3224 - val_loss: 0.9844 - val_landcover_loss: 0.8576 - val_canopy_loss: 0.1269 - val_landcover_acc: 0.6242 - val_canopy_mean_absolute_error: 0.3001\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 1.0041 - landcover_loss: 0.8952 - canopy_loss: 0.1089 - landcover_acc: 0.1589 - canopy_mean_absolute_error: 0.2561 - val_loss: 1.0026 - val_landcover_loss: 0.9074 - val_canopy_loss: 0.0952 - val_landcover_acc: 0.0982 - val_canopy_mean_absolute_error: 0.2334\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 0.7752 - landcover_loss: 0.6776 - canopy_loss: 0.0976 - landcover_acc: 0.4458 - canopy_mean_absolute_error: 0.2366 - val_loss: 0.7137 - val_landcover_loss: 0.6178 - val_canopy_loss: 0.0959 - val_landcover_acc: 0.4871 - val_canopy_mean_absolute_error: 0.2362\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 0.6203 - landcover_loss: 0.5275 - canopy_loss: 0.0929 - landcover_acc: 0.5996 - canopy_mean_absolute_error: 0.2285 - val_loss: 0.5954 - val_landcover_loss: 0.5035 - val_canopy_loss: 0.0919 - val_landcover_acc: 0.5990 - val_canopy_mean_absolute_error: 0.2247\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 0.5896 - landcover_loss: 0.5367 - canopy_loss: 0.0530 - landcover_acc: 0.6484 - canopy_mean_absolute_error: 0.1418 - val_loss: 0.5698 - val_landcover_loss: 0.5357 - val_canopy_loss: 0.0341 - val_landcover_acc: 0.6475 - val_canopy_mean_absolute_error: 0.1024\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 0.5114 - landcover_loss: 0.4796 - canopy_loss: 0.0318 - landcover_acc: 0.6384 - canopy_mean_absolute_error: 0.0958 - val_loss: 0.5106 - val_landcover_loss: 0.4828 - val_canopy_loss: 0.0278 - val_landcover_acc: 0.6142 - val_canopy_mean_absolute_error: 0.0861\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 0.5031 - landcover_loss: 0.4720 - canopy_loss: 0.0310 - landcover_acc: 0.6352 - canopy_mean_absolute_error: 0.0928 - val_loss: 0.5097 - val_landcover_loss: 0.4849 - val_canopy_loss: 0.0248 - val_landcover_acc: 0.6120 - val_canopy_mean_absolute_error: 0.0830\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 0.4890 - landcover_loss: 0.4620 - canopy_loss: 0.0270 - landcover_acc: 0.6349 - canopy_mean_absolute_error: 0.0843 - val_loss: 0.5053 - val_landcover_loss: 0.4812 - val_canopy_loss: 0.0241 - val_landcover_acc: 0.6090 - val_canopy_mean_absolute_error: 0.0786\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 0.4813 - landcover_loss: 0.4586 - canopy_loss: 0.0227 - landcover_acc: 0.6369 - canopy_mean_absolute_error: 0.0771 - val_loss: 0.5059 - val_landcover_loss: 0.4812 - val_canopy_loss: 0.0247 - val_landcover_acc: 0.5967 - val_canopy_mean_absolute_error: 0.0789\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 110s 2s/step - loss: 0.4819 - landcover_loss: 0.4592 - canopy_loss: 0.0227 - landcover_acc: 0.6355 - canopy_mean_absolute_error: 0.0767 - val_loss: 0.4909 - val_landcover_loss: 0.4712 - val_canopy_loss: 0.0198 - val_landcover_acc: 0.6173 - val_canopy_mean_absolute_error: 0.0709\n",
      "Epoch 23/200\n",
      "34/69 [=============>................] - ETA: 50s - loss: 0.4845 - landcover_loss: 0.4637 - canopy_loss: 0.0208 - landcover_acc: 0.6243 - canopy_mean_absolute_error: 0.0725"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-d50bb0cc6b8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_px\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtile_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_px\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     validation_steps=len(val_px) // batch_size)# callbacks=callbacks_list) #class_weight=weights, callbacks=callbacks_list) \n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=tile_gen.tile_generator(train_px, batch_size), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=tile_gen.tile_generator(val_px, batch_size),\n",
    "                    validation_steps=len(val_px) // batch_size)# callbacks=callbacks_list) #class_weight=weights, callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 4, 64, 64, 7) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 4, 64, 64, 7) 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 4, 64, 64, 7) 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 4, 64, 64, 7) 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 4, 64, 64, 7) 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_7 (Model)                 [(None, 64, 64, 6),  1191732     lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "landcover (Concatenate)         (None, 64, 64, 6)    0           model_7[1][0]                    \n",
      "                                                                 model_7[2][0]                    \n",
      "                                                                 model_7[3][0]                    \n",
      "                                                                 model_7[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "canopy (Concatenate)            (None, 64, 64, 1)    0           model_7[1][1]                    \n",
      "                                                                 model_7[2][1]                    \n",
      "                                                                 model_7[3][1]                    \n",
      "                                                                 model_7[4][1]                    \n",
      "==================================================================================================\n",
      "Total params: 1,191,732\n",
      "Trainable params: 1,191,732\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model.load_weights('strange_v3_merged.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 63s 165ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(generator = tile_gen.tile_generator(test_px, batch_size=1), steps=len(test_px) // 1, verbose=1)\n",
    "eval_generator = tile_gen.tile_generator(test_px, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = np.asarray(predictions[0])\n",
    "canopy = np.asarray(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.7310586 ],\n",
       "        [0.880797  ],\n",
       "        [0.880797  ],\n",
       "        ...,\n",
       "        [0.880797  ],\n",
       "        [0.880797  ],\n",
       "        [0.880797  ]],\n",
       "\n",
       "       [[0.880797  ],\n",
       "        [0.880797  ],\n",
       "        [0.95257413],\n",
       "        ...,\n",
       "        [0.95257413],\n",
       "        [0.95257413],\n",
       "        [0.880797  ]],\n",
       "\n",
       "       [[0.880797  ],\n",
       "        [0.95257413],\n",
       "        [0.95257413],\n",
       "        ...,\n",
       "        [0.95257413],\n",
       "        [0.95257413],\n",
       "        [0.880797  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.7310586 ],\n",
       "        [0.7310586 ],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.880797  ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.7310586 ],\n",
       "        [0.        ],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canopy[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(predictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangeBlock(input_block, nb_layers, filters):\n",
    "    x_list = [input_block]\n",
    "    c_temp = input_block\n",
    "    for i in range(nb_layers):\n",
    "        c_l = Bidirectional(ConvLSTM2D(filters=filters,kernel_size=(3,3), activation='elu', padding = 'same', return_sequences=True)) (c_temp)\n",
    "        x_list.append(c_l)\n",
    "        merge = Concatenate()(x_list)\n",
    "        c_temp = merge\n",
    "    return c_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty(pred.shape)\n",
    "count = 0\n",
    "while count < len(labels):\n",
    "        image_b, label_b = next(eval_generator)\n",
    "        label_b = np.argmax(label_b, axis=-1)\n",
    "        labels[count] = label_b\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = labels.reshape(len(test_px)*4096)\n",
    "pred_index = pred.reshape(len(test_px)*4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(util.indexed_dictionary)),\n",
    "                      class_dict=util.indexed_dictionary)\n",
    "# Plot normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(util.indexed_dictionary)),\n",
    "                      class_dict=util.indexed_dictionary,\n",
    "                      normalize=True)\n",
    "count = 0\n",
    "for i in range(len(label_index)):\n",
    "    if(label_index[i] == pred_index[i]):\n",
    "        count+=1\n",
    "print(\"Accuracy is {}\".format(count/len(label_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels(label_index, pred_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network(input_shape):\n",
    "    input_img = Input(input_shape)\n",
    "    #c_l1 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (input_img)\n",
    "    #c_l2 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (c_l1)\n",
    "    c_l3 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (input_img)\n",
    "    #pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (c_l3)\n",
    "    #c_l4 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (pool_1)\n",
    "    #c_l5 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (c_l4)\n",
    "    #c_l6 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (pool_1)\n",
    "    #upsample_1 = TimeDistributed(UpSampling2D((3,3))) (c_l6)\n",
    "    conv_1 = TimeDistributed(Conv2D(32, (3,3), padding='same'))(c_l3)\n",
    "    #merge = Concatenate()([c_l3, conv_1])\n",
    "    conv_lc = ConvLSTM2D(filters=16,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False) (conv_1)\n",
    "    #conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), activation='sigmoid', padding = 'same', return_sequences=False)(merge)\n",
    "    #model = Model(inputs=input_img, outputs=[conv_lc, conv_out_cc])\n",
    "    model = Model(inputs=input_img, outputs=conv_lc)\n",
    "    return model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)\n",
    "w_generator = w_tile_gen.tile_generator(pixels, batch_size=1)\n",
    "total_labels = list()\n",
    "count = 0\n",
    "while count < len(pixels):\n",
    "        image_b, label_b = next(w_generator)\n",
    "        label_b = np.argmax(label_b, axis=-1)\n",
    "        total_labels.append(label_b)\n",
    "        count+=1\n",
    "total_labels = np.asarray(total_labels)\n",
    "total_labels = total_labels.reshape(len(total_labels)*64*64)\n",
    "buckets = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0}\n",
    "for label in total_labels:\n",
    "    buckets[label] +=1\n",
    "print(buckets)\n",
    "weights_list = class_weight.compute_class_weight('balanced', np.unique(total_labels), total_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
