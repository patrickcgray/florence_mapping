{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Tile Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare 1 season (summer) and 4 temporal steps\n",
    "* Compare 0 - 1500 training training samples per class in 100 sample increments\n",
    "* CNN component and RNN components in isolation\n",
    "* regular CNN+RNN vs conv2dlstm and RNN vs just conv2dLSTM\n",
    "* Compare to scikit-learn methods using same val and test datasets\n",
    "* Compare best model across time\n",
    "    * if major decrease in accuracy then consider training on both 2010 and 2011 data for initial time step\n",
    "        * consider training on 1999 data to see how it changes the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "\n",
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "import rasterio\n",
    "import keras\n",
    "import random\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Bidirectional\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPooling3D, ConvLSTM2D, TimeDistributed, UpSampling2D, Concatenate, LSTM, concatenate\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import utilities as util\n",
    "import importlib\n",
    "import rnn_tiles\n",
    "import rnn_pixels\n",
    "import numpy as np\n",
    "\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Proj, transform\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon, Point\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/host/Code/florence_mapping/utilities.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rnn_pixels)\n",
    "importlib.reload(rnn_tiles)\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign your specific GPU so we don't overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that GPU and only that GPU visible?\n",
    "\n",
    "Note that it will always say GPU:0 but you should just see one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest Training Labels\n",
    "\n",
    "Note that these are monster files so be careful how you inspect them, typically you only want to use the `rasterio` windows option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/landcover/NLCD_2011_Land_Cover_L48_20190424.img')\n",
    "canopy_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/canopy/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img')\n",
    "class_dict = util.indexed_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest the landsat imagery stacked into yearly seasonal tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = {}\n",
    "landsat_datasets = {}\n",
    "tiles['028012'] = ['20110103', '20110308', '20110730', '20110831', '20111103']\n",
    "tiles['029011'] = ['20110103', '20110308', '20110730', '20110831', '20111018']\n",
    "tiles['028011'] = ['20110103', '20110308', '20110831', '20111018', '20111103']\n",
    "\n",
    "for tile_number, dates in tiles.items():\n",
    "    tile_datasets = []\n",
    "    l8_image_paths = []\n",
    "    for date in dates:\n",
    "        l8_image_paths.append('/deep_data/recurrent_data/tile{}/combined/combined{}.tif'.format(tile_number, date))\n",
    "    for fp in l8_image_paths:\n",
    "        tile_datasets.append(rasterio.open(fp))\n",
    "    landsat_datasets[tile_number] = tile_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_pixels(tile):\n",
    "    points = []\n",
    "    l8_points = []\n",
    "    x = np.arange(0, 5000, 1)\n",
    "    y = np.arange(0, 5000, 1)\n",
    "    for row in y:\n",
    "        for col in x:\n",
    "            point = (row, col)\n",
    "            points.append(point)\n",
    "    for point in points:\n",
    "        l8_points.append((point, tile))\n",
    "    return l8_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_bad_tiles(l8_data, lc_label, canopy_label, pixels, tile_size, buffer_pix=None):\n",
    "    buffer = math.floor(tile_size / 2)\n",
    "    cloud_list = [-999999] # nothing # high confidence cloud [224] # full list [72, 80, 96, 130, 132, 136, 160, 224]\n",
    "    new_pixels = []\n",
    "    l8_proj = Proj(l8_data['028012'][0].crs)\n",
    "    lc_proj = Proj(lc_label.crs)\n",
    "    canopy_proj = Proj(canopy_label.crs)\n",
    "    counter = 0\n",
    "    center_index = math.floor(tile_size / 2)\n",
    "    l8_mask = [1] * len(pixels)\n",
    "    for idx, pixel in enumerate(pixels):\n",
    "        r, c = pixel[0]\n",
    "        dataset_index = pixel[1]\n",
    "        tiles_to_read = l8_data[dataset_index]\n",
    "        tiles_read = util.read_windows(tiles_to_read, c ,r, buffer, tile_size)\n",
    "        (x, y) = l8_data[dataset_index][0].xy(r, c) \n",
    "        # convert the point we're sampling from to the same projection as the label dataset if necessary\n",
    "        #if l8_proj != lc_proj:\n",
    "            #lc_x,lc_y = transform(l8_proj,lc_proj,x,y)\n",
    "        lc_x,lc_y = x,y\n",
    "        # these are broken and not working for some reason because pyproj doesn't understand the canopy projection\n",
    "        #if l8_proj != canopy_proj:\n",
    "        #    canopy_x, canopy_y = transform(l8_proj,canopy_proj,x,y)\n",
    "        # but luckily there only a couple cm different so it shouldn't matter\n",
    "        canopy_x = x\n",
    "        canopy_y = y\n",
    "        # reference gps in label_image\n",
    "        lc_row, lc_col = lc_label.index(lc_x,lc_y)\n",
    " \n",
    "        lc_data = lc_label.read(1, window=Window(lc_col-buffer, lc_row-buffer, tile_size, tile_size))\n",
    "        canopy_row, canopy_col = canopy_label.index(canopy_x,canopy_y)\n",
    "        canopy_data = canopy_label.read(1, window=Window(canopy_col-buffer, canopy_row-buffer, tile_size, tile_size))\n",
    "        flag = True\n",
    "        # this used to eliminate pixels with only a single value to balance the FCN but now we don't want that\n",
    "        #if len(np.unique(lc_data)) == 1 and 11 in lc_data and tile_size != 1:\n",
    "        #    flag = False\n",
    "        \n",
    "        if 0 in lc_data or np.nan in lc_data or np.nan in canopy_data or 255 in canopy_data or canopy_data.shape != (tile_size, tile_size):\n",
    "            flag = False\n",
    "        #counter += 1\n",
    "        \n",
    "        if flag:\n",
    "            # TODO this can very likely be optimized and doesn't need to be a for loop\n",
    "            for tile in tiles_read:\n",
    "                if np.isnan(tile).any() == True or -9999 in tile or tile.size == 0 or np.amax(tile) == 0 or np.isin(tile[7,:,:], cloud_list).any() or tile.shape != (l8_data[dataset_index][0].count, tile_size, tile_size):\n",
    "                    flag = False\n",
    "                    break\n",
    "                \n",
    "        if buffer_pix and flag:\n",
    "            # check all surrounding pixels with a radius of buffer_pix and if any are a different value then \n",
    "            # flag it and don't include it in the output\n",
    "            lc_data_merged = np.vectorize(util.class_to_index.get)(lc_data)\n",
    "            if len(np.unique(lc_data_merged[center_index-buffer_pix:center_index+buffer_pix+1, center_index-buffer_pix:center_index+buffer_pix+1])) != 1:\n",
    "                flag = False\n",
    "        \n",
    "        if flag:\n",
    "            new_pixels.append(pixel)\n",
    "        else:\n",
    "            l8_mask[idx] = 0\n",
    "            \n",
    "        if counter % 1000 == 0:\n",
    "            #print(counter)\n",
    "            pass\n",
    "    returnnew_pixels, l8_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), '028012'),\n",
       " ((0, 1), '028012'),\n",
       " ((0, 2), '028012'),\n",
       " ((0, 3), '028012'),\n",
       " ((0, 4), '028012'),\n",
       " ((0, 5), '028012'),\n",
       " ((0, 6), '028012'),\n",
       " ((0, 7), '028012'),\n",
       " ((0, 8), '028012'),\n",
       " ((0, 9), '028012')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_px = make_all_pixels('028012')\n",
    "all_px[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-19 00:23:28.928236\n"
     ]
    }
   ],
   "source": [
    "tile_size = 13\n",
    "print(datetime.datetime.now())\n",
    "clean_px, l8_mask = delete_bad_tiles(landsat_datasets,lc_labels, canopy_labels, all_px, tile_size)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(l8_mask, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('mlt_dense_model_pcg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 13\n",
    "class_count = 6\n",
    "print(datetime.datetime.now())\n",
    "tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "predictions = model.predict_generator(generator = tile_gen.tile_generator(clean_px, batch_size=50, flatten=True, canopy=True), steps=len(clean_px) // 50, verbose=1)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_mask_np = np.array(l8_mask) #.reshape(1500,1500)\n",
    "l8_mask_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_idx = np.argmax(predictions, axis=-1)\n",
    "len(pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_mask_np[l8_mask_np == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = len(clean_px) - len(pred_idx)\n",
    "for x in range(diff):\n",
    "    pred_idx = np.append(pred_idx,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_mask_np[l8_mask_np == 1] = pred_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "# Build a listed colormap.\n",
    "c_map = colors.ListedColormap(['black', 'blue', 'red', 'darkgreen', 'saddlebrown', 'bisque', 'purple'])\n",
    "bounds = [-1, 0, 1, 2, 3,4,5,6]\n",
    "norm = colors.BoundaryNorm(bounds, c_map.N)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10,12))\n",
    "\n",
    "# Plot the image with a color bar\n",
    "axs = plt.imshow(l8_mask_np.reshape(3000,3000), cmap=c_map, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3000 = l8_mask_np.reshape(3000,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter\n",
    "\n",
    "filtered_array = median_filter(img3000, size=7)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(15,18))\n",
    "\n",
    "# Plot the image with a color bar\n",
    "axs[0].imshow(img3000, cmap=c_map, norm=norm)\n",
    "axs[1].imshow(filtered_array, cmap=c_map, norm=norm)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('img3000.npy', img3000)\n",
    "np.load('img3000.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
