{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/host/Desktop/cnn_dev/florence_mapping/utilities.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rasterio\n",
    "import keras\n",
    "import random\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Bidirectional\n",
    "from keras.layers import Conv2D, MaxPooling2D, ConvLSTM2D, TimeDistributed, UpSampling2D, Concatenate, LSTM\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import utilities as util\n",
    "import importlib\n",
    "import rnn_tiles\n",
    "import rnn_pixels\n",
    "import numpy as np\n",
    "importlib.reload(rnn_pixels)\n",
    "importlib.reload(rnn_tiles)\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/landcover/NLCD_2011_Land_Cover_L48_20190424.img')\n",
    "canopy_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/canopy/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = {}\n",
    "landsat_datasets = {}\n",
    "tiles['028012'] = ['20110324', '20110612', '20110831', '20111103']\n",
    "tiles['029011'] = ['20110308', '20110425', '20110831', '20111103']\n",
    "tiles['028011'] = ['20110308', '20110628', '20110831', '20111103']\n",
    "for tile_number, dates in tiles.items():\n",
    "    tile_datasets = []\n",
    "    l8_image_paths = []\n",
    "    for date in dates:\n",
    "        l8_image_paths.append('/deep_data/recurrent_data/tile{}/combined/combined{}.tif'.format(tile_number, date))\n",
    "    for fp in l8_image_paths:\n",
    "        tile_datasets.append(rasterio.open(fp))\n",
    "    landsat_datasets[tile_number] = tile_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 1\n",
    "tile_list = ['028012', '029011', '028011']\n",
    "class_count = 6\n",
    "epochs = 200\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The next two cells are for making pixels and prepping them for training (balancing)\n",
    "### This is unnecessary to run because I already saved them to text files so now you load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px = rnn_pixels.make_pixels(tile_size, tile_list)\n",
    "px_to_use = px[:1000000]\n",
    "pixels = rnn_pixels.delete_bad_tiles(landsat_datasets,lc_labels, canopy_labels, px_to_use, tile_size)\n",
    "train_px, val_px, test_px = rnn_pixels.train_val_test_split(use_px, 0.7, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets balanced pixels locations \n",
    "w_tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)\n",
    "w_generator = w_tile_gen.tile_generator(pixels, batch_size=1, flatten=True, canopy=False)\n",
    "total_labels = list()\n",
    "count = 0\n",
    "#buckets = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "buckets = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[], 10:[], 11:[], 12:[]}\n",
    "\n",
    "while count < len(pixels):\n",
    "        image_b, label_b = next(w_generator)\n",
    "        label_b = np.argmax(label_b)\n",
    "        buckets[label_b].append(pixels[count]) # appends pixels to dictionary\n",
    "        total_labels.append(label_b)\n",
    "        count+=1\n",
    "total_labels = np.asarray(total_labels)\n",
    "total_labels = total_labels.reshape(len(total_labels)*tile_size*tile_size)\n",
    "#weights_list = class_weight.compute_class_weight('balanced', np.unique(total_labels), total_labels)\n",
    "count = 0 \n",
    "for z, j in buckets.items():\n",
    "    print(len(j))\n",
    "    count += len(j)\n",
    "print(count) \n",
    "use_px = []\n",
    "use_px+=buckets[0][:3000]\n",
    "use_px+=(buckets[1][:3000])\n",
    "use_px+=(buckets[2][:3000])\n",
    "use_px+=(buckets[3][:3000])\n",
    "use_px+=(buckets[4][:3000])\n",
    "use_px+=(buckets[5][:3000])\n",
    "random.shuffle(use_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_px, val_px, test_px = util.read_txt(['train_px.txt', 'val_px.txt', 'test_px.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangeBlock_v4(input_block, nb_layers, filters):\n",
    "    x_list = [input_block]\n",
    "    c_temp = input_block\n",
    "    for i in range(nb_layers):\n",
    "        c_l = LSTM(units=filters, activation='elu', return_sequences=True) (c_temp)\n",
    "        x_list.append(c_l)\n",
    "        merge = Concatenate()(x_list)\n",
    "        c_temp = merge\n",
    "    return c_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLT_dense(in_shape, num_classes):\n",
    "    input_tensor = Input(shape = in_shape)\n",
    "    block = strangeBlock_v4(input_tensor, 5, 12)\n",
    "    block_2 = strangeBlock_v4(block, 3, 20)\n",
    "    landcover = LSTM(num_classes,activation='softmax', return_sequences=False, name='landcover') (block_2)\n",
    "    canopy = LSTM(1, return_sequences=False, name='canopy') (block_2)\n",
    "    model = Model(inputs=input_tensor, outputs=[landcover, canopy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_MLT_dense((4,7), class_count)\n",
    "model.summary()\n",
    "model.load_weights('mlt_dense_merged_2.hdf5')\n",
    "#model = keras.utils.multi_gpu_model(model, 4) SUPER SPEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = #NAME THIS HERE FOR CHECKPOINT\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_landcover_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss={'landcover':'categorical_crossentropy', 'canopy':'mse'}, metrics={'landcover':['accuracy'], 'canopy':['mae']}, loss_weights={\"landcover\":1, \"canopy\":1})\n",
    "#model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=tile_gen.tile_generator(train_px, batch_size, flatten=True, canopy=True), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=tile_gen.tile_generator(val_px, batch_size, flatten=True, canopy=True),\n",
    "                    validation_steps=len(val_px) // batch_size, callbacks=callbacks_list)# class_weight=weights_list)# callbacks=callbacks_list) #class_weight=weights, callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator = tile_gen.tile_generator(test_px, batch_size=1, flatten=True, canopy=True), steps=len(test_px) // 1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator = tile_gen.tile_generator(test_px, batch_size=1, flatten=True, canopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_predictions = np.asarray(predictions[0])\n",
    "canopy_pred = np.asarray(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_predictions = np.argmax(lc_predictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_lab = np.empty(lc_predictions.shape)\n",
    "canopy_true = np.empty(canopy_pred.shape)\n",
    "count = 0\n",
    "while count < len(lc_predictions):\n",
    "        image_b, label_b = next(eval_generator)\n",
    "        #label_b = np.argmax(label_b, axis=-1)\n",
    "        label_lc = np.argmax(label_b['landcover'], axis=-1)\n",
    "        canopy_true[count] = label_b['canopy']\n",
    "        lc_lab[count] = label_lc\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = lc_lab.reshape(len(test_px)*tile_size*tile_size)\n",
    "pred_index = lc_predictions.reshape(len(test_px)*tile_size*tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "tot = 0\n",
    "\n",
    "for count in range(len(canopy_pred)):\n",
    "    if canopy_true[count] != 0:\n",
    "        total+= np.absolute(canopy_pred[count] - canopy_true[count])\n",
    "        tot+=1\n",
    "print(total/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.hist(canopy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.hist(canopy_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(util.indexed_dictionary)),\n",
    "                      class_dict=util.indexed_dictionary)\n",
    "# Plot normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(util.indexed_dictionary)),\n",
    "                      class_dict=util.indexed_dictionary,\n",
    "                      normalize=True)\n",
    "count = 0\n",
    "for i in range(len(label_index)):\n",
    "    if(label_index[i] == pred_index[i]):\n",
    "        count+=1\n",
    "print(\"Accuracy is {}\".format(count/len(label_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangeBlock(input_block, nb_layers, filters):\n",
    "    x_list = [input_block]\n",
    "    c_temp = input_block\n",
    "    for i in range(nb_layers):\n",
    "        c_l = Bidirectional(ConvLSTM2D(filters=filters,kernel_size=(3,3), activation='elu', padding = 'same', return_sequences=True)) (c_temp)\n",
    "        x_list.append(c_l)\n",
    "        merge = Concatenate()(x_list)\n",
    "        c_temp = merge\n",
    "    return c_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels(label_index, pred_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network(input_shape):\n",
    "    input_img = Input(input_shape)\n",
    "    #c_l1 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (input_img)\n",
    "    #c_l2 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (c_l1)\n",
    "    c_l3 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (input_img)\n",
    "    #pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (c_l3)\n",
    "    #c_l4 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (pool_1)\n",
    "    #c_l5 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (c_l4)\n",
    "    #c_l6 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (pool_1)\n",
    "    #upsample_1 = TimeDistributed(UpSampling2D((3,3))) (c_l6)\n",
    "    conv_1 = TimeDistributed(Conv2D(32, (3,3), padding='same'))(c_l3)\n",
    "    #merge = Concatenate()([c_l3, conv_1])\n",
    "    conv_lc = ConvLSTM2D(filters=16,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False) (conv_1)\n",
    "    #conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), activation='sigmoid', padding = 'same', return_sequences=False)(merge)\n",
    "    #model = Model(inputs=input_img, outputs=[conv_lc, conv_out_cc])\n",
    "    model = Model(inputs=input_img, outputs=conv_lc)\n",
    "    return model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    \"\"\"Jaccard distance for semantic segmentation.\n",
    "    Also known as the intersection-over-union loss.\n",
    "    This loss is useful when you have unbalanced numbers of pixels within an image\n",
    "    because it gives all classes equal weight. However, it is not the defacto\n",
    "    standard for image segmentation.\n",
    "    For example, assume you are trying to predict if\n",
    "    each pixel is cat, dog, or background.\n",
    "    You have 80% background pixels, 10% dog, and 10% cat.\n",
    "    If the model predicts 100% background\n",
    "    should it be be 80% right (as with categorical cross entropy)\n",
    "    or 30% (with this loss)?\n",
    "    The loss has been modified to have a smooth gradient as it converges on zero.\n",
    "    This has been shifted so it converges on 0 and is smoothed to avoid exploding\n",
    "    or disappearing gradient.\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    # Arguments\n",
    "        y_true: The ground truth tensor.\n",
    "        y_pred: The predicted tensor\n",
    "        smooth: Smoothing factor. Default is 100.\n",
    "    # Returns\n",
    "        The Jaccard distance between the two tensors.\n",
    "    # References\n",
    "        - [What is a good evaluation measure for semantic segmentation?](\n",
    "           http://www.bmva.org/bmvc/2013/Papers/paper0032/paper0032.pdf)\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
