{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rnn_tiles' from '/host/Desktop/cnn_dev/florence_mapping/rcnn/rnn_tiles.py'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rasterio\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Bidirectional\n",
    "from keras.layers import Conv2D, MaxPooling2D, ConvLSTM2D, TimeDistributed, UpSampling2D, Concatenate\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import utilities as util\n",
    "import importlib\n",
    "import rnn_tiles\n",
    "import rnn_pixels\n",
    "import numpy as np\n",
    "importlib.reload(rnn_pixels)\n",
    "importlib.reload(rnn_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11: 0,\n",
       " 21: 3,\n",
       " 22: 1,\n",
       " 23: 1,\n",
       " 24: 1,\n",
       " 31: 4,\n",
       " 41: 2,\n",
       " 42: 2,\n",
       " 43: 2,\n",
       " 52: 2,\n",
       " 71: 3,\n",
       " 81: 3,\n",
       " 82: 3,\n",
       " 90: 2,\n",
       " 95: 5}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangeBlock(input_block, nb_layers, filters):\n",
    "    x_list = [input_block]\n",
    "    c_temp = input_block\n",
    "    for i in range(nb_layers):\n",
    "        c_l = ConvLSTM2D(filters=filters,kernel_size=(3,3), activation='elu', padding = 'same', return_sequences=True) (c_temp)\n",
    "        x_list.append(c_l)\n",
    "        merge = Concatenate()(x_list)\n",
    "        c_temp = merge\n",
    "    return c_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network_v2(input_shape, class_count):\n",
    "    input_img = Input(input_shape)\n",
    "    strange_block_1 = strangeBlock(input_img, 4, 20)\n",
    "    pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (strange_block_1)\n",
    "    strange_block_2 = strangeBlock(pool_1, 4, 20)\n",
    "    upsample_1 = TimeDistributed(UpSampling2D((3,3))) (strange_block_2)\n",
    "    conv_1 = TimeDistributed(Conv2D(32, (3,3)))(upsample_1)\n",
    "    conv_lc = ConvLSTM2D(filters=class_count,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False, name='landcover') (conv_1)\n",
    "    reshaping = Reshape((64*64,class_count)) (conv_lc)\n",
    "    #conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), padding = 'same', return_sequences=False, name='canopy')(conv_1)\n",
    "    model = Model(inputs=input_img, outputs=reshaping)  # conv_out_cc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network_v3(input_shape, class_count):\n",
    "    input_img = Input(input_shape)\n",
    "    strange_block_1 = strangeBlock(input_img, 4, 20)\n",
    "    #pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (strange_block_1)\n",
    "    strange_block_2 = strangeBlock(strange_block_1, 4, 20)\n",
    "    conv_lc = ConvLSTM2D(filters=class_count,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False, name='landcover') (strange_block_2)\n",
    "    reshaping = Reshape((64*64,class_count)) (conv_lc)\n",
    "    #conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), padding = 'same', return_sequences=False, name='canopy')(conv_1)\n",
    "    model = Model(inputs=input_img, outputs=reshaping)  # conv_out_cc])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network_v4(input_shape, class_count):\n",
    "    input_img = Input(input_shape)\n",
    "    strange_block_1 = strangeBlock(input_img, 4, 20)\n",
    "    #pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (strange_block_1)\n",
    "    strange_block_2 = strangeBlock(strange_block_1, 4, 20)\n",
    "    strange_block_3 = strangeBlock(strange_block_2, 4, 20)\n",
    "    conv_lc = ConvLSTM2D(filters=class_count,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False, name='landcover') (strange_block_3)\n",
    "    conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), activation='sigmoid' padding = 'same', return_sequences=False, name='canopy')(strange_block_3)\n",
    "    model = Model(inputs=input_img, outputs=[conv_lc, conv_out_cc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/landcover/NLCD_2011_Land_Cover_L48_20190424.img')\n",
    "canopy_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/canopy/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = {}\n",
    "landsat_datasets = {}\n",
    "tiles['028012'] = ['20110324', '20110612', '20110831', '20111103']\n",
    "tiles['029011'] = ['20110308', '20110425', '20110831', '20111103']\n",
    "tiles['028011'] = ['20110308', '20110628', '20110831', '20111103']\n",
    "for tile_number, dates in tiles.items():\n",
    "    tile_datasets = []\n",
    "    l8_image_paths = []\n",
    "    for date in dates:\n",
    "        l8_image_paths.append('/deep_data/recurrent_data/tile{}/combined/combined{}.tif'.format(tile_number, date))\n",
    "    for fp in l8_image_paths:\n",
    "        tile_datasets.append(rasterio.open(fp))\n",
    "    landsat_datasets[tile_number] = tile_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 64\n",
    "tile_list = ['028012', '029011', '028011']\n",
    "class_count = 6\n",
    "epochs = 200\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px = rnn_pixels.make_pixels(tile_size, tile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixels = rnn_pixels.delete_bad_tiles(landsat_datasets,lc_labels, canopy_labels, px, tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2481"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:1736 val:521 test:381\n"
     ]
    }
   ],
   "source": [
    "train_px, val_px, test_px = rnn_pixels.train_val_test_split(pixels, 0.7, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = strange_network_v4((4, 64, 64, 7), class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 4, 64, 64, 7) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 4, 64, 64, 7) 0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 4, 64, 64, 7) 0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 4, 64, 64, 7) 0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 4, 64, 64, 7) 0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 [(None, 64, 64, 6),  564212      lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "landcover (Concatenate)         (None, 64, 64, 6)    0           model_5[1][0]                    \n",
      "                                                                 model_5[2][0]                    \n",
      "                                                                 model_5[3][0]                    \n",
      "                                                                 model_5[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "canopy (Concatenate)            (None, 64, 64, 1)    0           model_5[1][1]                    \n",
      "                                                                 model_5[2][1]                    \n",
      "                                                                 model_5[3][1]                    \n",
      "                                                                 model_5[4][1]                    \n",
      "==================================================================================================\n",
      "Total params: 564,212\n",
      "Trainable params: 564,212\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.utils.multi_gpu_model(model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath ='strange_v4_merged.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    \"\"\"Jaccard distance for semantic segmentation.\n",
    "    Also known as the intersection-over-union loss.\n",
    "    This loss is useful when you have unbalanced numbers of pixels within an image\n",
    "    because it gives all classes equal weight. However, it is not the defacto\n",
    "    standard for image segmentation.\n",
    "    For example, assume you are trying to predict if\n",
    "    each pixel is cat, dog, or background.\n",
    "    You have 80% background pixels, 10% dog, and 10% cat.\n",
    "    If the model predicts 100% background\n",
    "    should it be be 80% right (as with categorical cross entropy)\n",
    "    or 30% (with this loss)?\n",
    "    The loss has been modified to have a smooth gradient as it converges on zero.\n",
    "    This has been shifted so it converges on 0 and is smoothed to avoid exploding\n",
    "    or disappearing gradient.\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    # Arguments\n",
    "        y_true: The ground truth tensor.\n",
    "        y_pred: The predicted tensor\n",
    "        smooth: Smoothing factor. Default is 100.\n",
    "    # Returns\n",
    "        The Jaccard distance between the two tensors.\n",
    "    # References\n",
    "        - [What is a good evaluation measure for semantic segmentation?](\n",
    "           http://www.bmva.org/bmvc/2013/Papers/paper0032/paper0032.pdf)\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss={'landcover':jaccard_distance, 'canopy':'mse'}, metrics={'landcover':['accuracy'], 'canopy':['mae']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8, labels = next(tile_gen.tile_generator(train_px, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]]],\n",
       "\n",
       "\n",
       "       [[[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 89.],\n",
       "         [ 92.],\n",
       "         [ 88.],\n",
       "         ...,\n",
       "         [ 97.],\n",
       "         [ 99.],\n",
       "         [100.]],\n",
       "\n",
       "        [[ 80.],\n",
       "         [ 91.],\n",
       "         [ 91.],\n",
       "         ...,\n",
       "         [ 95.],\n",
       "         [ 96.],\n",
       "         [ 97.]],\n",
       "\n",
       "        [[ 76.],\n",
       "         [ 62.],\n",
       "         [ 87.],\n",
       "         ...,\n",
       "         [ 95.],\n",
       "         [ 95.],\n",
       "         [ 95.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 99.],\n",
       "         [ 99.],\n",
       "         [100.],\n",
       "         ...,\n",
       "         [ 84.],\n",
       "         [ 98.],\n",
       "         [ 99.]],\n",
       "\n",
       "        [[100.],\n",
       "         [ 99.],\n",
       "         [ 99.],\n",
       "         ...,\n",
       "         [ 74.],\n",
       "         [ 96.],\n",
       "         [ 99.]],\n",
       "\n",
       "        [[ 99.],\n",
       "         [100.],\n",
       "         [ 99.],\n",
       "         ...,\n",
       "         [ 79.],\n",
       "         [ 97.],\n",
       "         [ 99.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 98.],\n",
       "         [ 97.],\n",
       "         [ 92.],\n",
       "         ...,\n",
       "         [ 93.],\n",
       "         [ 99.],\n",
       "         [ 98.]],\n",
       "\n",
       "        [[ 99.],\n",
       "         [ 98.],\n",
       "         [ 87.],\n",
       "         ...,\n",
       "         [ 97.],\n",
       "         [ 99.],\n",
       "         [ 99.]],\n",
       "\n",
       "        [[ 97.],\n",
       "         [ 97.],\n",
       "         [ 93.],\n",
       "         ...,\n",
       "         [100.],\n",
       "         [100.],\n",
       "         [ 99.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 98.],\n",
       "         [ 98.],\n",
       "         [ 98.],\n",
       "         ...,\n",
       "         [100.],\n",
       "         [100.],\n",
       "         [ 99.]],\n",
       "\n",
       "        [[ 98.],\n",
       "         [ 99.],\n",
       "         [ 99.],\n",
       "         ...,\n",
       "         [ 99.],\n",
       "         [100.],\n",
       "         [ 98.]],\n",
       "\n",
       "        [[ 98.],\n",
       "         [ 97.],\n",
       "         [ 95.],\n",
       "         ...,\n",
       "         [100.],\n",
       "         [100.],\n",
       "         [100.]]],\n",
       "\n",
       "\n",
       "       [[[ 96.],\n",
       "         [ 95.],\n",
       "         [ 89.],\n",
       "         ...,\n",
       "         [ 85.],\n",
       "         [ 89.],\n",
       "         [ 89.]],\n",
       "\n",
       "        [[ 93.],\n",
       "         [ 89.],\n",
       "         [ 94.],\n",
       "         ...,\n",
       "         [ 81.],\n",
       "         [ 87.],\n",
       "         [ 88.]],\n",
       "\n",
       "        [[ 94.],\n",
       "         [ 83.],\n",
       "         [ 92.],\n",
       "         ...,\n",
       "         [ 87.],\n",
       "         [ 89.],\n",
       "         [ 92.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 90.],\n",
       "         [ 83.],\n",
       "         [ 88.],\n",
       "         ...,\n",
       "         [ 86.],\n",
       "         [ 75.],\n",
       "         [ 79.]],\n",
       "\n",
       "        [[ 84.],\n",
       "         [ 78.],\n",
       "         [ 88.],\n",
       "         ...,\n",
       "         [ 76.],\n",
       "         [ 81.],\n",
       "         [ 80.]],\n",
       "\n",
       "        [[ 86.],\n",
       "         [ 83.],\n",
       "         [ 81.],\n",
       "         ...,\n",
       "         [ 84.],\n",
       "         [ 81.],\n",
       "         [ 82.]]],\n",
       "\n",
       "\n",
       "       [[[ 79.],\n",
       "         [ 80.],\n",
       "         [ 80.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[ 86.],\n",
       "         [ 84.],\n",
       "         [ 81.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[ 86.],\n",
       "         [ 86.],\n",
       "         [ 81.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [ 63.],\n",
       "         [ 63.],\n",
       "         [ 64.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [ 69.],\n",
       "         [ 66.],\n",
       "         [ 79.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [ 61.],\n",
       "         [ 66.],\n",
       "         [ 70.]]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['canopy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "69/69 [==============================] - 111s 2s/step - loss: 4353.3892 - landcover_loss: 1.0619 - canopy_loss: 4352.3274 - landcover_acc: 0.4212 - canopy_mean_absolute_error: 50.4047 - val_loss: 4335.9775 - val_landcover_loss: 0.8038 - val_canopy_loss: 4335.1737 - val_landcover_acc: 0.6156 - val_canopy_mean_absolute_error: 50.3743\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 61s 887ms/step - loss: 4324.9937 - landcover_loss: 0.6919 - canopy_loss: 4324.3018 - landcover_acc: 0.6088 - canopy_mean_absolute_error: 50.3105 - val_loss: 4337.9796 - val_landcover_loss: 0.6067 - val_canopy_loss: 4337.3729 - val_landcover_acc: 0.6341 - val_canopy_mean_absolute_error: 50.3657\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 61s 887ms/step - loss: 4335.4577 - landcover_loss: 0.5247 - canopy_loss: 4334.9330 - landcover_acc: 0.6460 - canopy_mean_absolute_error: 50.4267 - val_loss: 4335.5599 - val_landcover_loss: 0.5277 - val_canopy_loss: 4335.0322 - val_landcover_acc: 0.6222 - val_canopy_mean_absolute_error: 50.3500\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 61s 886ms/step - loss: 4336.9256 - landcover_loss: 0.4935 - canopy_loss: 4336.4321 - landcover_acc: 0.6437 - canopy_mean_absolute_error: 50.4429 - val_loss: 4356.6339 - val_landcover_loss: 0.4959 - val_canopy_loss: 4356.1381 - val_landcover_acc: 0.6302 - val_canopy_mean_absolute_error: 50.5620\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 61s 887ms/step - loss: 4324.2690 - landcover_loss: 0.4909 - canopy_loss: 4323.7781 - landcover_acc: 0.6552 - canopy_mean_absolute_error: 50.2916 - val_loss: 4348.7995 - val_landcover_loss: 0.4993 - val_canopy_loss: 4348.3002 - val_landcover_acc: 0.6452 - val_canopy_mean_absolute_error: 50.4562\n",
      "Epoch 6/200\n",
      "27/69 [==========>...................] - ETA: 33s - loss: 4240.9974 - landcover_loss: 0.4883 - canopy_loss: 4240.5090 - landcover_acc: 0.6506 - canopy_mean_absolute_error: 49.3556"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-d50bb0cc6b8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_px\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtile_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_px\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     validation_steps=len(val_px) // batch_size)# callbacks=callbacks_list) #class_weight=weights, callbacks=callbacks_list) \n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=tile_gen.tile_generator(train_px, batch_size), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=tile_gen.tile_generator(val_px, batch_size),\n",
    "                    validation_steps=len(val_px) // batch_size)# callbacks=callbacks_list) #class_weight=weights, callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model.load_weights('strange_v3_merged.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 39s 102ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(generator = tile_gen.tile_generator(test_px, batch_size=1), steps=len(test_px) // 1, verbose=1)\n",
    "eval_generator = tile_gen.tile_generator(test_px, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = np.asarray(predictions[0])\n",
    "canopy = np.asarray(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        ...,\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293]],\n",
       "\n",
       "       [[ 0.9640276],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        ...,\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293]],\n",
       "\n",
       "       [[ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        ...,\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        ...,\n",
       "        [ 0.       ],\n",
       "        [ 0.       ],\n",
       "        [ 0.       ]],\n",
       "\n",
       "       [[ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        ...,\n",
       "        [ 0.       ],\n",
       "        [ 0.       ],\n",
       "        [ 0.       ]],\n",
       "\n",
       "       [[ 0.9950548],\n",
       "        [ 0.9993293],\n",
       "        [ 0.9993293],\n",
       "        ...,\n",
       "        [ 0.       ],\n",
       "        [ 0.       ],\n",
       "        [-0.       ]]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canopy[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(predictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangeBlock(input_block, nb_layers, filters):\n",
    "    x_list = [input_block]\n",
    "    c_temp = input_block\n",
    "    for i in range(nb_layers):\n",
    "        c_l = Bidirectional(ConvLSTM2D(filters=filters,kernel_size=(3,3), activation='elu', padding = 'same', return_sequences=True)) (c_temp)\n",
    "        x_list.append(c_l)\n",
    "        merge = Concatenate()(x_list)\n",
    "        c_temp = merge\n",
    "    return c_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty(pred.shape)\n",
    "count = 0\n",
    "while count < len(labels):\n",
    "        image_b, label_b = next(eval_generator)\n",
    "        label_b = np.argmax(label_b, axis=-1)\n",
    "        labels[count] = label_b\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = labels.reshape(len(test_px)*4096)\n",
    "pred_index = pred.reshape(len(test_px)*4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(util.indexed_dictionary)),\n",
    "                      class_dict=util.indexed_dictionary)\n",
    "# Plot normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(util.indexed_dictionary)),\n",
    "                      class_dict=util.indexed_dictionary,\n",
    "                      normalize=True)\n",
    "count = 0\n",
    "for i in range(len(label_index)):\n",
    "    if(label_index[i] == pred_index[i]):\n",
    "        count+=1\n",
    "print(\"Accuracy is {}\".format(count/len(label_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels(label_index, pred_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_network(input_shape):\n",
    "    input_img = Input(input_shape)\n",
    "    #c_l1 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (input_img)\n",
    "    #c_l2 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (c_l1)\n",
    "    c_l3 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (input_img)\n",
    "    #pool_1 = TimeDistributed(MaxPooling2D((3,3), padding='same')) (c_l3)\n",
    "    #c_l4 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (pool_1)\n",
    "    #c_l5 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (c_l4)\n",
    "    #c_l6 = ConvLSTM2D(filters=32,kernel_size=(2,2), activation='elu', padding = 'same', return_sequences=True) (pool_1)\n",
    "    #upsample_1 = TimeDistributed(UpSampling2D((3,3))) (c_l6)\n",
    "    conv_1 = TimeDistributed(Conv2D(32, (3,3), padding='same'))(c_l3)\n",
    "    #merge = Concatenate()([c_l3, conv_1])\n",
    "    conv_lc = ConvLSTM2D(filters=16,kernel_size=(1,1), activation='softmax', padding = 'same', return_sequences=False) (conv_1)\n",
    "    #conv_out_cc = ConvLSTM2D(filters=1,kernel_size=(1,1), activation='sigmoid', padding = 'same', return_sequences=False)(merge)\n",
    "    #model = Model(inputs=input_img, outputs=[conv_lc, conv_out_cc])\n",
    "    model = Model(inputs=input_img, outputs=conv_lc)\n",
    "    return model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)\n",
    "w_generator = w_tile_gen.tile_generator(pixels, batch_size=1)\n",
    "total_labels = list()\n",
    "count = 0\n",
    "while count < len(pixels):\n",
    "        image_b, label_b = next(w_generator)\n",
    "        label_b = np.argmax(label_b, axis=-1)\n",
    "        total_labels.append(label_b)\n",
    "        count+=1\n",
    "total_labels = np.asarray(total_labels)\n",
    "total_labels = total_labels.reshape(len(total_labels)*64*64)\n",
    "buckets = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0}\n",
    "for label in total_labels:\n",
    "    buckets[label] +=1\n",
    "print(buckets)\n",
    "weights_list = class_weight.compute_class_weight('balanced', np.unique(total_labels), total_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
