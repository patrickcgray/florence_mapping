{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LC Model Search Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare 1 season (summer) and 4 temporal steps\n",
    "* Compare 0 - 1500 training training samples per class in 100 sample increments\n",
    "* CNN component and RNN components in isolation\n",
    "* regular CNN+RNN vs conv2dlstm and RNN vs just conv2dLSTM\n",
    "* Compare to scikit-learn methods using same val and test datasets\n",
    "* Compare best model across time\n",
    "    * if major decrease in accuracy then consider training on both 2010 and 2011 data for initial time step\n",
    "        * consider training on 1999 data to see how it changes the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "import datetime\n",
    "import rasterio\n",
    "import keras\n",
    "import random\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Bidirectional\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPooling3D, ConvLSTM2D, TimeDistributed, UpSampling2D, Concatenate, LSTM, concatenate\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import utilities as util\n",
    "import importlib\n",
    "import rnn_tiles\n",
    "import rnn_pixels\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/host/Code/florence_mapping/utilities.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rnn_pixels)\n",
    "importlib.reload(rnn_tiles)\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign your specific GPU so we don't overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that GPU and only that GPU visible?\n",
    "\n",
    "Note that it will always say GPU:0 but you should just see one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest Training Labels\n",
    "\n",
    "Note that these are monster files so be careful how you inspect them, typically you only want to use the `rasterio` windows option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/landcover/NLCD_2011_Land_Cover_L48_20190424.img')\n",
    "canopy_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/canopy/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img')\n",
    "class_dict = util.indexed_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest the landsat imagery stacked into yearly seasonal tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = {}\n",
    "landsat_datasets = {}\n",
    "tiles['028012'] = ['20110103', '20110308', '20110730', '20110831', '20111103']\n",
    "tiles['029011'] = ['20110103', '20110308', '20110730', '20110831', '20111018']\n",
    "tiles['028011'] = ['20110103', '20110308', '20110831', '20111018', '20111103']\n",
    "\n",
    "for tile_number, dates in tiles.items():\n",
    "    tile_datasets = []\n",
    "    l8_image_paths = []\n",
    "    for date in dates:\n",
    "        l8_image_paths.append('/deep_data/recurrent_data/tile{}/combined/combined{}.tif'.format(tile_number, date))\n",
    "    for fp in l8_image_paths:\n",
    "        tile_datasets.append(rasterio.open(fp))\n",
    "    landsat_datasets[tile_number] = tile_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pixels from shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, ((1407, 3674), '028012'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gdf = gpd.read_file('../train_buffered_points140520.shp')\n",
    "train_px = []\n",
    "for index, row in train_gdf.iterrows():\n",
    "    train_px.append(((row['row'], row['col']), row['tile_name']))\n",
    "\n",
    "random.shuffle(train_px)\n",
    "\n",
    "len(train_px), train_px[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, ((2399.0, 1688.0), '028012'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_gdf = gpd.read_file('../test_buffered_points140520_val.shp')\n",
    "val_px = []\n",
    "\n",
    "per_class_count = [0] * 6\n",
    "total_per_class_count = [0] * 6\n",
    "\n",
    "for index, row in val_gdf.iterrows():\n",
    "    if not row['dubious']:\n",
    "        total_per_class_count[int(row['label'])] = total_per_class_count[int(row['label'])] + 1\n",
    "        if per_class_count[int(row['label'])] < 125:\n",
    "            per_class_count[int(row['label'])] = per_class_count[int(row['label'])] + 1\n",
    "            val_px.append(((row['row'], row['col']), row['tile_name']))\n",
    "    \n",
    "random.shuffle(val_px)\n",
    "\n",
    "len(val_px), val_px[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([141, 147, 133, 133, 130, 129], [125, 125, 125, 125, 125, 125])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_per_class_count, per_class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canopy</th>\n",
       "      <th>col</th>\n",
       "      <th>label</th>\n",
       "      <th>row</th>\n",
       "      <th>tile_name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>manual_val</th>\n",
       "      <th>dubious</th>\n",
       "      <th>reject</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>028012</td>\n",
       "      <td>1750950.0</td>\n",
       "      <td>1466280.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-76.61112678048431 34.64445257944547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>028011</td>\n",
       "      <td>1771020.0</td>\n",
       "      <td>1644000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-75.98675821109941 36.16139632039837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>029011</td>\n",
       "      <td>1818630.0</td>\n",
       "      <td>1609740.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-75.54709982307929 35.77251818591635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3896.0</td>\n",
       "      <td>028011</td>\n",
       "      <td>1725120.0</td>\n",
       "      <td>1547910.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-76.70836461104372 35.40562568571118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3414.0</td>\n",
       "      <td>028012</td>\n",
       "      <td>1664100.0</td>\n",
       "      <td>1412370.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-77.66217912565303 34.32496740952818...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   canopy     col  label     row tile_name          x          y  manual_val  \\\n",
       "0     0.0  3884.0    0.0  1617.0    028012  1750950.0  1466280.0           0   \n",
       "1     0.0  4553.0    0.0   693.0    028011  1771020.0  1644000.0           0   \n",
       "2     0.0  1140.0    0.0  1835.0    029011  1818630.0  1609740.0           0   \n",
       "3     0.0  3023.0    0.0  3896.0    028011  1725120.0  1547910.0           0   \n",
       "4     0.0   989.0    0.0  3414.0    028012  1664100.0  1412370.0           0   \n",
       "\n",
       "   dubious  reject                                           geometry  \n",
       "0        0       0  POLYGON ((-76.61112678048431 34.64445257944547...  \n",
       "1        0       0  POLYGON ((-75.98675821109941 36.16139632039837...  \n",
       "2        0       0  POLYGON ((-75.54709982307929 35.77251818591635...  \n",
       "3        0       0  POLYGON ((-76.70836461104372 35.40562568571118...  \n",
       "4        0       0  POLYGON ((-77.66217912565303 34.32496740952818...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangeBlock_v4(input_block, nb_layers, filters):\n",
    "    x_list = [input_block]\n",
    "    c_temp = input_block\n",
    "    for i in range(nb_layers):\n",
    "        c_l = LSTM(units=filters, activation='elu', return_sequences=True) (c_temp)\n",
    "        x_list.append(c_l)\n",
    "        merge = Concatenate()(x_list)\n",
    "        c_temp = merge\n",
    "    return c_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLT_dense(in_shape, in_shape_tile, num_classes):\n",
    "    input_tensor = Input(shape = in_shape, name=\"rnn_input\")\n",
    "    #single pixel model\n",
    "    block = strangeBlock_v4(input_tensor, 5, 12)\n",
    "    block_2 = strangeBlock_v4(block, 3, 20)\n",
    "    final_block = LSTM(64, activation='softmax', return_sequences=False) (block_2)\n",
    "\n",
    "    #cnn model\n",
    "    input_tensor_tile = Input(shape = in_shape_tile, name=\"tile_input\")\n",
    "    \n",
    "    \n",
    "    cnn_layer1 = ConvLSTM2D(64, kernel_size=3, activation='elu', data_format='channels_last', \n",
    "                            return_sequences=True)(input_tensor_tile)\n",
    "    \n",
    "    first_batch_norm = BatchNormalization()(cnn_layer1)\n",
    "    \n",
    "    cnn_layer2 = ConvLSTM2D(64, kernel_size=3, activation='elu', data_format='channels_last', \n",
    "                            return_sequences=True)(first_batch_norm)\n",
    "    \n",
    "    second_batch_norm = BatchNormalization()(cnn_layer2)\n",
    "    \n",
    "    first_pool3D = MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last')(second_batch_norm)\n",
    "    \n",
    "    cnn_layer3 = ConvLSTM2D(64, kernel_size=2, activation='elu', data_format='channels_last', \n",
    "                            return_sequences=False)(first_pool3D)\n",
    "    \n",
    "    first_pool2D = MaxPooling2D(pool_size=(2, 2), strides=None, padding='same') (cnn_layer3)\n",
    "    \n",
    "    third_batch_norm = BatchNormalization()(first_pool2D)\n",
    "    \n",
    "    flatten = Flatten()(third_batch_norm)\n",
    "    \n",
    "    #concat = concatenate([final_block, flatten])\n",
    "    \n",
    "    concat = flatten\n",
    "    \n",
    "    denselayer = Dense(64, activation=\"elu\")(concat)\n",
    "    \n",
    "    landcover = Dense(num_classes,activation='softmax', name='landcover') (denselayer)\n",
    "    #canopy = Dense(1, name='canopy') (concat)\n",
    "\n",
    "    model = Model(inputs=[input_tensor,input_tensor_tile], outputs=[landcover])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLT_dense(in_shape, in_shape_tile, num_classes):\n",
    "    input_tensor = Input(shape = in_shape, name=\"rnn_input\")\n",
    "    #single pixel model\n",
    "    block = strangeBlock_v4(input_tensor, 5, 12)\n",
    "    block_2 = strangeBlock_v4(block, 3, 20)\n",
    "    final_block = LSTM(64, activation='softmax', return_sequences=False) (block_2)\n",
    "\n",
    "    #cnn model\n",
    "    input_tensor_tile = Input(shape = in_shape_tile, name=\"tile_input\")\n",
    "    \n",
    "    \n",
    "    cnn_layer1 = ConvLSTM2D(64, kernel_size=3, activation='elu', data_format='channels_last', \n",
    "                            return_sequences=True)(input_tensor_tile)\n",
    "    \n",
    "    first_batch_norm = BatchNormalization()(cnn_layer1)\n",
    "    \n",
    "    cnn_layer2 = ConvLSTM2D(64, kernel_size=3, activation='elu', data_format='channels_last', \n",
    "                            return_sequences=True)(first_batch_norm)\n",
    "    \n",
    "    second_batch_norm = BatchNormalization()(cnn_layer2)\n",
    "    \n",
    "    first_pool3D = MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last')(second_batch_norm)\n",
    "    \n",
    "    cnn_layer3 = ConvLSTM2D(64, kernel_size=2, activation='elu', data_format='channels_last', \n",
    "                            return_sequences=True)(first_pool3D)\n",
    "    \n",
    "    third_batch_norm = BatchNormalization()(cnn_layer3)\n",
    "    \n",
    "    #first_pool2D = MaxPooling2D(pool_size=(2, 2), strides=None, padding='same') (third_batch_norm)\n",
    "    #second_pool3D = MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last')(third_batch_norm)\n",
    "    \n",
    "    flatten = Flatten()(third_batch_norm)\n",
    "    \n",
    "    #concat = concatenate([final_block, flatten])    \n",
    "    denselayer = Dense(64, activation=\"elu\")(flatten)\n",
    "    \n",
    "    landcover = Dense(num_classes,activation='softmax', name='landcover') (denselayer)\n",
    "    #canopy = Dense(1, name='canopy') (concat)\n",
    "\n",
    "    model = Model(inputs=[input_tensor,input_tensor_tile], outputs=[landcover])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLT_dense(in_shape, in_shape_tile, num_classes):\n",
    "    input_tensor = Input(shape = in_shape, name=\"rnn_input\")\n",
    "    #single pixel model\n",
    "    block = strangeBlock_v4(input_tensor, 5, 12)\n",
    "    block_2 = strangeBlock_v4(block, 3, 20)\n",
    "    final_block = LSTM(64, activation='softmax', return_sequences=False) (block_2)\n",
    "\n",
    "    #cnn model\n",
    "    input_tensor_tile = Input(shape = in_shape_tile, name=\"tile_input\")\n",
    "    cnn_layer1 = ConvLSTM2D(64, kernel_size=3, activation='elu', return_sequences=True, data_format='channels_last')(input_tensor_tile)\n",
    "    first_batch_norm = BatchNormalization()(cnn_layer1)\n",
    "    cnn_layer2 = ConvLSTM2D(64, kernel_size=3, activation='elu', return_sequences=True, data_format='channels_last') (first_batch_norm)\n",
    "    second_batch_norm = BatchNormalization()(cnn_layer2)\n",
    "    maxpool = MaxPooling3D(pool_size=(1, 2, 2), strides=None, padding='same') (second_batch_norm)\n",
    "    cnn_layer3 = ConvLSTM2D(64, kernel_size=2, activation='elu', return_sequences=False, data_format='channels_last') (second_batch_norm)\n",
    "    flatten = Flatten()(cnn_layer3)\n",
    "    #concat = concatenate([final_block, flatten])\n",
    "    \n",
    "    denselayer = Dense(64, activation=\"relu\")(flatten)\n",
    "    \n",
    "    landcover = Dense(num_classes,activation='softmax', name='landcover') (denselayer)\n",
    "    #canopy = Dense(1, name='canopy') (concat)\n",
    "\n",
    "    model = Model(inputs=[input_tensor,input_tensor_tile], outputs=[landcover])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLT_dense(in_shape, in_shape_tile, num_classes):\n",
    "    input_tensor = Input(shape = in_shape, name=\"rnn_input\")\n",
    "    #single pixel model\n",
    "    block = strangeBlock_v4(input_tensor, 5, 12)\n",
    "    block_2 = strangeBlock_v4(block, 3, 20)\n",
    "    final_block = LSTM(64, activation='softmax', return_sequences=False) (block_2)\n",
    "\n",
    "    #cnn model\n",
    "    input_tensor_tile = Input(shape = in_shape_tile, name=\"tile_input\")\n",
    "    cnn_layer1 = ConvLSTM2D(64, kernel_size=3, activation='elu', return_sequences=True)(input_tensor_tile)\n",
    "    # batch norm\n",
    "    cnn_layer2 = ConvLSTM2D(64, kernel_size=3, activation='elu', return_sequences=False) (cnn_layer1)\n",
    "    maxpool = MaxPooling2D(pool_size=(2, 2), strides=None, padding='same') (cnn_layer2)\n",
    "    flatten = Flatten()(maxpool)\n",
    "    concat = concatenate([final_block, flatten])\n",
    "    \n",
    "    denselayer = Dense(64, activation=\"elu\")(concat)\n",
    "    \n",
    "    landcover = Dense(num_classes,activation='softmax', name='landcover') (denselayer)\n",
    "    #canopy = Dense(1, name='canopy') (concat)\n",
    "\n",
    "    model = Model(inputs=[input_tensor,input_tensor_tile], outputs=[landcover])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the experiments here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'rcnn_full_testing'\n",
    "model_name = 'rcnn_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (3.1.6) detected. current: 3.1.7 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/clifgray/chronos/3d8580f5cc54413aac7cbe63e7708484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(api_key=\"rMFbl2RlGxNuyyL37dE7qPSfE\",\n",
    "                        project_name=\"chronos\", workspace=\"clifgray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.add_tag(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 13\n",
    "tile_list = ['028012', '029011', '028011']\n",
    "class_count = len(class_dict)\n",
    "epochs = 60\n",
    "batch_size = 25\n",
    "steps_division_factor = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rnn_input (InputLayer)          (None, 5, 7)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 5, 12)        960         rnn_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 19)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 5, 12)        1536        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 31)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 5, 12)        2112        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5, 43)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 5, 12)        2688        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 55)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 5, 12)        3264        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 67)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 5, 20)        7040        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 87)        0           concatenate_5[0][0]              \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 5, 20)        8640        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tile_input (InputLayer)         (None, 5, 13, 13, 7) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5, 107)       0           concatenate_5[0][0]              \n",
      "                                                                 lstm_6[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)     (None, 5, 11, 11, 64 163840      tile_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 5, 20)        10240       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)     (None, 9, 9, 64)     295168      conv_lst_m2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5, 127)       0           concatenate_5[0][0]              \n",
      "                                                                 lstm_6[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "                                                                 lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 64)     0           conv_lst_m2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 64)           49152       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1600)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1664)         0           lstm_9[0][0]                     \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           106560      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "landcover (Dense)               (None, 6)            390         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 651,590\n",
      "Trainable params: 651,590\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_MLT_dense((len(tiles['028012']),7),(len(tiles['028012']),tile_size,tile_size,7), class_count)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'model_search/' +  model_name + '--' + exp_name + '.hdf5' #your filepath here\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss={'landcover':'categorical_crossentropy'}, metrics={'landcover':['accuracy']}, loss_weights={\"landcover\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11: 0,\n",
       " 21: 3,\n",
       " 22: 1,\n",
       " 23: 1,\n",
       " 24: 1,\n",
       " 31: 4,\n",
       " 41: 2,\n",
       " 42: 2,\n",
       " 43: 2,\n",
       " 52: 2,\n",
       " 71: 3,\n",
       " 81: 3,\n",
       " 82: 3,\n",
       " 90: 2,\n",
       " 95: 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n",
      "COMET INFO: Ignoring automatic log_parameter('do_validation') because 'keras:do_validation' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      " 1/36 [..............................] - ETA: 4:50 - loss: 1.8549 - acc: 0.2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Ignoring automatic log_metric('batch_size') because 'keras:batch_size' is in COMET_LOGGING_METRICS_IGNORE\n",
      "COMET INFO: Ignoring automatic log_metric('batch_batch') because 'keras:batch_batch' is in COMET_LOGGING_METRICS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 16s 440ms/step - loss: 0.7596 - acc: 0.7044 - val_loss: 0.2850 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90800, saving model to model_search/rcnn_full--rcnn_full_testing.hdf5\n",
      "Epoch 2/60\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 0.4301 - acc: 0.8456 - val_loss: 0.3627 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90800\n",
      "Epoch 3/60\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.3971 - acc: 0.8822 - val_loss: 0.2753 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90800 to 0.90800, saving model to model_search/rcnn_full--rcnn_full_testing.hdf5\n",
      "Epoch 4/60\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.3355 - acc: 0.8733 - val_loss: 0.1544 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90800 to 0.94400, saving model to model_search/rcnn_full--rcnn_full_testing.hdf5\n",
      "Epoch 5/60\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.3427 - acc: 0.8856 - val_loss: 0.1691 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94400 to 0.94400, saving model to model_search/rcnn_full--rcnn_full_testing.hdf5\n",
      "Epoch 6/60\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.3040 - acc: 0.8978 - val_loss: 0.1532 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94400 to 0.96000, saving model to model_search/rcnn_full--rcnn_full_testing.hdf5\n",
      "Epoch 7/60\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.2636 - acc: 0.9044 - val_loss: 0.2023 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.96000\n",
      "Epoch 8/60\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.3423 - acc: 0.8878 - val_loss: 0.1991 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.96000\n",
      "Epoch 9/60\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.2763 - acc: 0.8989 - val_loss: 0.1639 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.96000\n",
      "Epoch 10/60\n",
      "36/36 [==============================] - 6s 177ms/step - loss: 0.2901 - acc: 0.9056 - val_loss: 0.1385 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.96000\n",
      "Epoch 11/60\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.2340 - acc: 0.9200 - val_loss: 0.1174 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.96000 to 0.96133, saving model to model_search/rcnn_full--rcnn_full_testing.hdf5\n",
      "Epoch 12/60\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.2146 - acc: 0.9256 - val_loss: 0.1940 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.96133\n",
      "Epoch 13/60\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.2460 - acc: 0.9167 - val_loss: 0.1324 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.96133\n",
      "Epoch 14/60\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.2288 - acc: 0.9156 - val_loss: 0.1161 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.96133 to 0.96400, saving model to model_search/rcnn_full--rcnn_full_testing.hdf5\n",
      "Epoch 15/60\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.2272 - acc: 0.9311 - val_loss: 0.1747 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.96400\n",
      "Epoch 16/60\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.2603 - acc: 0.9156 - val_loss: 0.1505 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.96400\n",
      "Epoch 17/60\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.2242 - acc: 0.9144 - val_loss: 0.1439 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.96400\n",
      "Epoch 18/60\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.2547 - acc: 0.9178 - val_loss: 0.1941 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96400\n",
      "Epoch 19/60\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.2024 - acc: 0.9222 - val_loss: 0.1435 - val_acc: 0.9573\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.96400\n",
      "Epoch 20/60\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.2353 - acc: 0.9156 - val_loss: 0.1475 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.96400\n",
      "Epoch 21/60\n",
      " 8/36 [=====>........................] - ETA: 3s - loss: 0.2380 - acc: 0.9250"
     ]
    }
   ],
   "source": [
    "train_time_start = datetime.datetime.now()\n",
    "\n",
    "history = model.fit_generator(generator=tile_gen.tile_generator(train_px, batch_size, flatten=True, canopy=True), \n",
    "                steps_per_epoch=len(train_px) // batch_size // steps_division_factor, epochs=epochs, verbose=1,\n",
    "                validation_data=tile_gen.tile_generator(val_px, batch_size, flatten=True, canopy=True),\n",
    "                validation_steps=len(val_px) // batch_size,\n",
    "                callbacks=callbacks_list) \n",
    "\n",
    "train_time_stop = datetime.datetime.now()\n",
    "training_time = train_time_stop - train_time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "experiment.log_figure(figure=plt, figure_name=\"model_acc\")\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "experiment.log_figure(figure=plt, figure_name=\"model_loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_time_start = datetime.datetime.now()\n",
    "\n",
    "predictions = model.predict_generator(generator = tile_gen.tile_generator(val_px, batch_size=50, flatten=True, canopy=True), steps=len(val_px) // 50, verbose=1)\n",
    "\n",
    "inference_time_stop = datetime.datetime.now()\n",
    "inference_time = inference_time_stop - inference_time_start\n",
    "\n",
    "eval_generator = tile_gen.tile_generator(val_px, batch_size=1, flatten=True, canopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "450 * 60 *60 * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_predictions = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_lab = np.empty(lc_predictions.shape[0])\n",
    "#canopy_true = np.empty(canopy_pred.shape)\n",
    "count = 0\n",
    "while count < len(lc_predictions):\n",
    "        image_b, label_b = next(eval_generator)\n",
    "        #label_b = np.argmax(label_b, axis=-1)\n",
    "        label_lc = np.argmax(label_b['landcover'], axis=-1)\n",
    "        #canopy_true[count] = label_b['canopy']\n",
    "        lc_lab[count] = label_lc\n",
    "        count += 1\n",
    "label_index = lc_lab.reshape(len(val_px)*1*1)\n",
    "pred_index = np.argmax(lc_predictions, axis=-1).reshape(len(val_px)*1*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "_, users_acc, prod_acc = util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(class_dict)),\n",
    "                      class_dict=class_dict)\n",
    "experiment.log_figure(figure=plt, figure_name=\"unnorm_conf_matrix\")\n",
    "# Plot normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(class_dict)),\n",
    "                      class_dict=class_dict,\n",
    "                      normalize=True,\n",
    "                          title=\" \")\n",
    "experiment.log_figure(figure=plt, figure_name=\"norm_conf_matrix\")\n",
    "count = 0\n",
    "per_class_acc = [0] * 6\n",
    "for i in range(len(label_index)):\n",
    "    if(label_index[i] == pred_index[i]):\n",
    "        per_class_acc[int(label_index[i])] = per_class_acc[int(label_index[i])] + 1\n",
    "        count+=1\n",
    "\n",
    "val_accuracy=count/len(label_index)\n",
    "class_acc_dict = {}\n",
    "print(\"Accuracy is\",val_accuracy)\n",
    "# this is producer's accuracy\n",
    "for idx, class_correct in enumerate(per_class_acc):\n",
    "    class_acc_dict[class_dict[idx]] = round(class_correct/(int(len(label_index)/class_count)),4)\n",
    "    print('per_class_acc', class_correct/(per_class_count[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy per class\n",
    "Calculate overall accuracy\n",
    "Add training samples\n",
    "add epochs\n",
    "add tile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "experiment_df = pd.DataFrame(columns=['exp_name','model_name','time_steps','train_count','overall_acc', \n",
    "                                      'epochs', 'tile_size', 'training_time', 'inference_time',\n",
    "                                      'water_acc_prod','dev_acc_prod', 'forest_acc_prod', 'cult_acc_prod', 'barren_acc_prod', 'wetland_acc_prod',\n",
    "                                      'water_acc_user','dev_acc_user', 'forest_acc_user', 'cult_acc_user', 'barren_acc_user', 'wetland_acc_user'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df.loc[len(experiment_df)] = [exp_name, model_name, len(tiles['028012']), len(train_px)/class_count, val_accuracy, \n",
    "                                         epochs, tile_size, training_time, inference_time] + list(np.round(prod_acc,3)) + list(np.round(users_acc,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df.to_csv('model_search/' + model_name + '--' + exp_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps = pd.read_csv('model_search/' + 'all_model_runs.csv')\n",
    "all_exps = pd.concat([all_exps,experiment_df], ignore_index=True)\n",
    "all_exps.to_csv('model_search/' + 'all_model_runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"exp_name\":exp_name,\n",
    "    \"model_name\":model_name,\n",
    "    \"landsat_tiles\":tiles,\n",
    "    \"cnn_tile_size\":tile_size,\n",
    "    \"class_dict\":class_dict,\n",
    "    \"batch_size\":batch_size,\n",
    "    \"steps_division_factor\":steps_division_factor,\n",
    "    \"lc_validation_acc\":val_accuracy\n",
    "}\n",
    "experiment.log_parameters(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
