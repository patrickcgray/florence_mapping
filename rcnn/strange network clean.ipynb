{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strange Network Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import keras\n",
    "import random\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Bidirectional\n",
    "from keras.layers import Conv2D, MaxPooling2D, ConvLSTM2D, TimeDistributed, UpSampling2D, Concatenate, LSTM, concatenate\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import utilities as util\n",
    "import importlib\n",
    "import rnn_tiles\n",
    "import rnn_pixels\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/host/Desktop/florence_mapping/utilities.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rnn_pixels)\n",
    "importlib.reload(rnn_tiles)\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign your specific GPU so we don't overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that GPU and only that GPU visible?\n",
    "\n",
    "Note that it will always say GPU:0 but you should just see one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest Training Labels\n",
    "\n",
    "Note that these are monster files so be careful how you inspect them, typically you only want to use the `rasterio` windows option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/landcover/NLCD_2011_Land_Cover_L48_20190424.img')\n",
    "canopy_labels = rasterio.open('/deep_data/recurrent_data/NLCD_DATA/canopy/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest the landsat imagery stacked into yearly seasonal tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = {}\n",
    "landsat_datasets = {}\n",
    "tiles['028012'] = ['20110324', '20110612', '20110831', '20111103']\n",
    "tiles['029011'] = ['20110308', '20110425', '20110831', '20111103']\n",
    "tiles['028011'] = ['20110308', '20110628', '20110831', '20111103']\n",
    "for tile_number, dates in tiles.items():\n",
    "    tile_datasets = []\n",
    "    l8_image_paths = []\n",
    "    for date in dates:\n",
    "        l8_image_paths.append('/deep_data/recurrent_data/tile{}/combined/combined{}.tif'.format(tile_number, date))\n",
    "    for fp in l8_image_paths:\n",
    "        tile_datasets.append(rasterio.open(fp))\n",
    "    landsat_datasets[tile_number] = tile_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 7\n",
    "tile_list = ['028012', '029011', '028011']\n",
    "class_count = 6\n",
    "epochs = 200\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The next two cells are for making pixels and prepping them for training (balancing)\n",
    "### This is unnecessary to run because I already saved them to text files so now you load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d28876a5b6ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_pixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpx_to_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_pixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_bad_tiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandsat_datasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlc_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanopy_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpx_to_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/host/Desktop/florence_mapping/rcnn/rnn_pixels.py\u001b[0m in \u001b[0;36mdelete_bad_tiles\u001b[0;34m(l8_data, lc_label, canopy_label, pixels, tile_size)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdataset_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtiles_to_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml8_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mtiles_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles_to_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml8_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# convert the point we're sampling from to the same projection as the label dataset if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/host/Desktop/florence_mapping/utilities.py\u001b[0m in \u001b[0;36mread_windows\u001b[0;34m(rasters, c, r, buffer, tile_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#only works when rasters are in same projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mraster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrasters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mrasterio/_io.pyx\u001b[0m in \u001b[0;36mrasterio._io.DatasetReaderBase.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36mmax\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;34m\"\"\"Maximum value of given dtype.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "px = rnn_pixels.make_pixels(tile_size, tile_list)\n",
    "px_to_use = px[:100000]\n",
    "pixels = rnn_pixels.delete_bad_tiles(landsat_datasets,lc_labels, canopy_labels, px_to_use, tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gets balanced pixels locations \n",
    "w_tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)\n",
    "w_generator = w_tile_gen.tile_generator(pixels, batch_size=1, flatten=True, canopy=False)\n",
    "total_labels = list()\n",
    "count = 0\n",
    "#buckets = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "buckets = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "\n",
    "while count < len(pixels):\n",
    "        image_b, label_b = next(w_generator)\n",
    "        label_b = np.argmax(label_b)\n",
    "        buckets[label_b].append(pixels[count]) # appends pixels to dictionary\n",
    "        total_labels.append(label_b)\n",
    "        count+=1\n",
    "total_labels = np.asarray(total_labels)\n",
    "total_labels = total_labels.reshape(len(total_labels))\n",
    "#weights_list = class_weight.compute_class_weight('balanced', np.unique(total_labels), total_labels)\n",
    "count = 0 \n",
    "for z, j in buckets.items():\n",
    "    print(len(j))\n",
    "    count += len(j)\n",
    "print(count) \n",
    "use_px = []\n",
    "use_px+=buckets[0][:3000]\n",
    "use_px+=(buckets[1][:3000])\n",
    "use_px+=(buckets[2][:3000])\n",
    "use_px+=(buckets[3][:3000])\n",
    "use_px+=(buckets[4][:3000])\n",
    "use_px+=(buckets[5][:3000])\n",
    "random.shuffle(use_px)\n",
    "train_px, val_px, test_px = rnn_pixels.train_val_test_split(use_px, 0.7, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "1000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "train_px, val_px, test_px = util.read_txt(['train_px.txt', 'val_px.txt', 'test_px.txt'])\n",
    "train_px = rnn_pixels.delete_bad_tiles(landsat_datasets,lc_labels, canopy_labels, train_px, tile_size)\n",
    "val_px =  rnn_pixels.delete_bad_tiles(landsat_datasets,lc_labels, canopy_labels, val_px, tile_size)\n",
    "test_px =  rnn_pixels.delete_bad_tiles(landsat_datasets,lc_labels, canopy_labels, test_px, tile_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangeBlock_v4(input_block, nb_layers, filters):\n",
    "    x_list = [input_block]\n",
    "    c_temp = input_block\n",
    "    for i in range(nb_layers):\n",
    "        c_l = LSTM(units=filters, activation='elu', return_sequences=True) (c_temp)\n",
    "        x_list.append(c_l)\n",
    "        merge = Concatenate()(x_list)\n",
    "        c_temp = merge\n",
    "    return c_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLT_dense(in_shape, in_shape_tile, num_classes):\n",
    "    input_tensor = Input(shape = in_shape, name=\"rnn_input\")\n",
    "    #single pixel model\n",
    "    block = strangeBlock_v4(input_tensor, 5, 12)\n",
    "    block_2 = strangeBlock_v4(block, 3, 20)\n",
    "    final_block = LSTM(64, activation='softmax', return_sequences=False) (block_2)\n",
    "\n",
    "    #cnn model\n",
    "    input_tensor_tile = Input(shape = in_shape_tile, name=\"tile_input\")\n",
    "    cnn_layer1 = ConvLSTM2D(64, kernel_size=2, activation='elu', return_sequences=True)(input_tensor_tile)\n",
    "    # batch norm\n",
    "    cnn_layer2 = ConvLSTM2D(64, kernel_size=2, activation='elu', return_sequences=False) (cnn_layer1)\n",
    "    maxpool = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid') (cnn_layer2)\n",
    "    flatten = Flatten()(maxpool)\n",
    "    concat = concatenate([final_block, flatten])\n",
    "    \n",
    "    landcover = Dense(num_classes,activation='softmax', name='landcover') (concat)\n",
    "    canopy = Dense(1, name='canopy') (concat)\n",
    "\n",
    "    model = Model(inputs=[input_tensor,input_tensor_tile], outputs=[landcover, canopy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rnn_input (InputLayer)          (None, 4, 7)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 4, 12)        960         rnn_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 19)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 4, 12)        1536        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 31)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 4, 12)        2112        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 43)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 4, 12)        2688        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 55)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 4, 12)        3264        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4, 67)        0           rnn_input[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 4, 20)        7040        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4, 87)        0           concatenate_5[0][0]              \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 4, 20)        8640        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tile_input (InputLayer)         (None, 4, 7, 7, 7)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 4, 107)       0           concatenate_5[0][0]              \n",
      "                                                                 lstm_6[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)     (None, 4, 6, 6, 64)  72960       tile_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 4, 20)        10240       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)     (None, 5, 5, 64)     131328      conv_lst_m2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 4, 127)       0           concatenate_5[0][0]              \n",
      "                                                                 lstm_6[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "                                                                 lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 2, 2, 64)     0           conv_lst_m2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 64)           49152       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 320)          0           lstm_9[0][0]                     \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "landcover (Dense)               (None, 6)            1926        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "canopy (Dense)                  (None, 1)            321         concatenate_9[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 292,167\n",
      "Trainable params: 292,167\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_MLT_dense((4,7),(4,tile_size,tile_size,7), 6)\n",
    "#model.load_weights('mlt_dense_model.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model('dense_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath = 'mlt_dense_model_pcg.hdf5'#your filepath here\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_landcover_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss={'landcover':'categorical_crossentropy', 'canopy':'mae'}, metrics={'landcover':['accuracy'], 'canopy':['mae']}, loss_weights={\"landcover\":1, \"canopy\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "347/347 [==============================] - 57s 164ms/step - loss: 0.9805 - landcover_loss: 0.8460 - canopy_loss: 0.1345 - landcover_acc: 0.6794 - canopy_mean_absolute_error: 0.1345 - val_loss: 0.7469 - val_landcover_loss: 0.6510 - val_canopy_loss: 0.0959 - val_landcover_acc: 0.7604 - val_canopy_mean_absolute_error: 0.0959\n",
      "Epoch 2/200\n",
      " 41/347 [==>...........................] - ETA: 36s - loss: 0.7980 - landcover_loss: 0.6921 - canopy_loss: 0.1059 - landcover_acc: 0.7493 - canopy_mean_absolute_error: 0.1059"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=tile_gen.tile_generator(train_px, batch_size, flatten=True, canopy=True), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                   validation_data=tile_gen.tile_generator(val_px, batch_size, flatten=True, canopy=True),\n",
    "                  validation_steps=len(val_px) // batch_size)# callbacks=callbacks_list)# class_weight=weights_list)# callbacks=callbacks_list) #class_weight=weights, callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rnn_tiles)\n",
    "tile_gen = rnn_tiles.rnn_tile_gen(landsat_datasets, lc_labels, canopy_labels, tile_size, class_count)\n",
    "dict1, dict2 = next(tile_gen.tile_generator(train_px, batch_size, flatten=False, canopy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2[\"canopy\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mlt_dense_pcg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2[\"landcover\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator = tile_gen.tile_generator(train_px, batch_size=1, flatten=True, canopy=True), steps=len(train_px) // 1, verbose=1)\n",
    "eval_generator = tile_gen.tile_generator(train_px, batch_size=1, flatten=True, canopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_predictions_train = np.asarray(predictions[0])\n",
    "canopy_pred_train = np.asarray(predictions[1])\n",
    "lc_predictions_train = np.argmax(lc_predictions_train,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_lab_train = np.empty(lc_predictions_train.shape)\n",
    "canopy_true_train = np.empty(canopy_pred_train.shape)\n",
    "count = 0\n",
    "while count < len(lc_predictions_train):\n",
    "        image_b, label_b = next(eval_generator)\n",
    "        #label_b = np.argmax(label_b, axis=-1)\n",
    "        label_lc = np.argmax(label_b['landcover'], axis=-1)\n",
    "        canopy_true_train[count] = label_b['canopy']\n",
    "        lc_lab_train[count] = label_lc\n",
    "        count += 1\n",
    "label_index = lc_lab_train.reshape(len(train_px)*tile_size*tile_size)\n",
    "pred_index = lc_predictions_train.reshape(len(train_px)*tile_size*tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(canopy_true_train, alpha=0.75), plt.hist(canopy_pred_train, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(canopy_true_train, canopy_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "x = (canopy_pred_train * 100).flatten()\n",
    "y = (canopy_true_train * 100).flatten()\n",
    "\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "idx = z.argsort()\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.scatter(x,y,c=z,s=50,edgecolor='')\n",
    "ax.set_xlabel(\"Predictions\")\n",
    "ax.set_ylabel(\"Annotations\")\n",
    "ax.set_title(\"Canopy Cover Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator = tile_gen.tile_generator(test_px, batch_size=1, flatten=True, canopy=True), steps=len(test_px) // 1, verbose=1)\n",
    "eval_generator = tile_gen.tile_generator(test_px, batch_size=1, flatten=True, canopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_predictions = np.asarray(predictions[0])\n",
    "canopy_pred = np.asarray(predictions[1])\n",
    "lc_predictions = np.argmax(lc_predictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_lab = np.empty(lc_predictions.shape)\n",
    "canopy_true = np.empty(canopy_pred.shape)\n",
    "count = 0\n",
    "while count < len(lc_predictions):\n",
    "        image_b, label_b = next(eval_generator)\n",
    "        #label_b = np.argmax(label_b, axis=-1)\n",
    "        label_lc = np.argmax(label_b['landcover'], axis=-1)\n",
    "        canopy_true[count] = label_b['canopy']\n",
    "        lc_lab[count] = label_lc\n",
    "        count += 1\n",
    "label_index = lc_lab.reshape(len(test_px)*tile_size*tile_size)\n",
    "pred_index = lc_predictions.reshape(len(test_px)*tile_size*tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(util.indexed_dictionary)),\n",
    "                      class_dict=util.indexed_dictionary)\n",
    "# Plot normalized confusion matrix\n",
    "util.plot_confusion_matrix(label_index.astype(np.int), pred_index.astype(np.int), classes=np.array(list(util.indexed_dictionary)),\n",
    "                      class_dict=util.indexed_dictionary,\n",
    "                      normalize=True,\n",
    "                          title=\" \")\n",
    "count = 0\n",
    "for i in range(len(label_index)):\n",
    "    if(label_index[i] == pred_index[i]):\n",
    "        count+=1\n",
    "print(\"Accuracy is {}\".format(count/len(label_index)))\n",
    "\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "tot = 0\n",
    "for count in range(len(canopy_pred)):\n",
    "    if canopy_true[count] != 0 and canopy_pred[count] !=0:\n",
    "        if canopy_pred[count] < 0:\n",
    "            canopy_pred[count] = 0\n",
    "        total+= np.absolute(canopy_pred[count] - canopy_true[count])\n",
    "        tot+=1\n",
    "print(total/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_df = pd.DataFrame({'lc_pred': pred_index,\n",
    "                        'lc_true': label_index,\n",
    "                        'canopy_pred': canopy_pred.flatten(),\n",
    "                        'canopy_true': canopy_true.flatten()})\n",
    "pred_df[pred_df[\"lc_true\"] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=pred_df['canopy_pred'][pred_df['lc_true']!=0], y=pred_df['canopy_true'][pred_df['lc_true']!=0], kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pred_df['canopy_pred'][pred_df['lc_true']!=0]\n",
    "y=pred_df['canopy_true'][pred_df['lc_true']!=0]\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "#ax.set_xlabel(\"Predictions\")\n",
    "#ax.set_ylabel(\"Annotations\")\n",
    "#ax.set_title(\"Canopy Cover Predictions\")\n",
    "\n",
    "g = sns.jointplot(x,y, kind='scatter', alpha=0.2)\n",
    "#g.ax_joint.scatter(x=pred_df['canopy_pred'][pred_df['lc_true']!=0], y=pred_df['canopy_true'][pred_df['lc_true']!=0])\n",
    "g.ax_joint.set_xticks(np.linspace(0,1,6))\n",
    "g.ax_joint.set_xlabel(\"\")\n",
    "g.ax_joint.set_ylabel(\"\")\n",
    "\n",
    "plt.savefig(\"canopy_regression.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(canopy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(canopy_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "#x = (canopy_pred * 100).flatten()\n",
    "#y = (canopy_true * 100).flatten()\n",
    "\n",
    "x=pred_df['canopy_pred'][pred_df['lc_true']!=0]\n",
    "y=pred_df['canopy_true'][pred_df['lc_true']!=0]\n",
    "\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "idx = z.argsort()\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.scatter(x,y,c=z,s=50,edgecolor='', alpha=0.7, cmap=\"nipy_spectral\")\n",
    "ax.set_xticks(np.linspace(0,1,6))\n",
    "#ax.set_xlabel(\"Predictions\")\n",
    "#ax.set_ylabel(\"Annotations\")\n",
    "#ax.set_title(\"Canopy Cover Predictions\")\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.savefig(\"canopy_regression.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_df['canopy_pred'][pred_df['lc_true']!=0])\n",
    "plt.hist(pred_df['canopy_true'][pred_df['lc_true']!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(canopy_pred, canopy_true)\n",
    "plt.xlabel(\"Canopy Fraction Predictions\")\n",
    "plt.ylabel(\"Canopy Fraction Annotations\")\n",
    "plt.savefig(\"canopy_regression.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(canopy_true, canopy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library & dataset\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('iris')\n",
    " \n",
    "\n",
    "sns.jointplot(y=(canopy_true*100).flatten(), x=(canopy_pred*100).flatten(), kind='scatter')\n",
    "sns.jointplot(x=(canopy_true*100).flatten(), y=(canopy_pred*100).flatten(), kind='hex')\n",
    "sns.jointplot(x=(canopy_true*100).flatten(), y=(canopy_pred*100).flatten(), kind='kde')\n",
    "#plt.savefig(\"canopy_reg_dist_cont.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
